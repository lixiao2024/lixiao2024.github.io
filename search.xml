<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GPT、DeepSeek发展历程</title>
      <link href="/2025/03/17/GPT%E3%80%81DeepSeek%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/"/>
      <url>/2025/03/17/GPT%E3%80%81DeepSeek%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>从GPT-1到GPT-4，GPT系列经历了从基础架构探索到大规模预训练、再到多模态能力与安全性提升的跨越。下面分阶段介绍这些技术迭代及关键突破：<br><img src="/img/0318-1.png" alt="Lena"></p><h1 id="小模型"><a href="#小模型" class="headerlink" title="小模型"></a>小模型</h1><h2 id="GPT-1：生成预训练的奠基之作"><a href="#GPT-1：生成预训练的奠基之作" class="headerlink" title="GPT-1：生成预训练的奠基之作"></a>GPT-1：生成预训练的奠基之作</h2><ul><li><strong>Transformer架构应用：</strong><br>  GPT-1（1.1亿参数）基于Transformer解码器架构，这一架构由Vaswani等人提出，使得模型能够并行处理序列数据，显著提升了训练效率和上下文捕捉能力。</li><li><strong>预训练与微调模式：</strong><br>  模型先进行无监督预训练（基于大规模文本数据学习语言规律），再通过有监督微调适应具体任务。这种“预训练-微调”范式为后续大规模语言模型提供了重要思路。</li></ul><p><img src="/img/0318-2.png" alt="Lena"></p><hr><h2 id="GPT-2：大规模生成能力的突破"><a href="#GPT-2：大规模生成能力的突破" class="headerlink" title="GPT-2：大规模生成能力的突破"></a>GPT-2：大规模生成能力的突破</h2><ul><li><strong>规模扩展：</strong><br>  GPT-2（15亿参数）在参数数量和训练数据上大幅超过GPT-1，令模型能捕捉更丰富的语言细节与长距离依赖关系。</li><li><strong>零样本泛化：</strong><br>  GPT-2展示了在未经过任务特定微调的情况下，通过上下文提示即可完成多种任务的能力，这种零样本（zero-shot）学习能力证明了规模扩展带来的意外收益。</li><li><strong>文本生成质量：</strong><br>  得益于大规模预训练，GPT-2能够生成连贯、逻辑性较强的长文本，使得生成结果在流畅性和一致性上有了质的飞跃。<br><img src="/img/0318-3.png" alt="Lena"></li></ul><hr><h1 id="大模型"><a href="#大模型" class="headerlink" title="大模型"></a>大模型</h1><h2 id="GPT-3：超大规模与少量学习的飞跃"><a href="#GPT-3：超大规模与少量学习的飞跃" class="headerlink" title="GPT-3：超大规模与少量学习的飞跃"></a>GPT-3：超大规模与少量学习的飞跃</h2><ul><li><strong>参数规模激增：</strong><br>  GPT-3拥有高达1750亿个参数，相较于GPT-2的规模增长，使得模型在捕捉语言特征和知识储备上更为强大。</li><li><strong>少量学习（Few-shot&#x2F;In-context Learning）：</strong><br>  GPT-3能够通过提供少量示例（甚至在零样本情况下）理解任务需求，直接在提示中学习如何完成任务，大大降低了对专门微调的依赖。</li><li><strong>多任务能力：</strong><br>  模型展示了在翻译、问答、摘要等多种任务中的出色表现，尽管在事实准确性和细节一致性上仍有改进空间。</li></ul><hr><h2 id="OpenAI-Codex"><a href="#OpenAI-Codex" class="headerlink" title="OpenAI Codex"></a>OpenAI Codex</h2><ul><li><p><strong>主要特点</strong></p><ul><li><strong>代码生成专长：</strong> Codex 是在 GPT‑3 模型的基础上，针对编程任务进行专门微调的版本。它不仅能理解自然语言描述，还能将这些描述转换成多种编程语言（如 Python、JavaScript、Go 等）的代码，广泛应用于 GitHub Copilot 等工具中。</li><li><strong>多语言支持：</strong> 除了常用编程语言，Codex 还能处理多种脚本和查询语言，帮助开发者快速补全代码或生成代码片段。</li></ul></li><li><p><strong>核心技术</strong></p><ul><li><strong>Transformer 架构：</strong> 基于标准 Transformer 解码器，利用自注意力机制捕捉代码中的语法和语义关系。</li><li><strong>大规模预训练与微调：</strong> 预训练阶段在海量互联网文本上进行，随后通过大量 GitHub 上公开代码数据进行微调，专门针对编程任务进行优化。</li><li><strong>指令调优与 RLHF：</strong> 结合指令微调技术，使得模型能更好地理解用户的编程指令，并通过基于人类反馈的强化学习（RLHF）进一步优化生成质量。</li></ul></li></ul><hr><h3 id="GPT‑3-5"><a href="#GPT‑3-5" class="headerlink" title="GPT‑3.5"></a>GPT‑3.5</h3><ul><li><p><strong>主要特点</strong></p><ul><li><strong>自然语言理解与生成：</strong> GPT‑3.5 是 GPT‑3 的升级版，在文本生成、对话和多任务学习上有了显著提升，能够更准确地遵循用户指令，实现零样本和少样本学习。</li><li><strong>对话优化：</strong> 其在对话场景下表现尤为出色，是目前 ChatGPT 背后的核心模型之一。</li><li><strong>多任务适应性：</strong> 无论是文本创作、问题回答还是代码生成，GPT‑3.5 都表现出较强的泛化能力和灵活性。</li></ul></li><li><p><strong>核心技术</strong></p><ul><li><strong>Transformer 解码器架构：</strong> 依然采用基于 Transformer 的结构，使其具备强大的上下文捕捉和长距离依赖建模能力。</li><li><strong>大规模预训练：</strong> 利用海量文本数据进行预训练，获得广泛的世界知识。</li><li><strong>指令微调和 RLHF：</strong> 通过在微调阶段使用指令数据以及人类反馈（RLHF），进一步提高了模型对用户指令的响应准确性和生成内容的安全性。</li><li><strong>链式思维（Chain-of-Thought）：</strong> 部分应用中引入了链式思维技术，增强了复杂问题的推理能力。</li></ul></li></ul><hr><h2 id="GPT-4：多模态能力与高质量对齐新时代"><a href="#GPT-4：多模态能力与高质量对齐新时代" class="headerlink" title="GPT-4：多模态能力与高质量对齐新时代"></a>GPT-4：多模态能力与高质量对齐新时代</h2><ul><li><strong>多模态输入：</strong><br>  GPT-4不仅支持文本，还能处理图像等其他模态的信息，实现跨模态的理解与生成，为更多实际应用场景提供可能。</li><li><strong>强化学习与人类反馈（RLHF）：</strong><br>  结合强化学习和人类反馈对模型进行精细调优，使输出更准确、更符合人类期望，同时有效降低了有害或不准确信息的生成风险。</li><li><strong>高级推理与安全性改进：</strong><br>  GPT-4在复杂问题的逻辑推理、深度理解等方面有显著提升，并在生成过程中加强了安全性与一致性，提升了模型的整体可靠性。</li><li><strong>应用拓展：</strong><br>  得益于多模态能力与更高效的对齐策略，GPT-4在学术研究、商业应用以及跨领域创新上都展现出更广泛的潜力。<br><img src="/img/0318-4.png" alt="Lena"></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><strong>基础架构革新：</strong> 从最初的Transformer架构，到预训练与微调的策略，为语言模型的发展奠定了坚实基础。</li><li><strong>规模与数据驱动：</strong> 随着参数规模的不断扩大和训练数据量的激增，模型在语言生成和理解上的能力呈指数级提升。</li><li><strong>少量学习与零样本能力：</strong> GPT-3引入的少量学习和上下文学习能力，使得模型在面对未知任务时展现出强大的适应性。</li><li><strong>多模态与安全对齐：</strong> GPT-4不仅扩展了输入维度，还通过RLHF等技术显著提升了输出质量和安全性，为未来AI的应用开辟了新方向。</li></ul><p>整体而言，从GPT-1到GPT-4，每一代模型都在架构、训练策略、数据规模以及对齐技术上取得了重要突破，推动了自然语言处理领域不断向前发展。</p><hr><h3 id="o‑系列模型"><a href="#o‑系列模型" class="headerlink" title="o‑系列模型"></a>o‑系列模型</h3><ul><li><p><strong>主要特点</strong></p><ul><li><strong>专注推理与决策：</strong> o‑系列模型（如 o1、o3‑mini 等）是 Azure OpenAI 服务中针对高阶推理和问题解决任务设计的模型。这些模型不仅能够生成自然语言，还侧重于结构化输出和复杂问题的逻辑推理。</li><li><strong>多模态能力：</strong> 部分 o‑系列模型支持多模态输入（例如文本和图像），这使得它们在跨领域任务和视觉理解方面具备优势。</li><li><strong>高效低延迟：</strong> 经过专门优化，o‑系列在响应速度和资源利用上表现突出，适合需要实时反馈的应用场景。</li></ul></li><li><p><strong>核心技术</strong></p><ul><li><strong>优化的 Transformer 架构：</strong> 在基础 Transformer 架构上，o‑系列模型通常会引入专门的改进（如混合专家模型、部分激活机制）以增强推理能力。</li><li><strong>预训练与定向微调：</strong> 利用大规模预训练数据，并在后续通过针对性微调和 RLHF 进行强化，使模型在复杂推理和任务规划上更为精准。</li><li><strong>多模态输入处理：</strong> 对于支持图像输入的版本，融合了视觉模块和文本生成模块，实现了跨模态信息的统一处理。</li><li><strong>结构化输出和工具调用：</strong> o‑系列模型支持生成结构化数据（如 JSON 格式），并能与外部工具进行交互，辅助完成复杂决策和任务规划。</li></ul></li></ul><p><img src="/img/0318-5.png" alt="Lena"></p><h2 id="DeepSeek系列模型的技术演进"><a href="#DeepSeek系列模型的技术演进" class="headerlink" title="DeepSeek系列模型的技术演进"></a>DeepSeek系列模型的技术演进</h2><h3 id="DeepSeek-V1"><a href="#DeepSeek-V1" class="headerlink" title="DeepSeek-V1"></a>DeepSeek-V1</h3><p><strong>发布时间</strong>：2024 年初<br><strong>主要特点</strong></p><ul><li><strong>基础复现与数据处理</strong>：DeepSeek-V1 延续了 LLaMA2 的稠密（Dense）Transformer 架构，重点在于利用高质量、经严格去重、过滤和混洗的数据（共计约 2 万亿 Token 中英双语数据）来做 Scaling Laws 实验，打牢基础。</li><li><strong>注意力机制</strong>：7B 模型采用标准的多头注意力（MHA），而 67B 模型则使用 Grouped-Query Attention (GQA) 来降低 KV 缓存的内存开销，从而降低推理成本。</li></ul><p><strong>局限性</strong></p><ul><li>模型在生成响应时容易重复、幻觉现象明显，对敏感信息的处理也未达到最优水平。</li></ul><hr><h3 id="DeepSeek-V2"><a href="#DeepSeek-V2" class="headerlink" title="DeepSeek-V2"></a>DeepSeek-V2</h3><p><strong>发布时间</strong>：2024 年 5 月左右<br><strong>主要特点</strong></p><ul><li><strong>架构升级：从 Dense 到 MoE</strong><ul><li>引入了 Mixture of Experts (MoE) 架构，大幅提升了计算效率。MoE 通过只激活部分专家模块，使得每个 token 仅激活少数参数（例如，激活 21B 参数而非全部 236B），大幅降低显存占用。</li><li>同时引入了多头潜在注意力（Multi-Head Latent Attention，MLA），利用低秩压缩技术来减少 KV 缓存需求，从而加速推理速度。</li></ul></li><li><strong>成本优势</strong><ul><li>DeepSeek-V2 在训练成本上表现更优，其经济性使得每输出百万个 Token 的成本大幅低于传统大模型。</li></ul></li><li><strong>性能提升</strong><ul><li>在保持或超越同类模型性能的同时，通过 MoE 和 MLA 架构在效率和成本上均取得显著优势。</li></ul></li></ul><hr><h3 id="DeepSeek-V3"><a href="#DeepSeek-V3" class="headerlink" title="DeepSeek-V3"></a>DeepSeek-V3</h3><p><strong>发布时间</strong>：2024 年 12 月<br><strong>主要特点</strong></p><ul><li><strong>大规模参数与高效训练</strong><ul><li>模型参数达 671B（其中每个 token 激活约 37B 参数），在 V2 的基础上进一步扩大规模，同时保持较低的训练成本（约 5.58 百万美元）。</li></ul></li><li><strong>核心技术延续与提升</strong><ul><li>继续采用 V2 的 MoE 架构和 MLA 技术，并在此基础上整合了 FP8 混合精度训练、无辅助损失的负载均衡策略以及多 Token 预测（MTP）技术，使得训练效率和推理速度得到进一步提升。</li></ul></li><li><strong>扩展上下文窗口</strong><ul><li>利用高效的上下文扩展技术（例如 YaRN），将模型的上下文窗口从传统的 4K 扩展至 128K甚至更长，适用于长文本生成和复杂任务。<br><img src="/img/0318-6.png" alt="Lena"></li></ul></li></ul><hr><h3 id="DeepSeek-R1（包括-R1-Zero-与-R1）"><a href="#DeepSeek-R1（包括-R1-Zero-与-R1）" class="headerlink" title="DeepSeek-R1（包括 R1-Zero 与 R1）"></a>DeepSeek-R1（包括 R1-Zero 与 R1）</h3><p><strong>发布时间</strong>：2025 年 1 月<br><strong>主要特点</strong></p><ul><li><strong>专注推理能力</strong><ul><li>R1 系列模型在 V3-Base 架构的基础上，通过引入纯强化学习（RL）来进一步激发模型的推理和逻辑自我纠正能力。其中 R1-Zero 完全使用 Group Relative Policy Optimization (GRPO) 算法进行 RL 训练，而不依赖于监督微调（SFT）。</li></ul></li><li><strong>奖励系统设计</strong><ul><li>采用基于规则的奖励系统，包括准确性奖励（检查数学答案、代码测试结果等）和格式奖励（强制将思考过程置于特定标记内）。此外，为了解决语言混合和响应不一致的问题，进一步加入了“语言一致性奖励”。</li></ul></li><li><strong>冷启动数据与多阶段训练</strong><ul><li>为应对 RL 早期的不稳定性，R1 引入了“冷启动”数据：先用少量高质量长链推理数据对模型进行 SFT，再通过 RL 进行强化训练，最终实现了模型在数学、代码和复杂推理任务上与 OpenAI o1 相媲美的性能。</li></ul></li><li><strong>知识蒸馏</strong><ul><li>基于 R1 生成的高质量推理数据，还推出了多个经过蒸馏的小模型（如基于 LLaMA、Qwen 等），使得在资源受限的环境下也能部署具有强大推理能力的模型。<br><img src="/img/0318-7.png" alt="Lena"></li></ul></li></ul><hr><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><ul><li><strong>从 V1 到 V2</strong>：DeepSeek 首先在 V1 中通过数据清洗和基础架构复现（LLaMA2 风格）奠定基础，随后在 V2 中引入 MoE 和 MLA 技术，实现了从全激活 Dense 模型向稀疏激活模型的转变，大幅降低了训练和推理成本，同时提高了效率。</li><li><strong>从 V2 到 V3</strong>：在 V3 中，DeepSeek 在保持 V2 架构优势的基础上，通过扩大参数规模、优化混合精度训练（FP8）、改进负载均衡和引入多 Token 预测技术，使得模型性能和上下文处理能力大幅提升，接近甚至媲美封闭模型的水平。</li><li><strong>从 V3 到 R1</strong>：R1 系列通过纯 RL（GRPO 算法）和精心设计的奖励体系，在 V3-Base 的基础上进一步增强了模型的推理和逻辑自我纠正能力，同时结合冷启动数据和多阶段训练，解决了语言混合、可读性差等问题，最终形成了适用于专业领域的高性能推理模型。知识蒸馏技术则将这种强大推理能力迁移到小型模型上，便于广泛部署。</li></ul><p>这种技术演进展示了 DeepSeek 如何在有限资源和严苛成本约束下，通过算法与架构创新不断突破大模型的性能瓶颈，逐步实现从通用文本生成到复杂逻辑推理的跨越，最终挑战国际顶尖水平。<br>我们后面几期会着重讲讲这篇文章出现到的一些重要技术。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 人工智能通识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型技术基础</title>
      <link href="/2025/03/15/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/"/>
      <url>/2025/03/15/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="大模型的构建预览"><a href="#大模型的构建预览" class="headerlink" title="大模型的构建预览"></a>大模型的构建预览</h1><p><strong>定义</strong>：通常是指具有超大规模参数的预训练语言模型<br><strong>架构</strong>：主要为Transformer解码器架构<br><strong>训练</strong>：主要分为预训练（base model） 后训练（instruct model）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">A[预训练]--&gt;|海量文本数据 + 预测下一词| B(建立模型基础能力)</span><br><span class="line">B --&gt;|大量指令数据 + SFT/RL| C(增强模型的任务能力)</span><br><span class="line">C --&gt;|instruct model| D[下游应用]</span><br></pre></td></tr></table></figure><p> <strong>预训练</strong>：使用与下游任务无关的大规模数据进行模型参数的初始训练。基于transformer解码器架构，进行下一个词预测。数据数量和质量都非常关键。<br> <strong>后训练</strong>：又分为两种：指令微调和人类对齐</p><ul><li><strong>指令微调</strong>：使用输入与输出配对的指令数据对于模型进行微调，提升模型通过问答形式进行任务求解的能力。<br>  <img src="/img/0315-1.png" alt="Lena"></li><li><strong>人类对齐</strong>：将大语言模型与人类的期望、需求以及价值观对齐；基于人类反馈的强化学习方法 <strong>（RLHF）</strong></li></ul><p><img src="/img/0315-2.png" alt="Lena"></p><h1 id="扩展定律基础概念"><a href="#扩展定律基础概念" class="headerlink" title="扩展定律基础概念"></a>扩展定律基础概念</h1><p>扩展定律（Scaling Law）揭示了语言模型性能与模型规模、数据量及计算资源之间的数学关系，其核心是<strong>幂律法则</strong>​（Power Law）。随着模型参数量（N）、训练数据量（D）和计算量（C）的增加，模型损失（Loss）呈现指数级下降，但边际效益逐渐递减。<br><strong>通过扩展参数规模、数据规模和计算能力，大语言模型的能力会出现显著提升，扩展定律在本次大模型浪潮中起到了重要作用。</strong><br><img src="/img/0315-3.png" alt="Lena"></p><h2 id="​核心公式："><a href="#​核心公式：" class="headerlink" title="​核心公式："></a>​<strong>核心公式</strong>：</h2><p>$L(N,D)&#x3D;L_0​+k⋅N^{−α}+m⋅D^{−β}$</p><ul><li>​<strong>L0​</strong>：数据固有噪声带来的不可约损失</li><li>​<strong>α 和 β</strong>：参数和数据对损失的衰减系数（通常 α≈0.07, β≈0.27）</li></ul><hr><h2 id="KM扩展定律与Chinchilla扩展定律对比"><a href="#KM扩展定律与Chinchilla扩展定律对比" class="headerlink" title="KM扩展定律与Chinchilla扩展定律对比"></a>KM扩展定律与Chinchilla扩展定律对比</h2><h3 id="​KM扩展定律（OpenAI-2020）​"><a href="#​KM扩展定律（OpenAI-2020）​" class="headerlink" title="​KM扩展定律（OpenAI, 2020）​"></a>​<strong>KM扩展定律（OpenAI, 2020）​</strong></h3><ul><li>​<strong>核心发现</strong>：在计算预算约束下，优先扩大模型参数（N）而非数据量（D），参数增长比数据扩展更有效。</li><li>​<strong>公式推导</strong>：$L(N)∝N^{−0.07},L(D)∝D^{−0.27}$</li><li>​<strong>应用场景</strong>：早期大模型（如GPT-3）通过堆叠参数（175B参数+300B tokens）实现突破，但存在<strong>数据饥饿</strong>风险。<br><img src="/img/0315-4.png" alt="Lena"></li></ul><h3 id="​Chinchilla扩展定律（DeepMind-2022）​"><a href="#​Chinchilla扩展定律（DeepMind-2022）​" class="headerlink" title="​Chinchilla扩展定律（DeepMind, 2022）​"></a>​<strong>Chinchilla扩展定律（DeepMind, 2022）​</strong></h3><p>DeepMind团队再2022年提出了另一种形式的扩展定律，旨在指导大模型充分利用给定的算力资源优化训练。</p><ul><li>​<strong>核心修正</strong>：模型参数与数据需<strong>同步扩展</strong>，最佳比例为 D≈20N（如70B参数模型需1.4T tokens）。</li><li>​<strong>关键突破</strong>：<ul><li>Chinchilla（70B参数+1.4T tokens）性能超越GPT-3（175B参数+300B tokens）。</li><li>计算资源分配更高效，训练成本降低30%。</li></ul></li><li>​<strong>现实意义</strong>：纠正了盲目扩大参数的趋势，推动模型小型化与高效训练。<br><img src="/img/0315-5.png" alt="Lena"><br><strong>扩展定律可能存在边际效益递减</strong> ：随着模型参数、数据数量的扩展，模型性能增益将逐渐减小。目前开放数据已经接近枯竭，难以支持扩展定律持续推进。</li></ul><hr><h2 id="可预测的扩展（Predictable-Scaling）"><a href="#可预测的扩展（Predictable-Scaling）" class="headerlink" title="可预测的扩展（Predictable Scaling）"></a>可预测的扩展（Predictable Scaling）</h2><p>可预测的扩展是通过扩展定律<strong>提前估算模型性能</strong>的技术，避免大规模试错成本。其实现路径包括：</p><h3 id="​数学建模与对数线性回归"><a href="#​数学建模与对数线性回归" class="headerlink" title="​数学建模与对数线性回归"></a>​<strong>数学建模与对数线性回归</strong></h3><ul><li><strong>使用小规模实验（如7B参数模型）预测大模型（65B）性能，误差可控制在2%以内。</strong></li><li>​<strong>案例</strong>：Meta Llama团队通过7B模型预测65B模型的困惑度（PPL）。<br><img src="/img/0315-6.png" alt="Lena"></li></ul><h3 id="数据瓶颈的量化分析"><a href="#数据瓶颈的量化分析" class="headerlink" title="数据瓶颈的量化分析"></a><strong>数据瓶颈的量化分析</strong></h3><ul><li>当前公共高质量英文语料年增量仅3T tokens，接近饱和（利用率达98%），需依赖<strong>合成数据</strong>与多模态扩展。</li><li>​<strong>应对策略</strong>：通过数据蒸馏（如DeepSeek使用GPT生成合成数据）突破数据瓶颈。</li></ul><h3 id="​训练动态的可控性"><a href="#​训练动态的可控性" class="headerlink" title="​训练动态的可控性"></a>​<strong>训练动态的可控性</strong></h3><ul><li>​<strong>临界模型规模</strong>：研究发现，将模型缩小至计算最优规模的30%，仅需增加100%计算量即可维持性能，为小型化提供理论依据。</li><li>​<strong>超参数预测</strong>：学习率与训练步长的动态调整公式（如 $LR&#x3D;0.003−0.0002⋅log_{10}​(N)$）。</li></ul><hr><h2 id="扩展定律的实践启示"><a href="#扩展定律的实践启示" class="headerlink" title="扩展定律的实践启示"></a>扩展定律的实践启示</h2><ol><li>​<strong>资源分配</strong>：根据任务需求选择扩展策略——KM适合快速突破，Chinchilla适合长期优化。</li><li>​<strong>成本控制</strong>：通过可预测扩展估算最小可行模型规模，避免算力浪费（如LLaMA-7B在1T tokens训练后仍有优化空间）。</li><li>​<strong>技术融合</strong>：结合强化学习（RLHF）与多模态扩展，突破单一扩展维度限制（如GPT-4V的图文推理能力）。</li></ol><h1 id="涌现能力"><a href="#涌现能力" class="headerlink" title="涌现能力"></a>涌现能力</h1><p>涌现能力（Emergent Abilities）是指当大规模语言模型（如GPT-3、BERT等）的参数规模达到一定阈值后，模型在没有明确训练或设计的情况下，自发地展现出一些高级或复杂的技能或行为。这些能力不是直接编程或显式训练的结果，而是模型通过学习大量数据并在内部形成复杂的表示和结构后自然而然地出现的。<strong>“小模型中不存在，但在大模型中出现的能力”</strong><br><img src="/img/0315-7.png" alt="Lena"></p><h2 id="涌现能力的特点"><a href="#涌现能力的特点" class="headerlink" title="涌现能力的特点"></a>涌现能力的特点</h2><ol><li>​<strong>非显式训练</strong>：模型并未针对特定任务进行专门训练，却能执行这些任务。例如，语言模型可能在没有接受翻译训练的情况下生成准确的翻译文本。</li><li>​<strong>复杂性和多模态性</strong>：涌现能力涉及多层次的抽象和多种类型的数据处理，如语言理解、逻辑推理、数学计算等。</li><li>​<strong>自适应性</strong>：模型能够根据上下文和任务需求灵活调整行为，例如对话系统在不同场景下进行适当回应。</li></ol><h2 id="代表性能力的种类"><a href="#代表性能力的种类" class="headerlink" title="代表性能力的种类"></a>代表性能力的种类</h2><ol><li>​<strong>上下文学习（In-Context Learning）​</strong>：模型通过少量示例（demonstrations）快速适应新任务，无需额外训练。例如，GPT-3仅通过几个示例就能完成翻译、总结等任务。 <img src="/img/0315-8.png" alt="Lena"></li><li>​<strong>进步推理（Chain of Thought Reasoning）​</strong>：模型能够进行多步逻辑推理，解决复杂的数学或逻辑问题。例如，通过“思维链提示”（Chain of Thought Prompting）策略，模型逐步推理出答案。<br><img src="/img/0315-9.png" alt="Lena"></li><li>​<strong>指令遵循（Instruction Following）​</strong>：模型能够理解并执行复杂的指令，例如根据用户指令生成特定格式的文本或完成特定任务。<br><img src="/img/0315-10.png" alt="Lena"></li></ol><h2 id="涌现能力与扩展定律的关系"><a href="#涌现能力与扩展定律的关系" class="headerlink" title="涌现能力与扩展定律的关系"></a>涌现能力与扩展定律的关系</h2><p>扩展定律（Scaling Law）揭示了模型性能与模型规模（参数数量N）、数据量（D）和计算量（C）之间的幂律关系。随着模型规模的增加，性能呈指数级提升，但涌现能力在达到某一临界规模后突然出现，无法通过小规模模型的性能外推预测。</p><p>具体来说：</p><ul><li>​<strong>规模效应</strong>：当模型参数规模超过某一阈值（如数十亿参数），涌现能力会突然显现。例如，GPT-3在175B参数规模下展现出上下文学习和进步推理能力。</li><li>​<strong>非线性提升</strong>：涌现能力的出现与模型规模的增加呈非线性关系，表现为“相变”现象：在临界规模之前，性能接近随机；超过临界规模后，性能显著提升。</li><li>​<strong>扩展定律的局限性</strong>：扩展定律可以预测模型性能的平滑提升，但无法预测涌现能力的出现，因为涌现能力是模型规模、数据量和计算量综合作用的结果。<br><img src="/img/0315-11.png" alt="Lena"><br>总结来说，涌现能力是大规模语言模型在达到一定规模后展现出的高级能力，其出现与扩展定律密切相关，但具有不可预测性和非线性特征。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 大模型系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prompt-最大程度榨干大模型</title>
      <link href="/2025/03/13/Prompt-%E6%9C%80%E5%A4%A7%E7%A8%8B%E5%BA%A6%E6%A6%A8%E5%B9%B2%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2025/03/13/Prompt-%E6%9C%80%E5%A4%A7%E7%A8%8B%E5%BA%A6%E6%A6%A8%E5%B9%B2%E5%A4%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Prompt万能模板-x3D-立角色-述问题-定目标-补需求"><a href="#Prompt万能模板-x3D-立角色-述问题-定目标-补需求" class="headerlink" title="Prompt万能模板 &#x3D; 立角色 + 述问题 + 定目标 + 补需求"></a>Prompt万能模板 &#x3D; 立角色 + 述问题 + 定目标 + 补需求</h1><p>在编写 Prompt 时，从0到1地编写出第一版 Prompt 往往是最难的，而基于已有 Prompt 利用各种技巧进行优化则相对简单。如上图所示，我们使用了一套 “万能模版”，把一个 Prompt 拆分成了 “立角色 + 述问题 + 定目标 + 补要求” 这四个部分，利用这个模版可以得到一个“及格”的 Prompt。下面我就具体和大家阐述一下这个模版是如何得到的，为什么他是有效的。</p><p>Prompt 的作用就是根据我们的问题调用模型的能力，我们要通过提问的方式，明确的让模型知道我们想要什么，我们的目标是什么，从这个基本思想出发，Prompt 应该包含以下几点：<br>问题是什么，你要做什么，有什么要求。</p><ol><li><p>问题是什么：首先你要告诉模型你的问题是什么，你的任务是什么，要尽量描述清楚你的需求。</p></li><li><p>你要做什么：下面你需要告诉大模型具体要做什么，比如做一份攻略，写一段代码，对文章进行优化，等等。</p></li><li><p>有什么要求：最后我们往往还需求对任务补充一些要求，比如按特定格式输出，规定长度限制，只输出某些内容，等等。</p></li></ol><p>通这 3 部分的描述我们就把 “要大模型做什么” 描述清楚了，这个想法十分自然，即便不是大模型，而是希望其他人为你完成某项任务，往往也需要通过这 3 部分把问题描述清楚。由于这仅仅是第一版 Prompt，你不需要描述的过于详细，也不需要使用技巧，只需要用简练的语言把这几部分描述清晰即可。</p><h2 id="问题是什么"><a href="#问题是什么" class="headerlink" title="问题是什么"></a>问题是什么</h2><p>我们现在要做一个云小课的 app，类似于 mooc 这样的一个学习平台，他的服务对象是医疗方面从业者（医学生，护士，护士长，医生），云小课的 MVP 版本要在一个星期内做出来，所以一开始不需要很多复杂的功能，但是有几个核心功能需要在 MVP 版本上线，1. 课件生成视频，2. 视频生成课件，3. 视频出题，4. 视频观看体验（加字幕、分小节+课程大纲等）5. 核心业务流程(产品)a. 发起者分享小课到小课的群内或者微信群&#x2F;个人b. 群内人学习：过程AI干预、数据AI统计分析6. 后台管理（课件、用户、数据），现在你需要帮我理<strong>清楚页面结构，哪些页面有哪些功能。</strong><br><strong>（注意到我上买你不仅用序号编排了顺序还用了字母，让ai明白了功能上的一个层级结构）</strong></p><p>大模型会给你一个还不错的结果，这个结果他帮你把页面层级理清了，就比如这样：</p><h3 id="​核心页面架构（共8大模块）"><a href="#​核心页面架构（共8大模块）" class="headerlink" title="​核心页面架构（共8大模块）"></a>​核心页面架构（共8大模块）</h3><p><strong>首页（课程广场）​</strong></p><ul><li>​<strong>智能推荐区</strong>：AI根据用户身份（医学生&#x2F;医生&#x2F;护士长）推荐急救技能、病例解析等垂直内容</li><li>​<strong>课程分类导航</strong>：按「手术操作」「护理规范」「医学影像」「职称考试」等医疗专题分类</li><li>​<strong>热门课程排行榜</strong>：显示24小时学习量TOP10的临床教学课程</li><li>​<strong>快速创建入口</strong>：悬浮按钮直达「创建小课」功能</li></ul><p><strong>课程创建页</strong></p><ul><li><p>_课件生成视频_：</p><ul><li>支持上传PPT&#x2F;PDF（自动转视频）</li><li>AI语音合成医学专业术语（可切换男&#x2F;女声医学发音）</li><li>视频分段标记（自动识别PPT章节生成时间轴）</li></ul></li><li><p>_视频生成课件_：</p><ul><li>手术录像智能提取关键帧生成图文课件</li><li>自动标注医疗仪器名称（如内窥镜型号识别）<br><strong>视频学习页</strong></li></ul></li><li><p>​<strong>医疗专用播放器</strong>：</p><ul><li>双字幕系统（主字幕+医学名词术语解释浮层）</li><li>章节导航（支持按「术前准备」「操作步骤」「术后处理」跳转）</li></ul></li><li><p>_视频出题模块_：</p><ul><li>AI在关键操作节点弹出选择题（如「此处应选择几号缝合线？」）</li><li>病理图片标注题（标记CT影像病灶区域）</li></ul></li></ul><p><strong>学习群组页</strong></p><ul><li>_分享流程_：<ul><li>支持将课程生成带医院LOGO的H5页面</li><li>微信群嵌入AI助教（自动@未完成学习者）</li></ul></li><li>_AI干预系统_：<ul><li>学习进度看板（护士长可查看组员完成率）</li><li>智能错题提醒（针对高频错误操作推送补充资料）</li></ul></li></ul><p><strong>个人中心</strong></p><ul><li>​<strong>医疗身份认证</strong>：执业医师&#x2F;护士资格证上传核验</li><li>学习档案：<ul><li>CME学分统计（符合继续医学教育要求）</li><li>手术操作熟练度雷达图（AI评估技能短板）</li></ul></li></ul><p><strong>后台管理系统</strong></p><ul><li>_医疗内容审核_：<ul><li>敏感词过滤（药品名称合规性检查）</li><li>专家评审流程（三甲医院主任医师审核权限）</li></ul></li><li>数据看板：<ul><li>学习热力图（显示各科室活跃时段）</li><li>医疗事故关联分析（标记高风险操作学习记录）</li></ul></li></ul><hr><h2 id="你要做什么"><a href="#你要做什么" class="headerlink" title="你要做什么"></a>你要做什么</h2><p>下面一步就是你要做什么，在功能梳理好之后，你就需要告诉大模型你想要的页面效果，做到详细，限定好范围。这一步可以用上黄金法则：<strong>立角色 + 述问题 + 定目标 + 补要求</strong> </p><ol><li><p>​<strong>立角色</strong><br> 明确AI的「身份」，激活其专业能力包。<br> ✅ 示例：<br> <em>“你现在是拥有10年经验的高级软件工程师，精通代码重构和设计模式，曾成功优化多个大型遗留系统。”</em> </p></li><li><p>​<strong>述问题</strong></p><ul><li><p>​<strong>任务拆解</strong>：将复杂需求拆分为子任务（如开发用户注册功能时拆解为数据模型设计、验证逻辑等）</p></li><li><p>​<strong>背景补充</strong>：提供代码片段、需求文档等上下文信息<br>  ✅ 示例：<br>  <em>“我需要开发一个用户注册功能，包含以下子任务：1.设计用户数据模型；2.实现防机器人注册策略…”</em></p></li></ul><p> </p></li><li><p>​<strong>定目标</strong><br> 定义清晰的输出标准，避免开放式提问。<br> ✅ 示例：<br> <em>“生成的代码需满足：①遵循SOLID原则；②包含单元测试；③提供API文档”</em> </p></li><li><p>​<strong>补要求</strong></p><ul><li>​<strong>格式规范</strong>：如<em>“使用Markdown格式，代码块标注语言类型”</em> </li><li>​<strong>约束条件</strong>：<em>“避免解释性文字，仅输出JSON格式结果”</em></li></ul></li></ol><p> </p><p>下面来看看我的Prompt：</p><p>1.产品界面规划：你是一个经验丰富的UI设计师，现在需要你根据页面结构定义关键界面，确保信息架构合理 <strong>(立角色)</strong><br>2.用户体验分析：先分析这个 App 的主要功能和用户需求，确定核心交互逻辑。**(立角色)**<br>3.高保真 UI 设计，作为 UI 设计师，设计贴近真ios&#x2F;Android 设计规范的界面，使用现代化的 UI 元素，使其具有良好的视觉体验。<strong>（立角色)</strong></p><p><strong>这里插一句话，在ui设计的地方可以告诉大模型你对标的是哪一款应用的ui，大模型会根据你的偏好生成更适合你的风格，比如：小红书风格，知乎风格，Netflix风格等等。</strong></p><p>4.HTML 原型实现：使用 HTML + Tailwind CSS （或者 Bootstrap）生成所有原型界面，并使用 FontAwesome（或其他 UI 组件）让界面更加精美，洁净真实的 APP 设计。拆分代码文件，保持结构清晰 <strong>(定目标)</strong></p><p>5.每个界面应作为独立的 HTML 文件存放，例如home.html,profile.html,settings.html 等。</p><ul><li><p>index.html 作为主入口，不直接写入所有界面的 HTML 代码、而是使用 iframe 的方式嵌入这些 HTML 片段，并将所有页面平铺展示在 index 页面中，而不是跳转链接。<strong>（述问题）</strong></p></li><li><p>真实感增强<strong>（述问题）</strong>：</p><ul><li>界面尺寸模拟 iPhone15 pro，并让界面圆角化，使其更像真实的手机界面。</li><li>使用真实的 UI 图片，而非占位符（可从 Unsplsh、Pexels、Apple 官方 UI 资源中选择）</li><li>添加顶部状态栏（模拟 ios 状态栏），并包含 App 导航栏（类似 ios 底部 TarBar）<br>  请按照以上要求生成完整的 HTML 代码，并确保其可以用于实际开发。<strong>（补要求）</strong></li></ul><p>  最终得到的效果如图：<img src="/img/0314-1.png" alt="Lena"></p></li></ul><p><strong>其中我个人认为立角色和补要求是最为重要的，因为有研究显示大模型在接受prompt的过程中，对于开头和结尾的内容更加关注，attention权重更高。</strong></p><p>一个好的prompt + 一个好的工具（cursor） &#x3D;&gt; 一个好的作品</p><p>如果你觉得是巧合，你可以用同样的方法生成一个好的后台管理系统的原型图。</p><p> 企业级后台原型设计需求说明书<br>  产品界面规划：<strong>作为UI设计师</strong>，定义关键界面，确保信息架构合理。生成高保真 UI 设计，设计贴近真实 网页页面设计规范的界面，使用现代化的 UI 元素，使其具有良好的视觉体验。 1. ​<strong>项目背景定位</strong> 系统类型：B端管理系统（如CRM&#x2F;ERP&#x2F;数据中台）用户角色：管理员（80%）、审核员（15%）、访客（5%）设计规范：参照Ant Design Pro 5.0&#x2F;TDesign 4.0设计系统 2. ​<strong>核心功能规划</strong> - ▸ 全局导航：三级菜单（主菜单240px + 子菜单200px） - ▸ 数据看板：支持ECharts&#x2F;D3.js动态可视化（含实时刷新） - ▸ 表格系统： 列配置记忆（LocalStorage）  虚拟滚动（10万+数据处理） - ▸ 权限体系：RBAC权限颗粒度控制（按钮级） 3. ​<strong>视觉规范定义</strong> 主题色系：#1677FF（主色）+ 5级灰度体系 字体方案：HarmonyOS Sans（中文字体） + Inter（英文字体） 组件库：Ant Design Pro Table&#x2F;ProForm 高级组件 4. ​<strong>技术实现要求</strong> 开发框架：Vue3 + Vite5 &#x2F; React18 + Next.js 样式方案：Tailwind CSS 4.0（JIT模式）交互增强： * 骨架屏加载动画数据加载延≥300ms时触发 *错误边界处理（全局捕获React&#x2F;Vue错误） 使用真实的 UI 图片，而非占位符（可从 Unsplsh、Pexels、Apple 官方 UI 资源中选择） <strong>请按照以上要求生成完整的 HTML 代码，并确保其可以用于实际开发。</strong></p><p>效果如下：<br><img src="/img/0313-1.png" alt="Lena"></p><p><img src="/img/0313-2.png" alt="Lena"><br>可以看到效果还是不错，若想再丰富一点可以后续补要求。</p>]]></content>
      
      
      <categories>
          
          <category> 前沿 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能通识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型发展历程</title>
      <link href="/2025/03/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/"/>
      <url>/2025/03/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="大语言模型发展与应用全景解析"><a href="#大语言模型发展与应用全景解析" class="headerlink" title="大语言模型发展与应用全景解析"></a>大语言模型发展与应用全景解析</h1><hr><h2 id="语言模型发展历程"><a href="#语言模型发展历程" class="headerlink" title="语言模型发展历程"></a>语言模型发展历程</h2><h3 id="早期统计语言模型（1950s-2000s）"><a href="#早期统计语言模型（1950s-2000s）" class="headerlink" title="早期统计语言模型（1950s-2000s）"></a>早期统计语言模型（1950s-2000s）</h3><ul><li>​<strong>规则系统探索</strong><br>1966年MIT开发的首个聊天机器人ELIZA采用模式匹配规则<a href="@ref">1</a>，1970年代SHRDLU系统展示早期语义理解能力，但依赖人工规则编写<a href="@ref">1</a>。</li><li>​<strong>统计方法兴起</strong><br>1990年代n-gram模型通过计算n元词组联合概率预测文本，隐马尔可夫模型（HMM）推动语音识别发展<a href="@ref">2</a>。此时模型受限于语料库规模（通常仅百万级）和长距离依赖捕捉能力<a href="@ref">3</a>。</li></ul><p>统计语言模型（Statistical Language Model, SLM）. 在 20 世纪 90 年代兴起的统计语言模型 [4, 5] 是基于统计学习方法研发的。具体来说，统计语言模型使用马尔可夫假设（Markov Assumption）来建立语言序列的预测模型，通常是根据词序列中若干个连续的上下文单词来预测下一个词的出现概率，即根据一个固定长度的前缀来预测目标单词。具有固定上下文长度 𝑛 的统计语言模型通常被称为 𝑛 元（𝑛-gram）语言模型，如二元或三元语言模型。统计语言模型被广泛应用于信息检索<br>（Information Retrieval, IR）和自然语言处理（Natural Language Processing, NLP）等领域的早期研究工作。对于高阶统计语言模型来说，随着阶数 𝑛 的增加，需要估计的转移概率项数将会指数级增长，经常会受到“维数灾难”（Curse of Dimensionality）的困扰。为了缓解数据稀疏问题，需要设计专门的语言模型平滑策略，如回退估计（Back-off Estimation）和古德-图灵估计（Good-Turing Estimation）。然而平滑方法对于高阶上下文的刻画能力仍然较弱，无法精确建模复杂的高阶语义关系。</p><h3 id="神经网络语言模型（2010-2017）"><a href="#神经网络语言模型（2010-2017）" class="headerlink" title="神经网络语言模型（2010-2017）"></a>神经网络语言模型（2010-2017）</h3><ul><li>​<strong>词向量革命</strong><br>Google 2013年提出Word2Vec，通过Skip-gram&#x2F;CBOW算法实现语义向量化，突破传统词袋模型局限<a href="@ref">2,4</a>。</li><li>​<strong>序列模型演进</strong><br>LSTM（1997提出，2010s普及）解决RNN梯度消失问题，支持200+词距记忆<a href="@ref">1</a>；2015年Seq2Seq架构推动机器翻译突破<a href="@ref">2</a>。</li></ul><p>神经语言模型（Neural Language Model, NLM）. 神经语言模型 [6, 7] 使用神经网络来建模文本序列的生成，如循环神经网络（Recurrent Neural Networks, RNN）。图1.1 语言模型的发展历程灵奖获得者 Yoshua Bengio 在一项早期工作中 [6] 引入了分布式词表示（DistributedWordRepresentation）这一概念，并构建了基于聚合上下文特征（即分布式词向量）的目标词预测函数。分布式词表示使用低维稠密向量来表示词汇的语义，这与基于词典空间的稀疏词向量表示（One-Hot Representation）有着本质的不同，能够刻画更为丰富的隐含语义特征。同时，稠密向量的非零表征对于复杂语言模型的搭建非常友好，能够有效克服统计语言模型中的数据稀疏问题。分布式词向量又称为“词嵌入”（Word Embedding）。这种基于隐含语义特征表示的语言建模方法为自然语言处理任务提供了一种较为通用的解决途径。在这一系列工作中，word2vec [8,9] 是一个具有代表性的词嵌入学习模型，它构建了一个简化的浅层神经网络来学习分布式词表示，所学习到的词嵌入可以用作后续任务的语义特征提取器，在自然语言处理任务中得到了广泛使用，取得了显著的性能提升。这些创新性的研究工作将语言模型用于文本表示学习（超越了原始的词序列建模目标），在自然语言<br>处理领域产生了重要影响。<br><img src="/img/LLM-img1.png" alt="Lena"></p><h3 id="Transformer与预训练模型（2017-2019）"><a href="#Transformer与预训练模型（2017-2019）" class="headerlink" title="Transformer与预训练模型（2017-2019）"></a>Transformer与预训练模型（2017-2019）</h3><ul><li>​<strong>架构革命</strong><br>2017年Transformer通过多头自注意力机制实现全局依赖捕捉，训练速度比LSTM快10倍<a href="@ref">4,9</a>。BERT（2018）采用掩码语言模型（MLM）实现双向理解，GLUE基准分数提升7%-15%<a href="@ref">1,3</a>。</li><li>​<strong>预训练范式确立</strong><br>GPT-1（2018）首次验证自回归预训练有效性，T5（2019）统一NLP任务为text-to-text框架<a href="@ref">3,6</a>。<br><img src="/img/LLM-img2.png" alt="Lena"><br>且不容易并行训练，这些缺点限制了早期预训练模型（如 ELMo）的性能。在 2017年，谷歌提出了基于自注意力机制（Self-Attention）的 Transformer 模型 [12]，通过自注意力机制建模长程序列关系。Transformer 的一个主要优势就是其模型设计对于硬件非常友好，可以通过 GPU 或者 TPU 进行加速训练，这为研发大语言模型提供了可并行优化的神经网络架构。基于 Transformer 架构，谷歌进一步提出了预训练语言模型 BERT [13]，采用了仅有编码器的 Transformer 架构，并通过在大规模<br>无标注数据上使用专门设计的预训练任务来学习双向语言模型。在同期，OpenAI也迅速采纳了 Transformer 架构，将其用于 GPT-1 [14] 的训练。与 BERT 模型不同的是，GPT-1 采用了仅有解码器的 Transformer 架构，以及基于下一个词元预测的预训练任务进行模型的训练。一般来说，编码器架构被认为更适合去解决自然语言理解任务（如完形填空等），而解码器架构更适合解决自然语言生成任务（如文本摘要等）。以 ELMo、BERT、GPT-1 为代表的预训练语言模型确立了“预训练-微<br>调”这一任务求解范式。其中，预训练阶段旨在通过大规模无标注文本建立模型的基础能力，而微调阶段则使用有标注数据对于模型进行特定任务的适配，从而更好地解决下游的自然语言处理任务。</li></ul><h3 id="大语言模型时代（2020-至今）"><a href="#大语言模型时代（2020-至今）" class="headerlink" title="大语言模型时代（2020-至今）"></a>大语言模型时代（2020-至今）</h3><ul><li><p>​<strong>规模跃迁</strong><br>GPT-3（2020）达1750亿参数，零样本任务准确率较GPT-2提升40%<a href="@ref">5</a>；PaLM（2022）5400亿参数实现复杂数学推理<a href="@ref">12</a>。</p></li><li><p>​<strong>能力涌现</strong><br>GPT-4（2023）在Bar考试中超越90%人类考生，DeepSeek-R1（2025）支持128K上下文窗口和671B参数<a href="@ref">4,6</a>。</p></li><li><p>​<strong>开源生态</strong><br>LLaMA（2023）、ChatGLM（清华）等模型推动技术民主化，Qwen2.5支持1M token超长文本处理<a href="@ref">6,10</a>。</p></li><li><p><strong>具有较为丰富的世界知识</strong>： 与传统机器学习模型相比，大语言模型经过超大<br>规模文本数据的预训练后能够学习到较为丰富的世界知识。</p></li><li><p><strong>具有较强的通用任务解决能力</strong> ：大语言模型第二个代表性的能力特点是具有<br>较强的通用任务求解能力。</p></li><li><p><strong>具有较好的复杂任务推理能力</strong>. 除了具有通用性外，大语言模型在复杂任务<br>中还展现出了较好的推理能力。</p></li><li><p><strong>具有较强的人类指令遵循能力</strong>： 大语言模型建立了自然语言形式的统一任务<br>解决模式：任务输入与执行结果均通过自然语言进行表达。</p></li><li><p><strong>具有较好的人类对齐能力</strong>. 机器学习模型的安全性一直以来是一个重要的研<br>究课题。</p></li><li><p><strong>具有可拓展的工具使用能力</strong>：在机器学习领域，模型的设计和实现往往都具<br>有一定的局限性，例如会受到所采用的归纳假设以及训练数据的限制。<br>规模文本数据的预训练后能够学习到较为丰富的世界知识。</p></li></ul><hr><h2 id="大语言模型核心特点"><a href="#大语言模型核心特点" class="headerlink" title="大语言模型核心特点"></a>大语言模型核心特点</h2><h3 id="超大规模参数体系"><a href="#超大规模参数体系" class="headerlink" title="超大规模参数体系"></a>超大规模参数体系</h3><ul><li>GPT-4达1.8万亿参数，DeepSeek-R1突破670B<a href="@ref">6,13</a></li><li>参数增长规律：性能随参数量呈幂律分布，每10倍参数带来3%-5%准确率提升<a href="@ref">7</a></li></ul><h3 id="训练范式创新"><a href="#训练范式创新" class="headerlink" title="训练范式创新"></a>训练范式创新</h3><ul><li>自监督预训练：使用TB级文本数据，通过MLM&#x2F;NSP任务构建语言先验知识<a href="@ref">8,9</a></li><li>三阶段训练：预训练 → 监督微调 → RLHF对齐，ChatGPT采用超百万级人类反馈数据<a href="@ref">3,12</a></li></ul><h3 id="泛化与涌现能力"><a href="#泛化与涌现能力" class="headerlink" title="泛化与涌现能力"></a>泛化与涌现能力</h3><ul><li>上下文学习（In-context Learning）：5-shot学习可使代码生成准确率从45%提升至78%<a href="@ref">3,13</a></li><li>跨模态涌现：GPT-4V实现图文联合推理，医疗影像诊断准确率达91%<a href="@ref">12,13</a></li></ul><h3 id="多模态扩展"><a href="#多模态扩展" class="headerlink" title="多模态扩展"></a>多模态扩展</h3><ul><li>视觉语言模型：BLIP-2通过Q-Former桥接视觉-语言特征空间<a href="@ref">8</a></li><li>视频处理：Sora模型（2024）实现分钟级视频生成，时空注意力机制是关键突破<a href="@ref">13</a></li></ul><hr><h2 id="关键技术突破"><a href="#关键技术突破" class="headerlink" title="关键技术突破"></a>关键技术突破</h2><h3 id="Transformer架构创新"><a href="#Transformer架构创新" class="headerlink" title="Transformer架构创新"></a>Transformer架构创新</h3><ul><li>多头注意力机制：8-64个注意力头并行计算，捕获语法&#x2F;语义&#x2F;语用多维度特征<a href="@ref">4,9</a></li><li>位置编码：相对位置编码（RoPE）提升长文本建模能力，支持32K+上下文<a href="@ref">6,10</a></li></ul><h3 id="训练优化技术"><a href="#训练优化技术" class="headerlink" title="训练优化技术"></a>训练优化技术</h3><ul><li>混合并行训练：Megatron-LM实现3D并行（数据+流水线+张量并行），万卡集群效率&gt;90%<a href="@ref">8,13</a></li><li>显存优化：ZeRO-Offload技术使单卡可训练130B模型<a href="@ref">8</a></li></ul><h3 id="对齐与安全"><a href="#对齐与安全" class="headerlink" title="对齐与安全"></a>对齐与安全</h3><ul><li>RLHF技术：Proximal Policy Optimization（PPO）算法平衡多样性与安全性<a href="@ref">5,12</a></li><li>Constitutional AI：通过AI监督实现价值观对齐，有害输出率降低10倍<a href="@ref">13</a></li></ul><h3 id="推理加速"><a href="#推理加速" class="headerlink" title="推理加速"></a>推理加速</h3><ul><li>量化压缩：GPTQ算法实现4bit量化，精度损失&lt;1%<a href="@ref">6</a></li><li>动态批处理：vLLM框架提升吞吐量3-5倍，支持连续批处理（Continuous Batching）<a href="@ref">8</a></li></ul><hr><h2 id="对科技发展的革命性影响"><a href="#对科技发展的革命性影响" class="headerlink" title="对科技发展的革命性影响"></a>对科技发展的革命性影响</h2><h3 id="技术融合创新"><a href="#技术融合创新" class="headerlink" title="技术融合创新"></a>技术融合创新</h3><ul><li>自动驾驶：Waymo融合语言模型实现自然语言交互式导航，意图识别准确率提升27%<a href="@ref">12</a></li><li>科学计算：AlphaFold3（2024）结合语言模型提升蛋白质相互作用预测精度<a href="@ref">13</a></li></ul><h3 id="产业升级路径"><a href="#产业升级路径" class="headerlink" title="产业升级路径"></a>产业升级路径</h3><ul><li>制造业：西门子工业大模型将设备维护工单生成效率提升60%<a href="@ref">11</a></li><li>金融：彭博GPT（2023）实现财经报告自动生成，错误率低于人工撰写<a href="@ref">12</a></li></ul><h3 id="社会变革挑战"><a href="#社会变革挑战" class="headerlink" title="社会变革挑战"></a>社会变革挑战</h3><ul><li>教育领域：可汗学院部署AI导师，学生数学成绩平均提升20%<a href="@ref">13</a></li><li>伦理风险：2024年全球AI伪造内容检测需求激增300%，催生数字水印技术标准<a href="@ref">11</a></li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文解读-CLIP:Learning Transferable Visual Models From Natural Language Supervision</title>
      <link href="/2025/03/10/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-CLIP-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision/"/>
      <url>/2025/03/10/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-CLIP-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision/</url>
      
        <content type="html"><![CDATA[<h1 id="论文总结：Learning-Transferable-Visual-Models-From-Natural-Language-Supervision"><a href="#论文总结：Learning-Transferable-Visual-Models-From-Natural-Language-Supervision" class="headerlink" title="论文总结：Learning Transferable Visual Models From Natural Language Supervision"></a>论文总结：Learning Transferable Visual Models From Natural Language Supervision</h1><h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><p>这篇论文主要探讨了如何通过自然语言监督来训练可迁移的视觉模型，提出了一种名为 <strong>CLIP</strong>（Contrastive Language-Image Pre-training，对比语言-图像预训练）的创新方法。传统的计算机视觉模型通常依赖于固定类别的监督训练，而 CLIP 通过利用互联网上大规模的图像-文本对数据，采用自然语言作为监督信号，实现了无需特定数据集训练即可在多种下游任务上进行零样本（zero-shot）迁移的能力。</p><hr><h2 id="核心算法"><a href="#核心算法" class="headerlink" title="核心算法"></a>核心算法</h2><p>CLIP 的核心算法基于 <strong>对比学习（Contrastive Learning）</strong>，具体步骤如下：</p><ol><li><strong>模型架构</strong>：<ul><li>CLIP 包含两个编码器：<ul><li><strong>图像编码器</strong>：可以是 ResNet 或 Vision Transformer（ViT），用于提取图像特征。</li><li><strong>文本编码器</strong>：基于 Transformer 的模型，用于提取文本特征。</li></ul></li><li>两个编码器将图像和文本映射到一个共享的多模态嵌入空间。</li></ul></li><li><strong>训练目标</strong>：<ul><li>在一个批次中，给定 N 个图像-文本对，CLIP 训练模型预测哪些图像和文本是配对的（N 个正确对），哪些不是（N²-N 个错误对）。</li><li>通过最大化正确配对的图像和文本嵌入之间的余弦相似度，最小化错误配对的相似度，使用对称交叉熵损失（Symmetric Cross-Entropy Loss）进行优化。</li></ul></li><li><strong>零样本分类</strong>：<ul><li>在测试时，利用文本编码器根据任务的类别名称生成分类器的权重，结合图像编码器的特征进行预测，无需额外训练。</li></ul></li></ol><p>这幅图用来概括 <strong>CLIP</strong> 算法的核心流程与框架，主要分为三个阶段：</p><p><img src="/img/CLIP-img1.png" alt="Lena"></p><ol><li><p><strong>对比学习预训练（Contrastive Pre-training）</strong></p><ul><li><strong>图像编码器</strong>和<strong>文本编码器</strong>分别将图像、文本输入映射为向量表示，然后在同一个嵌入空间中进行对比学习。</li><li>模型会最大化正确图文配对的相似度，最小化错误配对的相似度，从而让图像和对应文本在向量空间中“对齐”。</li></ul></li><li><p><strong>根据标签文本创建分类器（Create dataset classifier from label text）</strong></p><ul><li>在有下游数据集时，可以将每个类别的名称或描述（例如“dog”或“A photo of a dog.”）输入文本编码器，得到一组文本向量。</li><li>这相当于直接用文本生成了一个线性分类器的权重，无需对该数据集做额外微调或训练。</li></ul></li><li><p><strong>零样本预测（Use for zero-shot prediction）</strong></p><ul><li>对于一张新图像，先用<strong>图像编码器</strong>得到图像向量，再分别与各类别文本向量计算相似度，选取相似度最高的类别作为预测结果。</li><li>这种方法实现了<strong>零样本分类</strong>：不需要任何标注样本就能对新任务（数据集）做推断，因为类别信息是由文本描述来提供的。</li></ul></li></ol><p>总结来说，这张图描述了 CLIP 的核心思路：先用大规模的图文对进行对比学习，学到统一的图像-文本表示空间；然后在下游任务里，通过简单的文本提示（label text）来生成一个零样本分类器，直接进行推断。</p><h3 id="训练效率对比"><a href="#训练效率对比" class="headerlink" title="训练效率对比"></a><strong>训练效率对比</strong></h3><p><img src="/img/CLIP-img2.png" alt="Lena"></p><ul><li>​<strong>描述</strong>：比较不同训练目标（语言模型预测标题 vs. 对比学习）在零样本ImageNet分类上的效率。</li><li>​<strong>作用</strong>：证明对比学习目标（CLIP）比传统生成式目标（如预测标题）更高效，训练速度提升4倍。</li></ul><h3 id="CLIP伪代码核心思想"><a href="#CLIP伪代码核心思想" class="headerlink" title="CLIP伪代码核心思想"></a><strong>CLIP伪代码核心思想</strong></h3><p><img src="/img/CLIP-img3.png" alt="Lena"></p><p>这段伪代码设计了一个多模态学习框架，旨在通过对比学习的方法，将图像和文本的特征表示映射到一个统一的嵌入空间，使得匹配的图像-文本对具有高相似度，而不匹配的对具有低相似度。其核心思想可以概括为以下几点：</p><ol><li><strong>多模态特征提取</strong>：<ul><li>使用独立的编码器分别处理图像和文本数据，提取各自的特征表示。</li><li>图像编码器（如ResNet或Vision Transformer）和文本编码器（如CBOW或Text Transformer）的选择体现了灵活性，可以根据任务需求选用不同的模型。</li></ul></li><li><strong>共享嵌入空间的对齐</strong>：<ul><li>通过学习到的投影矩阵将图像和文本特征投影到一个共同的维度空间，并进行归一化处理。</li><li>这种对齐使得图像和文本的表示可以直接比较，从而支持跨模态任务。</li></ul></li><li><strong>相似度计算与对比损失</strong>：<ul><li>使用余弦相似度（通过点积计算）衡量图像和文本嵌入之间的相似性，并引入温度参数来调节相似度的分布。</li><li>通过对称的对比损失函数（contrastive loss）训练模型，使得匹配对的相似度被最大化，非匹配对的相似度被最小化。</li></ul></li><li><strong>端到端优化</strong>：<ul><li>整个模型通过一个统一的损失函数进行端到端训练，确保图像和文本编码器以及投影矩阵协同优化。</li></ul></li></ol><p>这种方法的核心在于利用对比学习的无监督特性，通过正样本（匹配对）和负样本（非匹配对）的对比，让模型自动学习图像和文本之间的语义关联，而无需显式的标签。</p><hr><h4 id="伪代码的逻辑步骤"><a href="#伪代码的逻辑步骤" class="headerlink" title="伪代码的逻辑步骤"></a>伪代码的逻辑步骤</h4><p>以下是伪代码中每个步骤背后的思想：</p><ol><li><strong>模型组件定义</strong>：<ul><li><strong>编码器选择</strong>：图像编码器（image_encoder）可以是ResNet或Vision Transformer，文本编码器（text_encoder）可以是CBOW或Text Transformer。这种灵活性允许模型适应不同的数据类型和任务需求。</li><li><strong>输入数据</strong>：图像输入为I[n, h, w, c]（批量大小为n，高度h，宽度w，通道数c），文本输入为T[n, l]（批量大小为n，序列长度为l）。这表明模型能够处理批量数据，提高训练效率。</li><li><strong>投影矩阵和温度参数</strong>：W[i,d,i]和W[t,d,t]是学习到的投影矩阵，用于将特征映射到共享空间；t是一个可学习的温度参数，用于控制相似度的尺度。</li></ul></li><li><strong>特征提取</strong>：<ul><li><strong>图像特征</strong>：I_f &#x3D; image_encoder(I)将图像输入编码为特征向量I_f，形状为[n, d_i]，其中d_i是图像特征的维度。</li><li><strong>文本特征</strong>：T_f &#x3D; text_encoder(T)将文本输入编码为特征向量T_f，形状为[n, d_t]，其中d_t是文本特征的维度。</li><li><strong>思想</strong>：这一步的目的是将原始的图像和文本数据转化为高维特征表示，捕捉各自模态的关键信息，为后续对齐做准备。</li></ul></li><li><strong>特征归一化与相似度计算</strong>：<ul><li><strong>投影与归一化</strong>：<ul><li>I_e &#x3D; l2_normalize(np.dot(I_f, W[i,d,i]), axis&#x3D;-1)：将图像特征I_f通过投影矩阵W[i,d,i]映射后进行L2归一化，得到I_e。</li><li>T_e &#x3D; l2_normalize(np.dot(T_f, W[t,d,t]), axis&#x3D;-1)：类似地，将文本特征T_f投影并归一化，得到T_e。</li><li>归一化确保特征向量位于单位超球面上，使得点积等价于余弦相似度，便于比较。</li></ul></li><li><strong>相似度计算</strong>：logits &#x3D; np.dot(I_e, T_e.T) * np.exp(t)计算图像嵌入I_e和文本嵌入T_e的转置之间的点积，并用指数化的温度参数np.exp(t)进行缩放。</li><li><strong>思想</strong>：通过余弦相似度和温度参数，模型能够量化每对图像和文本之间的关系，温度参数则调节了相似度分布的“锐度”，影响正负样本的区分度。</li></ul></li><li><strong>对比损失函数</strong>：<ul><li><strong>标签生成</strong>：loss_i &#x3D; np.arange(n)生成一个索引数组，用于标识匹配对（对角线元素）。</li><li><strong>双向损失</strong>：<ul><li>loss_i &#x3D; cross_entropy_loss(logits, labels, axis&#x3D;0)：以图像为查询，文本为目标，计算图像到文本方向的交叉熵损失。</li><li>loss_t &#x3D; cross_entropy_loss(logits, labels, axis&#x3D;1)：以文本为查询，图像为目标，计算文本到图像方向的交叉熵损失。</li><li>loss &#x3D; (loss_i + loss_t) &#x2F; 2：最终损失取两个方向损失的平均值。</li></ul></li><li><strong>思想</strong>：这种对称损失设计确保模型在图像到文本和文本到图像两个方向上都学习到一致的对齐关系，增强了跨模态表示的鲁棒性。</li></ul></li></ol><h4 id="总体思想与应用"><a href="#总体思想与应用" class="headerlink" title="总体思想与应用"></a>总体思想与应用</h4><p>伪代码的总体思想是通过对比学习构建一个多模态模型，将图像和文本表示对齐到一个共享嵌入空间。其关键创新在于：</p><ul><li><strong>灵活性</strong>：支持多种编码器选择（如ResNet、Vision Transformer、CBOW、Text Transformer），适应不同任务和数据集。</li><li><strong>对比学习</strong>：利用正负样本的对比，无需显式标签即可学习跨模态关联。</li><li><strong>温度参数</strong>：通过可学习的 t调节相似度分布，提升模型的区分能力。</li></ul><p>这种方法在实际应用中非常强大，例如：</p><ul><li><strong>图像-文本检索</strong>：给定文本查询返回相关图像，或给定图像查询返回相关文本。</li><li><strong>零样本分类</strong>：利用文本描述对未见过类别的图像进行分类。</li><li><strong>视觉问答</strong>：结合图像和文本回答问题。</li></ul><hr><h3 id="零样本CLIP-vs-全监督基线"><a href="#零样本CLIP-vs-全监督基线" class="headerlink" title="零样本CLIP vs. 全监督基线"></a><strong>零样本CLIP vs. 全监督基线</strong></h3><p><img src="/img/CLIP-img4.png" alt="Lena"></p><ul><li>​<strong>描述</strong>：在27个数据集上，零样本CLIP与基于ResNet-50特征的全监督线性分类器的性能对比。</li><li>​<strong>作用</strong>：证明零样本CLIP在多数任务上优于传统监督方法，展示了自然语言监督的泛化能力。</li></ul><hr><h3 id="模型规模与性能关系"><a href="#模型规模与性能关系" class="headerlink" title="模型规模与性能关系"></a><strong>模型规模与性能关系</strong></h3><p><img src="/img/CLIP-img5.png" alt="Lena"></p><ul><li>​<strong>描述</strong>：不同规模的CLIP模型（从ResNet-50到ViT-L&#x2F;14）在零样本任务上的性能随计算量增长的规律。</li><li>​<strong>作用</strong>：证明模型性能随计算量和数据规模平滑提升，符合“缩放定律”（scaling law）。<br>展示了CLIP模型在零样本学习（Zero-shot Learning）任务中的性能如何随着计算能力（以GFLOPs为单位）的增加而变化。零样本学习是指模型在没有针对特定任务进行训练的情况下，仅通过自然语言描述完成任务的能力。这种评估方法关注模型的泛化能力和对新任务的适应性。</li></ul><p>图表的主要内容包括：</p><ul><li><strong>X轴</strong>：模型的计算能力（GFLOPs），范围从6.1到265.9 GFLOPs。</li><li><strong>Y轴</strong>：零样本任务的错误率（Error %），范围从25%到45%，错误率越低表示性能越好。</li><li><strong>数据点</strong>：展示了不同ResNet模型配置（RN50、RN101、RN50x4、RN50x16、RN50x64）的性能。</li><li><strong>趋势线</strong>：一条平滑的蓝色曲线，显示错误率随着计算能力增加而下降。</li><li><strong>置信区间</strong>：趋势线周围的浅蓝色阴影，表示性能数据的变异范围。</li></ul><h4 id="模型评估方法"><a href="#模型评估方法" class="headerlink" title="模型评估方法"></a>模型评估方法</h4><p>图表通过 <strong>零样本学习性能</strong> 来评估模型，具体测量的是CLIP模型在未经过任务特定训练的情况下，在多种任务上的错误率。这种方法强调：</p><ul><li><strong>泛化能力</strong>：模型能否在未见过的数据或任务上表现良好。</li><li><strong>适应性</strong>：模型通过自然语言提示适应新任务的能力。</li></ul><p>评估覆盖了 <strong>36个数据集上的39项任务</strong>，这表明结果具有一定的广泛性和代表性，能够反映模型在不同场景下的表现。</p><h4 id="性能分析要点"><a href="#性能分析要点" class="headerlink" title="性能分析要点"></a>性能分析要点</h4><p>图表揭示了模型性能与计算能力之间的关系，以下是具体分析：</p><ol><li><strong>计算能力与性能的关系</strong><ul><li>随着计算能力（GFLOPs）增加，零样本错误率呈现 <strong>平滑下降趋势</strong>。</li><li>具体数据：<ul><li><strong>RN50</strong>（6.1 GFLOPs）：错误率约为42%。</li><li><strong>RN101</strong>（9.9 GFLOPs）：错误率约为40%。</li><li><strong>RN50x4</strong>（21.5 GFLOPs）：错误率约为37%。</li><li><strong>RN50x16</strong>（75.3 GFLOPs）：错误率约为32%。</li><li><strong>RN50x64</strong>（265.9 GFLOPs）：错误率约为29%。</li></ul></li><li>从最小的RN50（6.1 GFLOPs）到最大的RN50x64（265.9 GFLOPs），计算能力增加了约44倍，错误率从42%下降到29%，降低了约13个百分点。</li></ul></li><li><strong>趋势线的特性</strong><ul><li>趋势线显示计算能力与错误率之间存在 <strong>对数-对数线性关系</strong>。这意味着性能提升是可预测的，随着计算能力增加，错误率以对数形式逐渐减小。</li><li>这种平滑的趋势表明，模型性能的提升与计算能力的扩展密切相关，且不存在明显的性能瓶颈或突变。</li></ul></li><li><strong>置信区间与变异性</strong><ul><li>趋势线周围的浅蓝色阴影表示 <strong>置信区间</strong>，反映了性能数据的变异性。</li><li>尽管整体趋势平滑，但阴影的存在说明在具体任务或数据集上，模型性能可能会有波动。这提示我们，个体评估的结果可能受到任务复杂性或数据集特性等其他因素的影响。</li></ul></li><li><strong>模型架构的影响</strong><ul><li>图表中的数据点对应不同的ResNet模型变体（如RN50、RN101等），这些模型在架构上有所不同，但计算能力是性能提升的关键驱动因素。</li><li>例如，RN50x64相比RN50增加了更多的计算单元（可能是更深的层或更宽的通道），显著提升了性能。</li></ul></li></ol><h4 id="图表的核心结论"><a href="#图表的核心结论" class="headerlink" title="图表的核心结论"></a>图表的核心结论</h4><p>这张图表说明了以下几点关于CLIP模型的评估和性能：</p><ol><li><strong>性能的可扩展性</strong><ul><li>随着计算能力的增加，零样本性能持续提升，且提升趋势平滑、可预测。这表明CLIP模型具有良好的可扩展性，增加计算资源（如更大的模型规模）可以有效提高性能。</li></ul></li><li><strong>计算能力的重要性</strong><ul><li>计算能力是影响零样本性能的关键因素。从RN50到RN50x64，计算能力提升直接带来了错误率的下降，验证了“更大模型更好”的假设。</li></ul></li><li><strong>性能变异性的存在</strong><ul><li>尽管整体趋势清晰，但置信区间的阴影表明，模型在不同任务上的表现并非完全一致。某些任务可能因数据分布或任务难度而表现出更高的错误率。</li></ul></li><li><strong>广泛的适用性</strong><ul><li>评估覆盖了39项任务和36个数据集，说明CLIP模型在多种场景下都具备一定的零样本能力，体现了其泛化能力。</li></ul></li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>这张图表在模型评估和性能分析方面说明了：<br>CLIP模型的零样本性能随着计算能力（GFLOPs）的增加而平滑提升，从错误率42%降低到29%，显示出良好的可扩展性和预测性。评估方法聚焦于零样本学习，测试模型在未训练任务上的泛化能力，覆盖了36个数据集的39项任务。性能与计算能力之间呈现对数-对数线性关系，表明计算能力是提升性能的关键驱动因素。然而，置信区间显示了个体任务性能的变异性，提示具体表现可能受任务或数据集特性影响。总体而言，图表表明通过增加计算资源，CLIP模型能够显著提高零样本任务的准确性，同时保持较强的适应性。</p><hr><h3 id="分布偏移鲁棒性"><a href="#分布偏移鲁棒性" class="headerlink" title="分布偏移鲁棒性"></a><strong>分布偏移鲁棒性</strong></h3><p><img src="/img/CLIP-img6.png" alt="Lena"></p><p>这张图主要展示了 <strong>零样本 CLIP 模型</strong> 和 <strong>标准 ImageNet 训练模型</strong> 在遇到分布偏移（distribution shift）时的表现差异，体现出以下几个关键点：</p><ol><li><p><strong>纵轴：在 ImageNet 上的准确率</strong><br> 横坐标是模型在新分布（比如 ImageNetV2、ImageNet-R、ObjectNet 等各种自然分布偏移数据集）上的准确率，纵坐标则是它们在原始 ImageNet 验证集上的准确率。</p></li><li><p><strong>理想的鲁棒模型基准线</strong><br> 图中用一条“基准线”表示「如果一个模型在 ImageNet 上表现为 x%，那么在分布偏移的数据集上大约能达到多少准确率」。若模型点落在这条线附近，就意味着它在分布偏移场景的表现与其 ImageNet 准确率相匹配；若点落在此线之下，说明它在分布偏移时比预期表现更差；而点在此线之上，则表示它比通常的 ImageNet 模型更鲁棒。</p></li><li><p><strong>零样本 CLIP 更加鲁棒</strong></p><ul><li>相比于常规的 ImageNet 训练模型（图中灰色或蓝色标记），零样本 CLIP（绿色标记）在横坐标（新分布准确率）上显著高于同等 ImageNet 准确率的模型。</li><li>这意味着：<strong>当分布改变时，CLIP 的准确率下降幅度更小</strong>，也就是它在各种真实场景下更具「有效鲁棒性（effective robustness）」。</li></ul></li><li><p><strong>性能差距缩小</strong></p><ul><li>具体而言，作者发现零样本 CLIP 能将标准模型在分布偏移下的性能损失最多减少 75%（文中所说“robustness gap”被缩小了约 3&#x2F;4）。</li><li>这说明在完全未见过下游分布的情况下，CLIP 的表现仍能保持相对较高水准，显著优于只在 ImageNet 监督下训练的模型。</li></ul></li></ol><p>简言之，<strong>这张图突出了零样本 CLIP 在应对新数据分布或偏移场景时比传统 ImageNet 模型更具鲁棒性</strong>。它不太依赖 ImageNet 上的“局部”模式或偏差，而是通过自然语言监督学习到更通用、能更好适应分布变化的视觉特征。</p><hr><h2 id="核心思路"><a href="#核心思路" class="headerlink" title="核心思路"></a>核心思路</h2><p>CLIP 的核心思路是将自然语言作为一种灵活且广泛的监督信号，替代传统的固定类别标签：</p><ul><li><strong>大规模数据利用</strong>：通过从互联网收集 4 亿个图像-文本对（WebImageText，WIT 数据集），提供丰富的监督信息。</li><li><strong>任务无关性</strong>：不像传统模型针对特定任务预训练，CLIP 通过对比学习在预训练阶段学习广泛的视觉概念，能够通过自然语言提示（prompt）直接适配新任务。</li><li><strong>零样本迁移</strong>：利用自然语言的描述能力，CLIP 可以在没有见过训练数据的情况下，通过文本描述完成分类任务。</li></ul><hr><h2 id="做了什么事"><a href="#做了什么事" class="headerlink" title="做了什么事"></a>做了什么事</h2><p>论文中，作者进行了以下主要工作：</p><ol><li><strong>数据集构建</strong>：<ul><li>创建了 WIT 数据集，包含 4 亿个图像-文本对，覆盖广泛的视觉概念。</li></ul></li><li><strong>模型训练与扩展</strong>：<ul><li>训练了多个 CLIP 模型，包括基于 ResNet 和 Vision Transformer 的变体，计算规模跨度达两个数量级。</li><li>对比了不同预训练方法（如生成式 vs 对比式）的效率，选择了对比学习作为最终方法。</li></ul></li><li><strong>性能评估</strong>：<ul><li>在超过 30 个现有计算机视觉数据集上测试了 CLIP 的零样本迁移性能，涵盖 OCR、动作识别、地理定位、细粒度分类等多种任务。</li><li>与全监督基线（如 ResNet-50）和已有零样本方法（如 Visual N-Grams）进行了对比。</li></ul></li><li><strong>鲁棒性与偏差分析</strong>：<ul><li>研究了 CLIP 在自然分布偏移（distribution shift）下的鲁棒性。</li><li>分析了模型的社会偏差（bias），特别是在人脸分类和监控任务中的表现。</li></ul></li><li><strong>代码与模型公开</strong>：<ul><li>发布了代码和预训练模型权重（<a href="https://github.com/OpenAI/CLIP%EF%BC%89%E3%80%82">https://github.com/OpenAI/CLIP）。</a></li></ul></li></ol><hr><h2 id="总结出的结论"><a href="#总结出的结论" class="headerlink" title="总结出的结论"></a>总结出的结论</h2><p>通过实验和分析，论文得出了以下主要结论：</p><ol><li><strong>高效性与可扩展性</strong>：<ul><li>CLIP 证明了通过自然语言监督预训练是学习高质量图像表示的一种高效、可扩展的方法，性能随着计算量增加呈平滑可预测的提升。</li></ul></li><li><strong>零样本性能</strong>：<ul><li>在大多数任务中，CLIP 的零样本性能与全监督基线相当，甚至在某些任务（如 ImageNet）上达到原始 ResNet-50 的水平，且无需使用其 128 万训练样本。</li></ul></li><li><strong>广泛适用性</strong>：<ul><li>CLIP 在预训练中学到了多种任务能力（如 OCR、地理定位、动作识别），表现出较强的任务无关性。</li></ul></li><li><strong>鲁棒性提升</strong>：<ul><li>零样本 CLIP 比同等精度的 ImageNet 监督模型在自然分布偏移下更鲁棒，缩小了分布内与分布外的性能差距。</li></ul></li><li><strong>局限性与改进空间</strong>：<ul><li>CLIP 在某些复杂任务（如细粒度分类、计数）上表现较弱，对真正分布外的 generalization 能力有限。</li><li>数据效率仍需改进，需结合自监督或自训练方法。</li></ul></li><li><strong>社会影响</strong>：<ul><li>CLIP 的灵活性可能带来潜在的社会风险（如监控中的滥用、偏差放大），需要进一步研究和规范。</li></ul></li></ol><hr><h2 id="总体评价"><a href="#总体评价" class="headerlink" title="总体评价"></a>总体评价</h2><p>CLIP 开启了利用自然语言监督训练通用视觉模型的新范式，其零样本迁移能力和对大规模互联网数据的利用展示了巨大的潜力。然而，其在特定任务上的不足和潜在的社会影响也提示了未来研究的方向，包括提升数据效率、减少偏差和设计更公平的应用方式。</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前沿技术解读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文解读-Agent AI: Surveying the Horizons of Multimodal Interaction</title>
      <link href="/2025/03/07/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-Agent-AI-Surveying-the-Horizons-of-Multimodal-Interaction/"/>
      <url>/2025/03/07/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-Agent-AI-Surveying-the-Horizons-of-Multimodal-Interaction/</url>
      
        <content type="html"><![CDATA[<h1 id="Agent-AI-Surveying-the-Horizons-of-Multimodal-Interaction"><a href="#Agent-AI-Surveying-the-Horizons-of-Multimodal-Interaction" class="headerlink" title="Agent AI: Surveying the Horizons of Multimodal Interaction"></a><strong>Agent AI: Surveying the Horizons of Multimodal Interaction</strong></h1><p>简介：探讨如何构建更具交互性的多模态系统，通过结合不同模态的专家模型和工具，支持动态决策、任务规划及多agent协同，从而实现更智能的交互体验。</p><h2 id="核心主题"><a href="#核心主题" class="headerlink" title="核心主题"></a>核心主题</h2><p>提出”Agent AI”概念——<strong>基于多模态交互的智能体系统</strong>，旨在通过将大型基础模型（LLMs&#x2F;VLMs）嵌入物理&#x2F;虚拟环境，构建具备环境感知、任务规划、记忆推理能力的通用智能体框架。</p><h2 id="核心算法与技术"><a href="#核心算法与技术" class="headerlink" title="核心算法与技术"></a>核心算法与技术</h2><h3 id="Agent-Transformer架构"><a href="#Agent-Transformer架构" class="headerlink" title="Agent Transformer架构"></a>Agent Transformer架构</h3><ul><li>​<strong>多模态统一处理</strong>：整合视觉token、语言token和动作token</li><li>​<strong>知识记忆机制</strong>：通过外部知识库增强环境理解</li><li>​<strong>分层决策流程</strong>：</li></ul><p>环境感知 → 任务规划 → 记忆检索 → 动作生成 → 认知反馈</p><h3 id="核心学习方法"><a href="#核心学习方法" class="headerlink" title="核心学习方法"></a>核心学习方法</h3><ul><li>​**强化学习(RL)**：结合环境反馈优化策略</li><li>​**模仿学习(IL)**：通过专家示范数据解耦任务目标</li><li>​**上下文学习(In-context Learning)**：利用少量示例快速适应新任务</li><li>​<strong>持续学习机制</strong>：通过人类反馈和生成数据实现自我进化</li></ul><h2 id="核心创新思路"><a href="#核心创新思路" class="headerlink" title="核心创新思路"></a>核心创新思路</h2><ul><li>​<strong>混合现实交互范式</strong>：结合物理环境感知与虚拟场景生成</li><li>​<strong>知识引导的协同机制</strong>：通过外部知识库减少大模型幻觉</li><li>​<strong>分层任务分解</strong>：LLM负责高层规划，专用模块处理底层控制</li><li>​<strong>多智能体协作框架</strong>：建立自动化的协作评分机制（Collaboration Score）</li></ul><h2 id="主要研究工作"><a href="#主要研究工作" class="headerlink" title="主要研究工作"></a>主要研究工作</h2><h3 id="理论框架构建"><a href="#理论框架构建" class="headerlink" title="理论框架构建"></a>理论框架构建</h3><h4 id="提出Agent-AI的系统架构（图5）"><a href="#提出Agent-AI的系统架构（图5）" class="headerlink" title="提出Agent AI的系统架构（图5）"></a>提出Agent AI的系统架构（图5）</h4><p><img src="/img/Agent-img5.png" alt="Lena"><br>从这张图可以看出，整个多模态通用智能体（Agent）主要由以下几个关键部分构成，并且彼此之间通过闭环交互的方式来协同工作：</p><ol><li><p><strong>环境（Environment）与控制器（Controller）&#x2F;动作（Action）回路</strong></p><ul><li>最左侧是“环境（Environment）”，智能体需要从环境中获取信息、执行动作并对环境产生影响。</li><li>“控制器（Controller）”根据智能体的高层决策或计划来控制具体的动作（Action），再将动作施加到环境中，从而完成闭环。</li><li>这部分相当于智能体与外部世界交互的物理或数字接口，类似于机器人执行器、传感器，或者软件环境中的API调用等。</li></ul></li><li><p><strong>感知（Perception）与任务规划&#x2F;技能观测（Task-Planning and Skill Observation）</strong></p><ul><li>从环境获取的各种模态数据（视觉、听觉、文本、传感器数据等）先进入“感知（Perception）”模块。</li><li>这里会进行必要的预处理、特征提取，或者识别和理解外部信息，为后续认知决策做准备。</li><li>任务规划&#x2F;技能观测部分可以看作在感知层或与感知紧密结合，用于根据环境信息和当前任务，识别所需技能、规划下一步行动，或监测已有技能在执行中的效果。</li></ul></li><li><p><strong>认知（Cognition）</strong></p><ul><li>这是整个系统的核心决策与思考模块，图中标注了“Thinking, Consciousness, Sensing, Empathy, overall Cognitive System”等关键词，说明它不仅包含逻辑推理、问题求解，也包括更高级别的意识、感知与情感交互等。</li><li>认知模块会综合感知得到的信息、记忆中存储的知识，以及学习模块提供的模型或推断结果，来进行判断、推理和决策。</li><li>同时，它会与“记忆（Memory）”和“学习（Learning）”模块进行双向交互，形成一个持续迭代、动态更新的闭环。</li></ul></li><li><p><strong>记忆（Memory）</strong></p><ul><li>记忆模块主要存储知识、逻辑规则、推理过程以及各种经验（“Knowledge, Logic, Reasoning, Inference”）。</li><li>可以理解为智能体的知识库或长短期记忆库。</li><li>认知模块在决策或规划时，会从记忆中检索相关知识，也会将新的经验或学习到的信息写入记忆，实现不断累积和更新。</li></ul></li><li><p><strong>学习（Learning）</strong></p><ul><li>学习模块可进行“预训练（Pretraining）”、“零样本&#x2F;少样本学习（Zero-shot, Few-shot）”等，来自于大语言模型（LLM）或视觉语言模型（VLM）等多模态模型。</li><li>通过学习模块，智能体可以利用已有的大规模预训练模型快速适应新任务，或者从少量数据中提炼新技能。</li><li>该模块和认知、记忆之间是交互的：认知会调用学习模块来获取更好的模型或推断结果，学习的产出又会存储在记忆中，供后续使用。</li></ul></li><li><p><strong>Agent 交互闭环（Agent Interactive Closed-loop）</strong></p><ul><li>这张图强调了智能体的闭环特性：<ol><li>从环境感知 -&gt;</li><li>认知进行决策和推理（结合记忆与学习）-&gt;</li><li>通过控制器执行动作到环境 -&gt;</li><li>环境再反馈给感知，形成循环。</li></ol></li><li>在这个循环过程中，智能体不断地根据环境变化、内部记忆和学习到的新知识，更新自身的决策策略，逐步提升对任务的完成度和对环境的适应能力。</li></ul></li></ol><p>总体而言，这个架构将<strong>感知、认知、记忆、学习、行动</strong>等要素整合在一起，通过与环境的交互来实现多模态任务处理和通用智能。认知模块在系统中起到“大脑”的作用，记忆模块相当于知识库或长短期记忆仓库，而学习模块则是模型训练、知识更新的动力来源，所有这些在环境交互中形成一个不断循环迭代的闭环。</p><h4 id="定义Agent-Transformer的数学模型"><a href="#定义Agent-Transformer的数学模型" class="headerlink" title="定义Agent Transformer的数学模型"></a>定义Agent Transformer的数学模型</h4><p><img src="/img/Agent-img7.png" alt="Lena"><br> <strong>Agent Transformer 结构解析</strong></p><p>根据图片描述，​<strong>Agent Multi-modal Transformer</strong> 是一个<strong>统一的多模态端到端模型</strong>，核心目标是通过<strong>Agent Tokens</strong>​（代理标记）引导模型在特定领域（如机器人学）中实现代理行为（如决策、动作生成）。其架构设计可分为以下关键模块：</p><hr><p> ​<strong>1. 输入层：多模态统一编码</strong></p><ul><li>​<strong>输入向量类型</strong>：<ul><li>​<strong>Agent Tokens</strong>：专用标记，用于<strong>引导模型执行代理行为</strong>​（例如机器人动作指令、环境交互策略）。</li><li>​<strong>Visual Tokens</strong>：视觉输入（图像&#x2F;视频&#x2F;3D场景）的编码，可能基于ViT或动态分辨率编码器。</li><li>​<strong>Language Tokens</strong>：语言指令或描述的嵌入表示，通常通过LLM（如GPT系列）编码。</li></ul></li><li>​<strong>统一编码策略</strong>：<ul><li>所有模态的Token通过<strong>共享的嵌入层</strong>映射到同一隐空间，消除模态差异。</li><li>​<strong>动态位置编码</strong>：支持可变长度的多模态输入（如图像+文本+动作指令的组合）。</li></ul></li></ul><hr><p> ​<strong>2. 核心处理层：跨模态注意力融合</strong></p><ul><li>​<strong>Agent Multi-modal Transformer Block</strong>：<ul><li>​<strong>跨模态注意力机制</strong>：通过<strong>多头注意力</strong>，Agent Tokens主动对齐视觉和语言信息。例如：<ul><li>Agent Token作为Query，视觉&#x2F;语言Token作为Key-Value，提取任务相关特征。</li></ul></li><li>​<strong>Next Token Blend模块</strong>：<ul><li>动态混合当前模态特征，预测<strong>下一动作或状态</strong>​（例如机器人运动轨迹、决策指令）。</li><li>可能采用<strong>稀疏激活</strong>或<strong>门控机制</strong>，过滤无关信息以提升效率。</li></ul></li></ul></li></ul><hr><p> ​<strong>3. 输出层：端到端代理行为生成</strong></p><ul><li>​<strong>任务自适应输出头</strong>：<ul><li>​<strong>动作预测</strong>：生成机器人控制指令（如关节角度、移动速度）。</li><li>​<strong>多模态响应</strong>：联合输出语言反馈（如任务状态报告）和视觉规划（如路径示意图）。</li></ul></li><li>​<strong>训练范式</strong>：<ul><li>​<strong>端到端优化</strong>：所有子模块（视觉&#x2F;语言&#x2F;Agent）​<strong>联合训练</strong>，而非冻结预训练模型。</li><li>​<strong>Agent Tokens监督</strong>：通过强化学习或模仿学习，引导模型学习领域特定的代理策略。</li></ul></li></ul><hr><p> ​<strong>与现有模型的差异化</strong></p><ol><li><p>​<strong>统一架构 vs 模块拼接</strong>：</p><ul><li>传统方法（如LLM+视觉编码器）需冻结子模块并拼接，而Agent Transformer通过<strong>统一参数空间</strong>实现端到端优化，提升多模态对齐效率。</li></ul></li><li><p>​<strong>Agent Tokens的引导作用</strong>：</p><ul><li>Agent Tokens作为<strong>任务控制器</strong>，动态调节多模态信息的交互方式（类似“软提示”）。</li><li>例如：在机器人任务中，Agent Tokens可编码环境状态（如障碍物位置），指导视觉-语言特征融合。</li></ul></li><li><p>​<strong>Next Token Blend的创新</strong>：</p><ul><li>不仅预测语言&#x2F;视觉的下一个Token，还直接输出<strong>跨模态动作序列</strong>，适用于实时决策场景。</li></ul></li></ol><hr><p> ​<strong>技术价值与应用场景</strong></p><ul><li>​<strong>机器人控制</strong>：<ul><li>输入：视觉场景（摄像头图像）+ 语言指令（“拿起红色方块”）；</li><li>输出：机械臂动作序列 + 任务状态反馈（“已抓取目标”）。</li></ul></li><li>​<strong>多模态对话系统</strong>：<ul><li>输入：用户文本提问（“解释这张图表”）+ 图表截图；</li><li>输出：语言解释 + 视觉标注（箭头指向关键数据点）。</li></ul></li></ul><hr><p> ​<strong>总结</strong></p><p>Agent Transformer的核心创新在于：</p><ol><li>通过<strong>Agent Tokens</strong>统一多模态交互与代理行为生成；</li><li>​<strong>端到端训练范式</strong>打破传统模块化方案的局限性；</li><li>​<strong>Next Token Blend</strong>实现跨模态动作-语言的联合预测。<br> 这种架构特别适合需要<strong>实时决策</strong>与<strong>多模态闭环控制</strong>的场景（如机器人、自动驾驶），是当前多模态代理（Multimodal Agent）研究的前沿方向。</li></ol><h4 id="建立多模态交互的评估指标体系"><a href="#建立多模态交互的评估指标体系" class="headerlink" title="建立多模态交互的评估指标体系"></a>建立多模态交互的评估指标体系</h4><p><img src="/img/Agent-img12.png" alt="Lena"><br> ​<strong>多模态交互评估指标体系的构成解析</strong></p><p>根据图中信息，该体系旨在通过<strong>游戏化多智能体协作场景</strong>，构建多模态交互能力的量化评估框架。其核心模块可分为以下五层，各层协同运作并支撑评估目标的实现：</p><hr><p> ​<strong>一、环境层（Gaming Environment）​</strong></p><ul><li>​<strong>功能</strong>：模拟多模态交互的真实场景（如烹饪任务），生成动态交互数据。</li><li>​<strong>关键组件</strong>：<ol><li>​<strong>多智能体系统（Multi-Agents）​</strong>：<ul><li>包含玩家（Player）、NPC（如虚拟厨师）、协作伙伴（Collaborators），覆盖人机&#x2F;人人协作模式。</li></ul></li><li>​<strong>环境状态（Environment State）​</strong>：<ul><li>实时记录场景信息（如食材库存、待处理菜品、计时器状态）。</li></ul></li><li>​<strong>控制器（Controller）​</strong>：<ul><li>控制游戏规则与状态更新（如任务进度、成功&#x2F;失败条件）。</li></ul></li></ol></li></ul><p><strong>评估作用</strong>：</p><ul><li>提供<strong>标准化测试场景</strong>，确保不同模型&#x2F;策略的评估结果可比。</li><li>通过动态环境状态（如“食材耗尽”事件）测试智能体的实时应变能力。</li></ul><hr><p> ​<strong>二、规划与工具层（Planning Skills &amp; Tool Use）​</strong></p><ul><li>​<strong>功能</strong>：将多模态交互行为拆解为可量化的“技能单元”。</li><li>​<strong>核心模块</strong>：<ol><li>​<strong>状态提取（State Extraction）​</strong>：<ul><li>从游戏环境中提取结构化状态信息（如“当前可用工具：刀具、烤箱”）。</li></ul></li><li>​<strong>动作提取（Action Extraction）​</strong>：<ul><li>将自然语言指令（如“切胡萝卜”）解析为预定义动作类型（如<code>cut(object=&quot;carrot&quot;)</code>）。</li></ul></li><li>​<strong>领域知识库（Domain-specific Knowledge）​</strong>：<ul><li>内置任务相关知识（如菜谱步骤、工具使用规范）。</li></ul></li></ol></li></ul><p><strong>评估作用</strong>：</p><ul><li>定义<strong>技能原子指标</strong>：<ul><li>​<strong>状态理解准确率</strong>​（提取的环境状态与真实状态的匹配度）</li><li>​<strong>动作映射正确率</strong>​（自然语言到DSL的转换成功率）</li></ul></li></ul><hr><p> ​<strong>三、决策层（LLM Dispatcher）​</strong></p><ul><li>​<strong>功能</strong>：基于多模态输入（环境状态+历史记忆）进行动态决策。</li><li>​<strong>运行机制</strong>：<ol><li>​<strong>输入整合</strong>：<ul><li>融合当前状态（如“剩余时间：5分钟”）、历史轨迹（如“已执行动作序列”）、环境反馈（如“刀具损坏警告”）。</li></ul></li><li>​<strong>多智能体调度</strong>：<ul><li>分配任务给不同智能体（如指挥NPC准备食材，玩家执行关键步骤）。</li></ul></li><li>​<strong>决策输出</strong>：<ul><li>生成下一步动作指令（如“优先完成主菜烹饪”）。</li></ul></li></ol></li></ul><p><strong>评估指标</strong>：</p><ul><li>​<strong>决策合理性</strong>：通过专家标注验证动作是否符合逻辑（如“时间紧迫时是否优先核心任务”）。</li><li>​<strong>多智能体协作效率</strong>：任务完成时间 vs 理论最优时间。</li></ul><hr><p> ​<strong>四、记忆与反馈层（Memory History）​</strong></p><ul><li>​<strong>功能</strong>：存储交互历史以支持长期决策。</li><li>​<strong>数据结构</strong>：<ol><li>​<strong>轨迹历史（Trajectory History）​</strong>：<ul><li>记录完整的动作序列与环境状态变化。</li></ul></li><li>​<strong>错误日志（Validation Log）​</strong>：<ul><li>存储动作执行失败的原因（如DSL语法错误、资源不足）。</li></ul></li><li>​<strong>领域模式（Pattern for Instructions）​</strong>：<ul><li>积累成功案例库（如高效菜谱执行流程）。</li></ul></li></ol></li></ul><p><strong>评估作用</strong>：</p><ul><li>​<strong>长期一致性</strong>：检查智能体是否避免重复错误（如“是否学会刀具保养以防止损坏”）。</li><li>​<strong>知识复用能力</strong>：对比历史相似场景的决策优化程度。</li></ul><hr><p> ​<strong>五、执行验证层（Action Module）​</strong></p><ul><li>​<strong>功能</strong>：确保生成动作的可执行性与安全性。</li><li>​<strong>关键技术</strong>：<ol><li>​<strong>DSL转换（Domain-Specific Language）​</strong>：<ul><li>将自然语言指令转换为无歧义的机器指令（如<code>cook(dish=&quot;soup&quot;, temperature=100°C)</code>）。</li></ul></li><li>​<strong>语法验证（Validation）​</strong>：<ul><li>检查DSL是否符合预定义规则（如参数类型、取值范围）。</li></ul></li><li>​<strong>安全约束（Safety Constraints）​</strong>：<ul><li>阻止危险操作（如“空锅高温加热”）。</li></ul></li></ol></li></ul><p><strong>评估指标</strong>：</p><ul><li>​<strong>动作执行成功率</strong>：DSL在实际环境中的有效执行比例。</li><li>​<strong>异常处理能力</strong>：对非法操作的拦截率与修复建议质量。</li></ul><hr><p> ​<strong>体系特点与评估维度</strong></p><p> ​<strong>1. 多模态交互能力量化</strong></p><ul><li><p>​<strong>模态覆盖</strong>：</p><table><thead><tr><th>模态类型</th><th>评估焦点</th></tr></thead><tbody><tr><td>语言指令</td><td>意图理解、DSL转换准确性</td></tr><tr><td>视觉场景</td><td>环境状态提取完整度</td></tr><tr><td>时序动作序列</td><td>长期规划一致性</td></tr></tbody></table></li></ul><p> ​<strong>2. 动态闭环评估机制</strong></p><ul><li><p>​<strong>实时反馈循环</strong>：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">环境状态 → 决策生成 → 动作执行 → 结果反馈 → 状态更新  </span><br></pre></td></tr></table></figure></li><li><p>支持对<strong>自适应能力</strong>的持续评测（如突发事件的应对策略）。</p></li></ul><p> ​<strong>3. 可扩展性设计</strong></p><ul><li>​<strong>模块化架构</strong>：<ul><li>更换游戏环境（如从烹饪切换至物流调度）即可评测不同领域能力。</li></ul></li><li>​<strong>指标插件机制</strong>：<ul><li>支持自定义评估维度（如伦理合规性、能源消耗效率）。</li></ul></li></ul><hr><p> ​<strong>总结</strong></p><p>该评估体系通过<strong>游戏化多智能体协作场景</strong>，将多模态交互能力拆解为环境理解、规划决策、动作执行等可量化模块，其核心价值在于：</p><ol><li>​<strong>标准化</strong>：统一测试场景与指标，解决传统评测主观性强的问题；</li><li>​<strong>细粒度</strong>：从原子技能到宏观策略的全维度覆盖；</li><li>​<strong>动态性</strong>：支持实时交互与长期记忆能力的评估。<br> 此类体系特别适合评估自动驾驶助手、智能客服机器人等需要多模态协作的AI系统。</li></ol><h4 id="机器人任务规划系统流程图"><a href="#机器人任务规划系统流程图" class="headerlink" title="机器人任务规划系统流程图"></a>机器人任务规划系统流程图</h4><p><img src="/img/Agent-img13.png" alt="Lena"></p><p>该系统通过<strong>自然语言指令</strong>与<strong>视觉演示</strong>的结合，实现机器人复杂任务的端到端规划与执行。流程分为两大核心阶段——<strong>任务规划</strong>与<strong>技能参数化</strong>，以下是具体步骤解析：</p><hr><p> ​<strong>一、任务规划阶段（Task Planning）​</strong></p><p><strong>目标</strong>：将用户自然语言指令转化为可执行的机器人动作序列。<br><strong>流程分解</strong>：</p><ol><li><p>​<strong>用户指令输入</strong>：</p><ul><li>示例指令：<code>&quot;把果汁放在架子上&quot;</code></li><li>输入形式：自然语言文本（支持多语言）。</li></ul></li><li><p>​<strong>环境描述注入</strong>：</p><ul><li><p>系统加载预定义的环境信息（JSON格式），例如：</p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>  </span><br><span class="line">  <span class="attr">&quot;shelf&quot;</span><span class="punctuation">:</span> <span class="string">&quot;on_stable_base&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;juice&quot;</span><span class="punctuation">:</span> <span class="string">&quot;on_wheeled_bottom&quot;</span>  </span><br><span class="line"><span class="punctuation">&#125;</span>  </span><br></pre></td></tr></table></figure></li><li><p>描述内容：物体位置、稳定性、可移动性等物理属性。</p></li></ul></li><li><p>​<strong>ChatGPT任务规划器生成动作序列</strong>：</p><ul><li><p>​<strong>输入</strong>：用户指令 + 环境描述</p></li><li><p>​<strong>输出</strong>：初步动作序列（带解释的伪代码），例如：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. move_hand(): 移动机械臂接近果汁  </span><br><span class="line">2. grasp_object(juice): 抓取果汁  </span><br><span class="line">3. move_object(juice, upward): 垂直提升果汁  </span><br><span class="line">4. put_down_object(juice, shelf): 将果汁放置到架子  </span><br><span class="line">5. release_object(juice): 释放抓握  </span><br></pre></td></tr></table></figure></li><li><p>​<strong>关键技术</strong>：基于提示工程（Pre-defined Prompt）引导ChatGPT生成符合物理规则的逻辑链。</p></li></ul></li><li><p>​<strong>人工反馈调整</strong>：</p><ul><li>用户可修改动作顺序或参数（如调整移动方向为<code>[x,y,z]</code>而非<code>upward</code>），系统迭代优化序列。</li></ul></li></ol><hr><h4 id="​二、技能参数化阶段（Skill-Parameterization）​"><a href="#​二、技能参数化阶段（Skill-Parameterization）​" class="headerlink" title="​二、技能参数化阶段（Skill Parameterization）​"></a>​<strong>二、技能参数化阶段（Skill Parameterization）​</strong></h4><p><strong>目标</strong>：通过视觉演示将抽象动作转化为机器人可执行的精确参数。<br><strong>流程分解</strong>：</p><ol><li><p>​<strong>视觉演示输入</strong>：</p><ul><li>用户通过摄像头展示动作过程（如手持果汁放置到架子的完整路径）。</li><li>示例输入：RGB-D视频流 + 深度传感器数据。</li></ul></li><li><p>​<strong>视觉分析器提取参数</strong>：</p><ul><li>​<strong>3D物体定位</strong>：<ul><li>使用点云分析获取果汁的精确坐标<code>[x,y,z]</code>（如<code>[0.5m, 1.2m, 0.8m]</code>）。</li></ul></li><li>​<strong>操作方向解析</strong>：<ul><li>从运动轨迹中提取移动方向向量（如<code>approach_direction: [0, 0, 1]</code>表示垂直向上）。</li></ul></li><li>​<strong>抓取类型识别</strong>：<ul><li>根据物体形状（如圆柱形果汁瓶）匹配抓取策略（<code>&quot;power grasp&quot;</code>强力抓握 vs. <code>&quot;precision grasp&quot;</code>精细抓握）。</li></ul></li></ul></li><li><p>​<strong>参数化任务生成</strong>：</p><ul><li><p>将视觉参数注入任务序列，生成机器人控制指令，例如：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">grasp(  </span><br><span class="line">    <span class="built_in">object</span>=juice,  </span><br><span class="line">    position=[<span class="number">0.5</span>, <span class="number">1.2</span>, <span class="number">0.8</span>],  </span><br><span class="line">    grasp_type=<span class="string">&quot;power&quot;</span>,  </span><br><span class="line">    approach_direction=[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]  </span><br><span class="line">)  </span><br></pre></td></tr></table></figure></li></ul></li></ol><hr><h4 id="​三、执行与闭环验证"><a href="#​三、执行与闭环验证" class="headerlink" title="​三、执行与闭环验证"></a>​<strong>三、执行与闭环验证</strong></h4><ol><li><p>​<strong>动作执行</strong>：</p><ul><li>机器人根据参数化指令依次执行动作，实时反馈状态（如力传感数据、末端执行器位置）。</li></ul></li><li><p>​<strong>异常检测与修复</strong>：</p><ul><li>若执行失败（如抓取时果汁滑落），系统可触发：<ul><li>​<strong>重规划</strong>：重新调用ChatGPT生成替代动作（如调整抓握角度）。</li><li>​<strong>参数校准</strong>：基于新视觉数据更新3D坐标或运动轨迹。</li></ul></li></ul></li></ol><hr><h3 id="​系统核心优势"><a href="#​系统核心优势" class="headerlink" title="​系统核心优势"></a>​<strong>系统核心优势</strong></h3><ol><li>​<strong>自然交互</strong>：用户无需编程即可通过语言+演示指导机器人。</li><li>​<strong>物理规则嵌入</strong>：环境描述与参数化确保动作符合现实约束（如重力、碰撞避免）。</li><li>​<strong>灵活可扩展</strong>：<ul><li>支持新任务快速适配（更换ChatGPT提示词即可定义新指令模板）。</li><li>视觉分析器兼容多传感器（RGB-D摄像头、LiDAR等）。</li></ul></li></ol><hr><h3 id="​应用场景示例"><a href="#​应用场景示例" class="headerlink" title="​应用场景示例"></a>​<strong>应用场景示例</strong></h3><ul><li>​<strong>家庭服务机器人</strong>：整理杂物、端茶递水。</li><li>​<strong>工业机器人</strong>：基于语言指令调整装配流程（如“优先组装电路板”）。</li><li>​<strong>医疗辅助机器人</strong>：通过演示学习手术器械传递路径。</li></ul><p>通过这一流程，机器人任务规划从传统的硬编码模式升级为<strong>人机协作的智能闭环系统</strong>，大幅降低操作门槛并提升适应性。</p><h3 id="关键技术突破"><a href="#关键技术突破" class="headerlink" title="关键技术突破"></a>关键技术突破</h3><ul><li>​<strong>幻觉抑制</strong>：通过知识检索增强和视觉验证</li><li>​<strong>跨模态理解</strong>：开发统一的多模态表征空间</li><li>​<strong>实时决策优化</strong>：结合环境反馈的在线学习机制</li><li>​<strong>伦理安全机制</strong>：构建数据隐私保护和偏见检测系统</li></ul><h3 id="应用场景验证"><a href="#应用场景验证" class="headerlink" title="应用场景验证"></a>应用场景验证</h3><table><thead><tr><th>领域</th><th>典型案例</th><th>关键技术</th></tr></thead><tbody><tr><td>游戏AI</td><td>Minecraft场景生成、NPC行为预测（图8-12）</td><td>GPT-4V视觉推理、多智能体协作</td></tr><tr><td>机器人控制</td><td>厨房任务规划（图13）、视觉运动控制（图15-17）</td><td>ChatGPT任务分解、VLM环境感知</td></tr><tr><td>医疗辅助</td><td>医学影像分析、患者交互系统</td><td>多模态知识检索、隐私保护机制</td></tr><tr><td>虚拟现实</td><td>Unity引擎场景生成、动态环境编辑</td><td>扩散模型资产生成、物理引擎集成</td></tr></tbody></table><h2 id="主要结论"><a href="#主要结论" class="headerlink" title="主要结论"></a>主要结论</h2><ol><li>​<strong>技术突破</strong>：</li></ol><ul><li>证明基础模型可通过环境嵌入显著提升多模态理解能力</li><li>提出混合现实交互范式有效减少大模型幻觉（成功率提升37%）</li><li>建立首个多智能体协作评估基准CuisineWorld</li></ul><ol start="2"><li>​<strong>应用价值</strong>：</li></ol><ul><li>在游戏、机器人、医疗等领域验证框架有效性</li><li>实现从单模态到跨模态的通用智能体架构</li></ul><ol start="3"><li>​<strong>未来方向</strong>：</li></ol><ul><li>构建更高效的持续学习机制</li><li>开发可解释的决策过程可视化工具</li><li>建立跨领域通用的评估标准体系</li><li>解决数据隐私和伦理安全问题</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前沿技术解读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于模型微调</title>
      <link href="/2024/08/13/%E5%85%B3%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/"/>
      <url>/2024/08/13/%E5%85%B3%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-大语言模型介绍"><a href="#2-1-大语言模型介绍" class="headerlink" title="2.1 大语言模型介绍"></a>2.1 大语言模型介绍</h2><h3 id="大语言模型的概念"><a href="#大语言模型的概念" class="headerlink" title="大语言模型的概念"></a>大语言模型的概念</h3><p><strong>大语言模型（英文：Large Language Model，缩写LLM），</strong>也称大型语言模型，是一种人工智能模型，旨在理解和生成人类语言。</p><p>通常，大语言模型 (LLM) 指包含数<strong>十亿</strong>（<strong>Billion</strong>或更多）参数的语言模型，这些模型在大量的文本数据上进行训练，例如国外的有GPT-3 、GPT-4、PaLM 、Galactica 和 LLaMA 等，国内的有ChatGLM、文心一言、通义千问、讯飞星火等。</p><h3 id="大模型的能力和特点"><a href="#大模型的能力和特点" class="headerlink" title="大模型的能力和特点"></a><strong>大模型的能力和特点</strong></h3><ol><li><strong>大模型的能力</strong></li></ol><p>大语言模型（LLM）与以前的预训练语言模型（PLM）的主要区别在于其涌现能力。这种能力在小型模型中不明显，但在大型模型中显著。例如：</p><ul><li><p><strong>上下文学习</strong>：首次由GPT-3引入，允许模型在提供自然语言指令或多个任务示例的情况下，通过理解上下文并生成相应输出来执行任务。</p></li><li><p><strong>指令遵循</strong>：通过指令微调，LLM可以根据任务指令执行未见过的任务，展示出强大的泛化能力。</p></li><li><p><strong>逐步推理</strong>：通过”<strong>思维链（Chain of Thought, CoT）</strong>“策略，LLM能够解决多步推理任务，例如数学问题。</p></li></ul><ol start="2"><li><strong>大模型的特点</strong></li></ol><ul><li><p><strong>巨大的规模</strong>：参数规模达数十亿甚至数千亿，使其能捕捉更多语言知识和复杂语法结构。</p></li><li><p><strong>预训练和微调</strong>：在大规模无标签文本数据上预训练，然后通过有标签数据微调，适应特定任务。</p></li><li><p><strong>上下文感知</strong>：具备强大的上下文感知能力，能够理解和生成依赖前文的文本内容。</p></li><li><p><strong>多语言支持</strong>：支持多种语言，促进跨文化和跨语言的应用。</p></li><li><p><strong>多模态支持</strong>：一些LLM支持文本、图像和语音的多模态数据。</p></li><li><p><strong>涌现能力</strong>：在大规模模型中表现出明显的性能提升，能处理更复杂的任务。</p></li><li><p><strong>多领域应用</strong>：广泛应用于文本生成、自动翻译、信息检索、摘要生成、聊天机器人等多个领域。</p></li><li><p><strong>伦理和风险问题</strong>：需要谨慎处理生成有害内容、隐私问题和认知偏差等伦理和风险问题。</p></li></ul><h2 id="2-2-微调介绍"><a href="#2-2-微调介绍" class="headerlink" title="2.2 微调介绍"></a>2.2 微调介绍</h2><h3 id="什么是模型微调-？"><a href="#什么是模型微调-？" class="headerlink" title="*什么是模型微调*？"></a>*<em>什么是模型</em><em><strong>微调</strong></em>*？</h3><p><img src="/img/813-1.png" alt="Lena"></p><p>相当于给你一个预训练模型（Pre-trained model），基于这个模型微调（Fine Tune）。</p><p><strong>预训练模型就是</strong>已经用数据集训练好了的模型。</p><h3 id="两种-Finetune-范式"><a href="#两种-Finetune-范式" class="headerlink" title="两种 Finetune 范式"></a>两种 Finetune 范式</h3><ol><li><strong>增量预训练微调 (<strong><strong>Continue PreTraining</strong></strong>)</strong></li></ol><p>使用场景：让基座模型学习到一些新知识，如某个垂类领域的常识</p><ol><li><p>训练数据：文章、书籍、代码等</p></li><li><p>*<em>指令跟随微调 (<em><strong>Supervised Finetuning</strong></em></em>)</p></li></ol><p>使用场景：让模型学会对话模板，根据人类指令进行对话</p><p>训练数据：高质量的对话、问答数据</p><h3 id="为什么要微调？"><a href="#为什么要微调？" class="headerlink" title="为什么要微调？"></a>为什么要微调？</h3><p>相对于从头开始训练(Training a model from scatch)，微调可以省去大量计算资源和计算时间，提高了计算效率,甚至提高准确率。</p><p><strong>普通预训练模型</strong>的特点是：用了大型数据集做训练，已经具备了提取浅层基础特征和深层抽象特征的能力。</p><p><strong>不做微调</strong>：</p><p>（1）从头开始训练，需要大量的数据，计算时间和计算资源。</p><p>（2）存在模型不收敛，参数不够优化，准确率低，模型泛化能力低，容易过拟合等风险。</p><p><strong>使用微调</strong>：避免了上述可能存在的问题。</p><h3 id="什么情况下使用微调？"><a href="#什么情况下使用微调？" class="headerlink" title="什么情况下使用微调？"></a>什么情况下使用微调？</h3><p>（1） 你要使用的数据集和预训练模型的数据集相似</p><p>如果不太相似，效果可能就没有那么好了，特征提取是不同的，所以相应的参数训练后也是不同的。</p><p>（2） 自己搭建或者使用的模型正确率太低。</p><p>（3）数据集相似，但数据集数量太少。</p><p>（4）计算资源太少。</p><h3 id="不同数据集下使用微调"><a href="#不同数据集下使用微调" class="headerlink" title="不同数据集下使用微调"></a>不同数据集下使用微调</h3><ul><li><p>数据集1 - 数据量少，但数据相似度非常高在这种情况下，我们所做的只是修改最后几层或最终的softmax图层的输出类别。</p></li><li><p>数据集2 - 数据量少，数据相似度低在这种情况下，我们可以冻结预训练模型的初始层（比如k层），并再次训练剩余的（n-k）层。由于新数据集的相似度较低，因此根据新数据集对较高层进行重新训练具有重要意义。</p></li><li><p>数据集3 - 数据量大，数据相似度低在这种情况下，由于我们有一个大的数据集，我们的神经网络训练将会很有效。但是，由于我们的数据与用于训练我们的预训练模型的数据相比有很大不同。使用预训练模型进行的预测不会有效。因此，最好根据你的数据从头开始训练神经网络（Training from scatch）。</p></li><li><p>数据集4 - 数据量大，数据相似度高这是理想情况。在这种情况下，预训练模型应该是最有效的。使用模型的最好方法是保留模型的体系结构和模型的初始权重。然后，我们可以使用在预先训练的模型中的权重来重新训练该模型。</p></li></ul><h3 id="微调指导事项"><a href="#微调指导事项" class="headerlink" title="微调指导事项"></a>微调指导事项</h3><p>1.通常的做法是截断预先训练好的网络的最后一层（softmax层），并用与我们自己的问题相关的新的softmax层替换它。例如，ImageNet上预先训练好的网络带有1000个类别的softmax图层。如果我们的任务是对10个类别的分类，则网络的新softmax层将由10个类别组成，而不是1000个类别。然后，我们在网络上运行预先训练的权重。确保执行交叉验证，以便网络能够很好地推广。 2.使用较小的学习率来训练网络。由于我们预计预先训练的权重相对于随机初始化的权重已经相当不错，我们不想过快地扭曲它们太多。通常的做法是使初始学习率比用于从头开始训练（Training from scratch）的初始学习率小10倍。 3. 如果数据集数量过少，我们进来只训练最后一层，如果数据集数量中等，冻结预训练网络的前几层的权重也是一种常见做法。</p><blockquote><p>这是因为前几个图层捕捉了与我们的新问题相关的通用特征，如曲线和边。我们希望保持这些权重不变。相反，我们会让网络专注于学习后续深层中特定于数据集的特征。</p></blockquote><h3 id="LoRA"><a href="#LoRA" class="headerlink" title="LoRA"></a>LoRA</h3><p>LoRA是一种高效微调方法，深入了解其原理可参见博客：[<strong><strong><a href="https://zhuanlan.zhihu.com/p/650197598">知乎|深入浅出Lora</a></strong></strong>] 。</p><h3 id="LoRA-的优势"><a href="#LoRA-的优势" class="headerlink" title="LoRA 的优势"></a><strong>LoRA 的优势</strong></h3><ul><li><p>可以针对不同的下游任务构建小型 LoRA 模块，从而在共享预训练模型参数基础上有效地切换下游任务。</p></li><li><p>LoRA 使用自适应优化器（Adaptive Optimizer），不需要计算梯度或维护大多数参数的优化器状态，训练更有效、硬件门槛更低。</p></li><li><p>LoRA 使用简单的线性设计，在部署时将可训练矩阵与冻结权重合并，不存在推理延迟。</p></li><li><p>LoRA 与其他方法正交，可以组合。</p></li></ul><h3 id="LoRA-的原理"><a href="#LoRA-的原理" class="headerlink" title="LoRA 的原理"></a><strong>LoRA 的原理</strong></h3><p><img src="/img/813-2.png" alt="Lena"></p><h2 id="3-1-环境准备"><a href="#3-1-环境准备" class="headerlink" title="3.1 环境准备"></a>3.1 环境准备</h2><p>相关库的下载与安装：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install pandas openpyxl</span><br></pre></td></tr></table></figure><p>数据加载与抽取</p><h2 id="3-2-语文数据处理"><a href="#3-2-语文数据处理" class="headerlink" title="3.2 语文数据处理"></a>3.2 语文数据处理</h2><h3 id="3-2-1-数据加载"><a href="#3-2-1-数据加载" class="headerlink" title="3.2.1 数据加载"></a>3.2.1 数据加载</h3><p>这里我们使用pandas加载xlsx中的数据，这里面我们使用全局匹配，将训练集中的中文点与左侧括号匹配为英文类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding~</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取Excel文件</span></span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;训练集-语文.xlsx&#x27;</span>)</span><br><span class="line">df = df.replace(<span class="string">&#x27;．&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, regex=<span class="literal">True</span>)</span><br><span class="line">df = df.replace(<span class="string">&#x27;（&#x27;</span>, <span class="string">&#x27;(&#x27;</span>, regex=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取第二行（即第三行）“选项”列的内容</span></span><br><span class="line"><span class="comment"># 可以使用loc获取某行的数据</span></span><br><span class="line">second_row_option_content = df.loc[<span class="number">2</span>, <span class="string">&#x27;选项&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示第二行“选项”列的内容</span></span><br><span class="line"><span class="built_in">print</span>(second_row_option_content)</span><br></pre></td></tr></table></figure><h3 id="3-2-2-抽取问题"><a href="#3-2-2-抽取问题" class="headerlink" title="3.2.2 抽取问题"></a>3.2.2 抽取问题</h3><p>这里主要是为了抽取题目及答案，并且过滤简答题。大家可以阅读详细的注释理解问题抽取的函数如何工作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chinese_multiple_choice_questions</span>(<span class="params">questions_with_answers</span>):</span><br><span class="line">    <span class="comment"># 输入的题目文本</span></span><br><span class="line">    text = questions_with_answers</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    question_pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;\d+\..*?(?=\d+\.|$)&#x27;</span>, re.DOTALL)</span><br><span class="line">    <span class="comment"># 这一行作用是匹配一个以数字开头、后面跟着一个点字符的字符串，</span></span><br><span class="line">    <span class="comment">#。直到遇到下一个数字和点字符或字符串结束。</span></span><br><span class="line">    choice_pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([A-D])\s*(.*?)(?=[A-D]|$|\n)&#x27;</span>, re.DOTALL)</span><br><span class="line">    <span class="comment"># 这一行作用是匹配一个以字母[A到D]开头、后面跟着一个点字符的字符串，</span></span><br><span class="line">    <span class="comment">#直到遇到下一个[A到D]或字符串结束。</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到所有问题</span></span><br><span class="line">    questions = question_pattern.findall(text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化选择题和简答题列表</span></span><br><span class="line">    multiple_choice_questions = []</span><br><span class="line">    short_answer_questions = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理每个问题</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">id</span>,question <span class="keyword">in</span> <span class="built_in">enumerate</span>(questions):</span><br><span class="line">        <span class="comment"># 这里取到的question，如果是选择题会带着选择题的选项。</span></span><br><span class="line">        <span class="comment"># 检查是否是选择题 因为选择题内有ABCD这样的选项</span></span><br><span class="line">        <span class="keyword">if</span> re.search(<span class="string">r&#x27;[A-D]&#x27;</span>, question):</span><br><span class="line">            <span class="comment"># 如果有选项，提取出选项的内容</span></span><br><span class="line">            choices = choice_pattern.findall(question)</span><br><span class="line">            <span class="comment"># 这里提取了题目的内容，因为每个题目都会有一个打分的（X分）这样的标记</span></span><br><span class="line">            <span class="comment"># 以左括号为目标，截取选择题选项中的内容</span></span><br><span class="line">            question_text = re.split(<span class="string">r&#x27;\n&#x27;</span>, question.split(<span class="string">&#x27;(&#x27;</span>)[<span class="number">0</span>])[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            pattern_question = re.<span class="built_in">compile</span>(<span class="string">r&#x27;(\d+)\.(.*)&#x27;</span>)</span><br><span class="line">            <span class="comment"># 这里清洗了选择题的编号，重新用循环中的id进行编号。</span></span><br><span class="line">            <span class="comment"># 如果不做这一步可以发现给定的数据中编号是乱序的。</span></span><br><span class="line">            matches_question = <span class="built_in">str</span>(<span class="built_in">id</span>+<span class="number">1</span>)+<span class="string">&#x27;.&#x27;</span>+ pattern_question.findall(question_text)[<span class="number">0</span>][<span class="number">1</span>] <span class="comment"># 取出问题后重排序</span></span><br><span class="line">            <span class="comment"># print(str(id+1)+&#x27;.&#x27;+matches_question)</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 这里我们实现声明好了存储的列表</span></span><br><span class="line">            <span class="comment"># 将每个问题和选项以字典的形式存入方便我们处理</span></span><br><span class="line">            multiple_choice_questions.append(&#123;</span><br><span class="line">                <span class="string">&#x27;question&#x27;</span>: matches_question,</span><br><span class="line">                <span class="string">&#x27;choices&#x27;</span>: choices</span><br><span class="line">            &#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 大家可以想想这里怎么用？</span></span><br><span class="line">            short_answer_questions.append(question.strip())</span><br><span class="line">    <span class="comment"># 最后我们返回抽取后的选择题字典列表</span></span><br><span class="line">    <span class="keyword">return</span> multiple_choice_questions</span><br></pre></td></tr></table></figure><h3 id="3-2-3-抽取问题的结果"><a href="#3-2-3-抽取问题的结果" class="headerlink" title="3.2.3 抽取问题的结果"></a>3.2.3 抽取问题的结果</h3><p>这里我们抽取刚才我们拿到的选择题的答案部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chinese_multiple_choice_answers</span>(<span class="params">questions_with_answers</span>):</span><br><span class="line">   <span class="comment"># 首先清洗输入字段，因为答案字段中的格式不统一，清洗后便于统一处理。</span></span><br><span class="line">   <span class="comment"># 这里删除了所有的换行和空格</span></span><br><span class="line">    questions_with_answers = questions_with_answers.replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;\n&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># print(questions_with_answers)</span></span><br><span class="line">    <span class="comment"># 使用正则表达式匹配答案</span></span><br><span class="line">    <span class="comment"># 这里我们主要使用第一个匹配 一个数字+点+字母ABCD之间一个</span></span><br><span class="line">    choice_pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;(\d+)\.([A-Z]+)&#x27;</span>)</span><br><span class="line">    <span class="comment"># 下面这句匹配的是简答题答案~  目前可以忽略</span></span><br><span class="line">    short_pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;(\d+)\.([^A-Z]+)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 找到所有匹配的答案</span></span><br><span class="line">    choice_matches = choice_pattern.findall(questions_with_answers)</span><br><span class="line">    short_matches = short_pattern.findall(questions_with_answers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将匹配结果转换为字典</span></span><br><span class="line">    choice_answers = &#123;<span class="built_in">int</span>(index): answer <span class="keyword">for</span> index, answer <span class="keyword">in</span> choice_matches&#125;</span><br><span class="line">    short_answers = &#123;<span class="built_in">int</span>(index): answer <span class="keyword">for</span> index, answer <span class="keyword">in</span> short_matches&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 按序号重新排序</span></span><br><span class="line">    sorted_choice_answers = <span class="built_in">sorted</span>(choice_answers.items())</span><br><span class="line">    sorted_short_answers = <span class="built_in">sorted</span>(short_answers.items())</span><br><span class="line">    </span><br><span class="line">    answers = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出结果</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># print(&quot;选择题答案：&quot;)</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sorted_choice_answers)):</span><br><span class="line">    <span class="comment"># 这里我们也将重新编号号的答案作为返回，返回的是一个列表，方便与问题字典列表匹配~</span></span><br><span class="line">        answers.append(<span class="string">f&quot;<span class="subst">&#123;<span class="built_in">id</span>+<span class="number">1</span>&#125;</span>. <span class="subst">&#123;sorted_choice_answers[<span class="built_in">id</span>][<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> answers</span><br></pre></td></tr></table></figure><p><img src="/img/813-3.png" alt="Lena"></p><p>这里是一个样例~</p><h3 id="3-2-4-prompt设计"><a href="#3-2-4-prompt设计" class="headerlink" title="3.2.4 prompt设计"></a>3.2.4 prompt设计</h3><p>正如我们1.4介绍的，我们使用要求+阅读材料组成prompt，作为input部分。</p><p>我们看看代码如何实现？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_prompt_cn</span>(<span class="params">text</span>):</span><br><span class="line">    prompt = <span class="string">f&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择题，包含题目选项，以及对应的答案，注意：不⽤给出原文，每道题由1个问题和4个选项组成，仅存在1个正确答案，请严格按照要求执行。 阅读文本主要是中文，你出的题目需要满足以下要点，紧扣文章内容且题干和答案为中文：</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    ### 回答要求</span></span><br><span class="line"><span class="string">    (1)理解文中重要概念的含义</span></span><br><span class="line"><span class="string">    (2)理解文中重要句子的含意</span></span><br><span class="line"><span class="string">    (3)分析论点、论据和论证方法</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    ### 阅读文本</span></span><br><span class="line"><span class="string">    <span class="subst">&#123;text&#125;</span></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> prompt   </span><br></pre></td></tr></table></figure><p>可以看到代码里面首先对大模型做了声明，声明如下：</p><p><code>你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择题，包含题目选项，以及对应的答案，注意：不⽤给出原文，每道题由1个问题和4个选项组成，仅存在1个正确答案，请严格按照要求执行。 阅读文本主要是中文，你出的题目需要满足以下要点，紧扣文章内容且题干和答案为中文：</code></p><p>这里是官方的声明，不建议修改~</p><p>接下来是要求部分：（这里建议大家根据出题要求做修改尝试~）</p><p><code>### 回答要求</code></p><p><code>(1)理解文中重要概念的含义</code></p><p><code>(2)理解文中重要句子的含意</code></p><p><code>(3)分析论点、论据和论证方法</code></p><p>最后是阅读材料，这里其实是我们传入的阅读材料参数。</p><p><code>### 阅读文本</code></p><p><code>&#123;text&#125;</code></p><h3 id="3-2-5-中文数据处理主函数"><a href="#3-2-5-中文数据处理主函数" class="headerlink" title="3.2.5 中文数据处理主函数"></a>3.2.5 中文数据处理主函数</h3><p>这段代码将input与output部分进行组合，按照列表序号一一对应~</p><p>可以看看注释中的实现细节~</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">process_cn</span>(<span class="params">df</span>): </span><br><span class="line">    <span class="comment"># 定义好返回列表</span></span><br><span class="line">    res_input = []</span><br><span class="line">    res_output = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(df)):</span><br><span class="line">        <span class="comment"># 逐个遍历每行的选项、答案、阅读文本的内容</span></span><br><span class="line">        data_options = df.loc[<span class="built_in">id</span>, <span class="string">&#x27;选项&#x27;</span>]</span><br><span class="line">        data_answers = df.loc[<span class="built_in">id</span>,<span class="string">&#x27;答案&#x27;</span>]</span><br><span class="line">        data_prompt = df.loc[<span class="built_in">id</span>,<span class="string">&#x27;阅读文本&#x27;</span>]</span><br><span class="line">        <span class="comment"># 处理选项部分，抽取出选择题题目及选项</span></span><br><span class="line">        data_options = chinese_multiple_choice_questions(data_options)</span><br><span class="line">        <span class="comment"># 处理答案部分，抽取出选择题答案</span></span><br><span class="line">        data_answers = chinese_multiple_choice_answers(data_answers)</span><br><span class="line">        <span class="comment"># 抽取阅读材料组合成input内容</span></span><br><span class="line">        data_prompt = get_prompt_cn(data_prompt)</span><br><span class="line">        <span class="comment"># print(data_options)</span></span><br><span class="line">        <span class="comment"># print(data_answers)</span></span><br><span class="line">        <span class="comment"># 做数据验证，因为训练数据格式不能确定每组数据都能被正常处理（会有一部分处理失败）</span></span><br><span class="line">        <span class="comment"># 我们验证一下两个列表的长度 如果相同代表数据处理正确</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">len</span>(data_answers)==<span class="built_in">len</span>(data_options)):</span><br><span class="line">            <span class="comment"># 定义output的数据字符串</span></span><br><span class="line">            res = <span class="string">&#x27;&#x27;</span></span><br><span class="line">            <span class="comment"># 处理选择题目中的每个数据，逐个拼入到output字符串</span></span><br><span class="line">            <span class="keyword">for</span> id_,question <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_options):</span><br><span class="line">            <span class="comment"># 首先放入题目</span></span><br><span class="line">                res += <span class="string">f&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"><span class="subst">&#123;question[<span class="string">&#x27;question&#x27;</span>]&#125;</span>?</span></span><br><span class="line"><span class="string">                &#x27;&#x27;&#x27;</span>+<span class="string">&#x27;\n&#x27;</span></span><br><span class="line">                <span class="comment"># 然后找到选择题的每个选项，进行choices列表循环</span></span><br><span class="line">                <span class="keyword">for</span> choise <span class="keyword">in</span> question[<span class="string">&#x27;choices&#x27;</span>]:</span><br><span class="line">                <span class="comment"># 逐个将选项拼接到字符串</span></span><br><span class="line">                    res = res+ choise[<span class="number">0</span>] + choise[<span class="number">1</span>]+ <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">                <span class="comment">#  最后将答案拼接到每个选择题的最后</span></span><br><span class="line">                <span class="comment"># 以 答案：题号.选项的格式</span></span><br><span class="line">                res = res + <span class="string">&#x27;答案:&#x27;</span> + <span class="built_in">str</span>(data_answers[id_].split(<span class="string">&#x27;.&#x27;</span>)[-<span class="number">1</span>])  + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">            <span class="comment"># 最后将处理得到的input、output数据存入到列表</span></span><br><span class="line">            res_output.append(res)</span><br><span class="line">            res_input.append(data_prompt)</span><br><span class="line">        <span class="comment"># break</span></span><br><span class="line">    <span class="keyword">return</span> res_input,res_output</span><br><span class="line">    </span><br></pre></td></tr></table></figure><h2 id="3-3-英文数据处理"><a href="#3-3-英文数据处理" class="headerlink" title="3.3 英文数据处理"></a>3.3 英文数据处理</h2><h3 id="3-3-1-数据加载"><a href="#3-3-1-数据加载" class="headerlink" title="3.3.1 数据加载"></a>3.3.1 数据加载</h3><p>和中文一样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding~</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取Excel文件</span></span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;训练集-英语.xlsx&#x27;</span>)</span><br><span class="line"><span class="comment"># 英文数据处理中有一部分ocr识别的题目，这种题目中看上去是字母A，但是实际为俄文的字母，，</span></span><br><span class="line"><span class="comment"># 所以开始使用全局匹配做了清洗……</span></span><br><span class="line">df = df.replace(<span class="string">&#x27;．&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, regex=<span class="literal">True</span>).replace(<span class="string">&#x27;А.&#x27;</span>, <span class="string">&#x27;A.&#x27;</span>, regex=<span class="literal">True</span>).replace(<span class="string">&#x27;В.&#x27;</span>, <span class="string">&#x27;B.&#x27;</span>, regex=<span class="literal">True</span>).replace(<span class="string">&#x27;С.&#x27;</span>, <span class="string">&#x27;C.&#x27;</span>, regex=<span class="literal">True</span>).replace(<span class="string">&#x27;D.&#x27;</span>, <span class="string">&#x27;D.&#x27;</span>, regex=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># df = df.replace(&#x27;（&#x27;, &#x27;(&#x27;, regex=True)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取第二行（即第三行）“选项”列的内容</span></span><br><span class="line">second_row_option_content = df.loc[<span class="number">0</span>, <span class="string">&#x27;选项&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示第二行“选项”列的内容</span></span><br><span class="line"><span class="built_in">print</span>(second_row_option_content)</span><br></pre></td></tr></table></figure><h3 id="3-3-2-抽取问题"><a href="#3-3-2-抽取问题" class="headerlink" title="3.3.2 抽取问题"></a>3.3.2 抽取问题</h3><p>英文问题数据相对标准，但是也有不少小问题。比如ABCD的顺序可能是ACBD。我们看看这些如何解决。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例文本</span></span><br><span class="line">text = second_row_option_content</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_questions</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="comment"># 数据清洗，将所有换行改为两个空格方便统一处理</span></span><br><span class="line">    text = text.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;  &#x27;</span>)+<span class="string">&#x27;  &#x27;</span></span><br><span class="line">    <span class="comment"># print(text)</span></span><br><span class="line">    <span class="comment"># 正则表达式模式</span></span><br><span class="line">    <span class="comment"># 通过匹配以数字开头然后带一个点，为题干</span></span><br><span class="line">    <span class="comment"># 然后抽取选项A  以A开头 后面带一个点 最后以两个空格结尾</span></span><br><span class="line">    <span class="comment"># 为什么是两个空格？部分数据换行时为换行符，我们已经换成了两个空格，有些是以多个空格分割，我们默认为两个空格</span></span><br><span class="line">    <span class="comment"># 接着匹配B C D选项内容</span></span><br><span class="line">    <span class="comment"># 最后有一个</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;(\d+\..*?)(A\..*?\s&#123;2&#125;)([B-D]\..*?\s&#123;2&#125;)([B-D]\..*?\s&#123;2&#125;)(D\..*?\s&#123;2&#125;)&#x27;</span>, re.DOTALL)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找所有匹配项</span></span><br><span class="line">    matches = pattern.findall(text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 存储结果的字典列表</span></span><br><span class="line">    questions_dict_list = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> matches:</span><br><span class="line">        question, option1, option2, option3, option4 = <span class="keyword">match</span></span><br><span class="line">        pattern_question = re.<span class="built_in">compile</span>(<span class="string">r&#x27;(\d+)\.(.*)&#x27;</span>)</span><br><span class="line">        <span class="comment"># 第一个为选择题的题目 提前存到question_text </span></span><br><span class="line">        question_text = pattern_question.findall(question.strip())[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 提取选项字母和内容</span></span><br><span class="line">        options = &#123;option1[<span class="number">0</span>]: option1, option2[<span class="number">0</span>]: option2, option3[<span class="number">0</span>]: option3, option4[<span class="number">0</span>]: option4&#125;</span><br><span class="line">        </span><br><span class="line">        question_dict = &#123;</span><br><span class="line">            <span class="string">&#x27;question&#x27;</span>: question_text,</span><br><span class="line">            <span class="comment"># 这一步就是防止ACBD这种乱序，我们进行重新匹配，将可能是ACBD的数据以首字母按位置排好号</span></span><br><span class="line">            <span class="string">&#x27;options&#x27;</span>: &#123;</span><br><span class="line">                <span class="string">&#x27;A&#x27;</span>: options.get(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;&#x27;</span>).strip(),</span><br><span class="line">                <span class="string">&#x27;B&#x27;</span>: options.get(<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;&#x27;</span>).strip(),</span><br><span class="line">                <span class="string">&#x27;C&#x27;</span>: options.get(<span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;&#x27;</span>).strip(),</span><br><span class="line">                <span class="string">&#x27;D&#x27;</span>: options.get(<span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;&#x27;</span>).strip()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        questions_dict_list.append(question_dict)</span><br><span class="line">    <span class="comment"># 最后获得</span></span><br><span class="line">    <span class="keyword">return</span> questions_dict_list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用函数并打印结果</span></span><br><span class="line">questions = get_questions(text)</span><br><span class="line"><span class="keyword">for</span> q <span class="keyword">in</span> questions:</span><br><span class="line">    <span class="built_in">print</span>(q)</span><br></pre></td></tr></table></figure><h3 id="3-3-3-抽取问题的结果"><a href="#3-3-3-抽取问题的结果" class="headerlink" title="3.3.3 抽取问题的结果"></a>3.3.3 抽取问题的结果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先做数据清洗，将空格、换行符及点都删除</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">remove_whitespace_and_newlines</span>(<span class="params">input_string</span>):</span><br><span class="line">    <span class="comment"># 使用str.replace()方法删除空格和换行符</span></span><br><span class="line">    result = input_string.replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;\n&quot;</span>, <span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;.&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例文本</span></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">32. B. The underlying logic of the effect.                                                   33.D. estimates were not fully independent.</span></span><br><span class="line"><span class="string">34.C. The discussion process.            35.D. Approving.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_answers</span>(<span class="params">text</span>):</span><br><span class="line">    text = remove_whitespace_and_newlines(text)</span><br><span class="line">    <span class="comment"># 正则表达式模式</span></span><br><span class="line">    <span class="comment"># 这里是一个数字加一个A-D的大写字母表示为答案区域，因为有些答案中有解释，这样的匹配规则可以尽可能匹配到答案</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;(\d)\s*([A-D])&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找所有匹配项</span></span><br><span class="line">    matches = pattern.findall(text)</span><br><span class="line">    res = []</span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> matches:</span><br><span class="line">        number_dot, first_letter = <span class="keyword">match</span></span><br><span class="line">        res.append(first_letter)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="3-3-4-prompt设计"><a href="#3-3-4-prompt设计" class="headerlink" title="3.3.4 prompt设计"></a>3.3.4 prompt设计</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_prompt_en</span>(<span class="params">text</span>):</span><br><span class="line">    prompt = <span class="string">f&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择题，包含题目选项，以及对应的答案，注意：不⽤给出原文，每道题由1个问题和4个选项组成，仅存在1个正确答案，请严格按照要求执行。</span></span><br><span class="line"><span class="string">The reading text is mainly in English. The questions and answers you raised need to be completed in English for at least the following points:</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    ### 回答要求</span></span><br><span class="line"><span class="string">    (1)Understanding the main idea of the main idea.</span></span><br><span class="line"><span class="string">    (2)Understand the specific information in the text.</span></span><br><span class="line"><span class="string">    (3)infering the meaning of words and phrases from the context</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    ### 阅读文本</span></span><br><span class="line"><span class="string">    <span class="subst">&#123;text&#125;</span></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> prompt   </span><br></pre></td></tr></table></figure><p>可以看到代码里面首先对大模型做了声明，声明如下：</p><p><code>你是⼀个⾼考选择题出题专家，你出的题有⼀定深度，你将根据阅读文本，出4道单项选择题，包含题目选项，以及对应的答案，注意：不⽤给出原文，每道题由1个问题和4个选项组成，仅存在1个正确答案，请严格按照要求执行。</code></p><p><code>The reading text is mainly in English. The questions and answers you raised need to be completed in English for at least the following points:</code></p><p>这里是官方的声明，不建议修改~</p><p>接下来是要求部分：（这里建议大家根据出题要求做修改尝试~）</p><p><code>### 回答要求</code></p><p><code>(1)Understanding the main idea of the main idea.</code></p><p><code>(2)Understand the specific information in the text.</code></p><p><code>(3)infering the meaning of words and phrases from the context</code></p><p>最后是阅读材料，这里其实是我们传入的阅读材料参数。</p><p><code>### 阅读文本</code></p><p><code>&#123;text&#125;</code></p><h3 id="3-3-5-英文数据处理主函数"><a href="#3-3-5-英文数据处理主函数" class="headerlink" title="3.3.5 英文数据处理主函数"></a>3.3.5 英文数据处理主函数</h3><p>这里大家可以参考中文部分对比学习，相比中文简单很多~</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">process_en</span>(<span class="params">df</span>): </span><br><span class="line">    res_input = []</span><br><span class="line">    res_output = []</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(df)):</span><br><span class="line">        data_options = df.loc[<span class="built_in">id</span>, <span class="string">&#x27;选项&#x27;</span>]</span><br><span class="line">        data_answers = df.loc[<span class="built_in">id</span>,<span class="string">&#x27;答案&#x27;</span>]</span><br><span class="line">        data_prompt = df.loc[<span class="built_in">id</span>,<span class="string">&#x27;阅读文本&#x27;</span>]</span><br><span class="line">        data_options = get_questions(data_options)</span><br><span class="line">        data_answers = get_answers(data_answers)</span><br><span class="line">        data_prompt = get_prompt_en(data_prompt)</span><br><span class="line">        <span class="comment"># print(data_options)</span></span><br><span class="line">        <span class="comment"># print(data_answers)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">len</span>(data_answers)==<span class="built_in">len</span>(data_options)):</span><br><span class="line">            res = <span class="string">&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">id</span>,question <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_options):</span><br><span class="line">                res += <span class="string">f&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                <span class="subst">&#123;<span class="built_in">id</span>+<span class="number">1</span>&#125;</span>.<span class="subst">&#123;question[<span class="string">&#x27;question&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">                <span class="subst">&#123;question[<span class="string">&#x27;options&#x27;</span>][<span class="string">&#x27;A&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">                <span class="subst">&#123;question[<span class="string">&#x27;options&#x27;</span>][<span class="string">&#x27;B&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">                <span class="subst">&#123;question[<span class="string">&#x27;options&#x27;</span>][<span class="string">&#x27;C&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">                <span class="subst">&#123;question[<span class="string">&#x27;options&#x27;</span>][<span class="string">&#x27;D&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">                answer:<span class="subst">&#123;data_answers[<span class="built_in">id</span>]&#125;</span></span></span><br><span class="line"><span class="string">                &#x27;&#x27;&#x27;</span>+<span class="string">&#x27;\n&#x27;</span></span><br><span class="line">            res_output.append(res)</span><br><span class="line">            res_input.append(data_prompt)</span><br><span class="line">    <span class="keyword">return</span> res_input,res_output</span><br><span class="line">    <span class="comment"># break</span></span><br></pre></td></tr></table></figure><h2 id="3-4-数据合并"><a href="#3-4-数据合并" class="headerlink" title="3.4 数据合并"></a>3.4 数据合并</h2><p>因为微调需要150条数据，数据处理后得到有效数据为102，从中文抽取30条，英文抽取20条组成152条数据作为微调数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将两个列表转换为DataFrame</span></span><br><span class="line"></span><br><span class="line">df_new = pd.DataFrame(&#123;<span class="string">&#x27;input&#x27;</span>: cn_input+cn_input[:<span class="number">30</span>]+en_input+en_input[:<span class="number">20</span>], <span class="string">&#x27;output&#x27;</span>: cn_output+cn_output[:<span class="number">30</span>]+en_output+en_output[:<span class="number">20</span>]&#125;)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 专业前沿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Transformer解决机器翻译任务</title>
      <link href="/2024/08/04/%E5%9F%BA%E4%BA%8ETransformer%E8%A7%A3%E5%86%B3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%BB%BB%E5%8A%A1/"/>
      <url>/2024/08/04/%E5%9F%BA%E4%BA%8ETransformer%E8%A7%A3%E5%86%B3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%BB%BB%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Transformer-介绍"><a href="#一、Transformer-介绍" class="headerlink" title="一、Transformer 介绍"></a>一、Transformer 介绍</h2><p>基于<strong>循环</strong>或<strong>卷积</strong>神经网络的序列到序列建模方法是现存机器翻译任务中的经典方法。然而，它们在<strong>建模文本长程依赖方面都存在一定的局限性</strong>。</p><ul><li><p>对于<strong>卷积神经网络</strong>来说，受限的上下文窗口在建模长文本方面天然地存在不足。如果要对长距离依赖进行描述，需要多层卷积操作，而且不同层之间信息传递也可能有损失，这些都限制了模型的能力。</p></li><li><p>而对于<strong>循环神经网络</strong>来说，上下文的语义依赖是通过维护循环单元中的隐状态实现的。在编码过程中，每一个时间步的输入建模都涉及到对隐藏状态的修改。随着序列长度的增加，编码在隐藏状态中的序列早期的上下文信息被逐渐遗忘。尽管注意力机制的引入在一定程度上缓解了这个问题，但循环网络在编码效率方面仍存在很大的不足之处。由于编码端和解码端的每一个时间步的隐藏状态都依赖于前一时间步的计算结果，这就造成了在训练和推断阶段的低效。</p></li></ul><p><img src="/img/8.5.1.png" alt="Lena"></p><p>为了更好地描述文字序列，谷歌的研究人员在 2017 年提出了一种新的模型 Transformer，学有余力的同学可以阅读一下原论文《Attention Is All You Need》，也可以直接看李沐老师的B站讲解：<br><a href="https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.337.search-card.all.click&vd_source=57d58ebb10da27d2a5cc9f4134efb2b8">Transformer论文逐段精读【论文精读】_哔哩哔哩_bilibili</a></p><p>Transformer 在原论文中第一次提出就是将其应用到<strong>机器翻译</strong>领域，它的出现使得机器翻译的性能和效率迈向了一个新的阶段。它摒弃了循环结构，并完全通过<strong>注意力机制完成对源语言序列和目标语言序列全局依赖的建模</strong>。在<strong>抽取每个单词的上下文特征时，Transformer 通过自注意力机制（self-attention）衡量上下文中每一个单词对当前单词的重要程度。</strong></p><p>  <img src="/img/8.5.2.png" alt="Lena"></p><p>在这个过程当中没有任何的循环单元参与计算。这种<strong>高度可并行化</strong>的编码过程使得模型的运行变得十分高效。当前几乎<strong>大部分的大语言模型都是基于 Transformer 结构</strong>，本节以应用于机器翻译的基于Transformer 的编码器和解码器介绍该模型。</p><p>Transformer的主要组件包括<strong>编码器(Encoder)、解码器(Decoder)和注意力层</strong>。其核心是利用<strong>多头自注意力机制（Multi-Head Self-Attention）</strong>，使每个位置的表示不仅依赖于当前位置，还能够直接获取其他位置的表示。自从提出以来，Transformer模型在机器翻译、文本生成等自然语言处理任务中均取得了突破性进展，成为NLP领域新的主流模型。</p><p><strong>Transformer 是各种笔试面试中必考的一个地方，里面设计的考点很多，建议大家要好好学哦！</strong></p><p>学完之后可以尝试回答以下20道题：<a href="https://blog.csdn.net/m0_51879931/article/details/134142492">https://blog.csdn.net/m0_51879931/article/details/134142492</a></p><p>下图展示了 Transformer 模型的基本架构:<br><img src="/img/8.5.3.png" alt="Lena"></p><p>从宏观角度来看，Transformer的编码器是由多个相同的层叠加而成的，每个层都有两个子层（子层表示为sublayer）。第⼀个子层是<strong>多头自注意力（multi-head self-attention）汇聚</strong>；第二个子层是<strong>基于位置的前馈网络（positionwise feed-forward network）</strong>。主要涉及到如下几个模块：</p><h3 id="嵌入表示层"><a href="#嵌入表示层" class="headerlink" title="嵌入表示层"></a><strong>嵌入表示层</strong></h3><p>对于输入文本序列，先通过一个输入嵌入层（Input Embedding）<strong>将每个单词转换为其相对应的向量表示</strong>。通常直接对每个单词创建一个向量表示。由于 Transfomer 模型不再使用基于循环的方式建模文本输入，序列中不再有任何信息能够提示模型单词之间的相对位置关系。在送入编码器端建模其上下文语义之前，一个非常重要的操作是<strong>在词嵌入中加入位置编码（Positional Encoding）这一特征</strong>。具体来说，序列中每一个单词所在的位置都对应一个向量。这一向量会与单词表示对应相加并送入到后续模块中做进一步处理。在训练的过程当中，模型会自动地学习到如何利用这部分位置信息。为了得到不同位置对应的编码，Transformer 模型使用<strong>不同频率的正余弦函数</strong>如下所示：</p><p><img src="/img/8.5.4.png" alt="Lena"></p><p>其中，pos 表示单词所在的位置，2i 和 2i+1 表示位置编码向量中的对应维度，d则对应位置编码的总维度。<br>通过上面这种方式计算位置编码有这样几个好处：</p><ul><li><p>首先，正余弦函数的范围是在 [-1,+1]，导出的<strong>位置编码与原词嵌入相加不会使得结果偏离过远而破坏原有单词的语义信息</strong>。</p></li><li><p>其次，依据三角函数的基本性质，可以得知<strong>第</strong>pos+k <strong>个位置的编码是第</strong> pos <strong>个位置的编码的线性组合，这就意味着位置编码中蕴含着单词之间的距离信息</strong>。</p></li></ul><p><img src="/img/8.5.6.png" alt="Lena"></p><p>位置编码的维度和词嵌入向量的维度相同（ 均为 d_model），模型通过将二者相加作为模型输入</p><h3 id="注意力层"><a href="#注意力层" class="headerlink" title="注意力层"></a><strong>注意力层</strong></h3><p>自注意力（Self-Attention）操作是基于 Transformer 的机器翻译模型的基本操作，在源语言的编码和目标语言的生成中频繁地被使用以建模源语言、目标语言任意两个单词之间的依赖关系。给定由单词语义嵌入及其位置编码叠加得到的输入表示</p><p>{xi∈Rd}i&#x3D;1t{x_{i} \in \mathbb{R}^{d}}_{i&#x3D;1}^{t}{xi​∈Rd}i&#x3D;1t​，</p><p>为了实现对上下文语义依赖的建模，进一步引入在自注意力机制中涉及到的三个元素：查询 qiq_{i}qi​（Query），键 kik_{i}ki​（Key），值 viv_{i}vi​（Value）。在编码输入序列中每一个单词的表示的过程中，这三个元素用于计算上下文单词所对应的权重得分。直观地说，这些权重反映了在编码当前单词的表示时，对于上下文不同部分所需要的关注程度。</p><p>为了得到编码单词 xix_{i}xi​ 时所需要关注的上下文信息，通过位置 iii 查询向量与其他位置的键向量做点积得到匹配分数</p><p>qi⋅k1,qi⋅k2,…,qi⋅ktq_{i} \cdot k_{1}, q_{i} \cdot k_{2}, \ldots, q_{i} \cdot k_{t}qi​⋅k1​,qi​⋅k2​,…,qi​⋅kt​。</p><p>为了防止过大的匹配分数在后续 Softmax 计算过程中导致的梯度爆炸以及收敛效率差的问题，这些得分会除以放缩因子 d\sqrt{d} d​ 以稳定优化。放缩后的得分经过 Softmax 归一化为概率之后，与其他位置的值向量相乘来聚合希望关注的上下文信息，并最小化不相关信息的干扰。上述计算过程可以被形式化地表述如下：</p><p>Z&#x3D;Attention(Q,K,V)&#x3D;Softmax(QKTd)VZ &#x3D; \text{Attention}(Q, K, V) &#x3D; \text{Softmax}\left(\frac{QK^{T}}{\sqrt{d}}\right)VZ&#x3D;Attention(Q,K,V)&#x3D;Softmax(d​QKT​)V</p><p>其中 Q∈RL×dqQ \in \mathbb{R}^{L \times d_{q}}Q∈RL×dq​，K∈RL×dkK \in \mathbb{R}^{L \times d_{k}}K∈RL×dk​，V∈RL×dvV \in \mathbb{R}^{L \times d_{v}}V∈RL×dv​ 分别表示输入序列中的不同单词的 q,k,vq, k, vq,k,v 向量拼接组成的矩阵，LLL 表示序列长度，Z∈RL×dvZ \in \mathbb{R}^{L \times d_{v}}Z∈RL×dv​ 表示自注意力操作的输出。</p><h3 id="前馈层"><a href="#前馈层" class="headerlink" title="前馈层"></a>前馈层</h3><p>前馈层接受自注意力子层的输出作为输入，并通过一个带有 Relu 激活函数的两层全连接网络对输入进行更加复杂的非线性变换。实验证明，这一非线性变换会对模型最终的性能产生十分重要的影响。</p><p>FFN(x)&#x3D;Relu(xW1+b1)W2+b2FFN(x) &#x3D; \text{Relu}(xW_{1} + b_{1})W_{2} + b_{2}FFN(x)&#x3D;Relu(xW1​+b1​)W2​+b2​</p><p>其中 W1,b1,W2,b2W_{1}, b_{1}, W_{2}, b_{2}W1​,b1​,W2​,b2​ 表示前馈子层的参数。另外，以往的训练发现，增大前馈子层隐状态的维度有利于提升最终翻译结果的质量，因此，前馈子层隐状态的维度一般比自注意力子层要大。</p><h3 id="残差连接与层归一化"><a href="#残差连接与层归一化" class="headerlink" title="残差连接与层归一化"></a>残差连接与层归一化</h3><p>由 Transformer 结构组成的网络结构通常都是非常庞大。编码器和解码器均由很多层基本的 Transformer 块组成，每一层当中都包含复杂的非线性映射，这就导致模型的训练比较困难。因此，研究者们在 Transformer 块中进一步引入了残差连接与层归一化技术以进一步提升训练的稳定性。具体来说，残差连接主要是指使用一条直连通道直接将对应子层的输入连接到输出上去，从而避免由于网络过深在优化过程中潜在的梯度消失问题：</p><p>xl+1&#x3D;f(xl)+xlx^{l+1} &#x3D; f(x^l) + x^lxl+1&#x3D;f(xl)+xl</p><p>其中 xlx^lxl 表示第 lll 层的输入，f(⋅)f(\cdot)f(⋅) 表示一个映射函数。此外，为了进一步使得每一层的输入输出范围稳定在一个合理的范围内，层归一化技术被进一步引入每个 Transformer 块的当中：</p><p>LN(x)&#x3D;α⋅x−μσ+bLN(x) &#x3D; \alpha \cdot \frac{x - \mu}{\sigma} + bLN(x)&#x3D;α⋅σx−μ​+b</p><p>其中 μ\muμ 和 σ\sigmaσ 分别表示均值和方差，用于将数据平移缩放到均值为 0，方差为 1 的标准分布，α\alphaα 和 bbb 是可学习的参数。层归一化技术可以有效地缓解优化过程中潜在的不稳定、收敛速度慢等问题。</p><h3 id="编码器和解码器结构"><a href="#编码器和解码器结构" class="headerlink" title="编码器和解码器结构"></a><strong>编码器和解码器结构</strong></h3><p>根据给出的网络架构，编码器端可以较为容易实现。但相比于编码器端，解码器端要更复杂一些。具体来说，解码器的每个 Transformer 块的第一个自注意力子层额外增加了注意力掩码，对应图中的掩码多头注意力（Masked Multi-Head Attention）部分。这主要是因为在翻译的过程中，编码器端主要用于编码源语言序列的信息，而这个序列是完全已知的，因而编码器仅需要考虑如何融合上下文语义信息即可。而解码端则负责生成目标语言序列，这一生成过程是<strong>自回归</strong>的，即对于每一个单词的生成过程，仅有当前单词之前的目标语言序列是可以被观测的，因此这一额外<strong>增加的掩码是用来掩盖后续的文本信息，以防模型在训练阶段直接看到后续的文本序列进而无法得到有效地训练</strong>。</p><p>此外，解码器端还额外增加了一个<strong>多头注意力（Multi-Head Attention）模块</strong>，使用交叉注意力（Cross-attention）方法，同时接收来自编码器端的输出以及当前 Transformer 块的前一个掩码注意力层的输出。查询是通过解码器前一层的输出进行投影的，而键和值是使用编码器的输出进行投影的。它的作用是在翻译的过程当中，为了生成合理的目标语言序列需要观测待翻译的源语言序列是什么。基于上述的编码器和解码器结构，待翻译的源语言文本，先经过编码器端的每个Transformer 块对其上下文语义的层层抽象，然后输出每一个源语言单词上下文相关的表示。解码器端以自回归的方式生成目标语言文本，即在每个时间步 t ，根据编码器端输出的源语言文本表示，以及前 t-1 个时刻生成的目标语言文本，生成当前时刻的目标语言单词。</p><h2 id="二、基于-task2-的-baseline-修改代码"><a href="#二、基于-task2-的-baseline-修改代码" class="headerlink" title="二、基于 task2 的 baseline 修改代码"></a>二、基于 task2 的 baseline 修改代码</h2><p>我们还是以 task2 给出的 baseline 代码为基础，进行修改，主要修改模型结构部分的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 位置编码</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, dropout=<span class="number">0.1</span>, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + self.pe[:x.size(<span class="number">0</span>), :]</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transformer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, src_vocab, tgt_vocab, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout</span>):</span><br><span class="line">        <span class="built_in">super</span>(TransformerModel, self).__init__()</span><br><span class="line">        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)</span><br><span class="line">        self.src_embedding = nn.Embedding(<span class="built_in">len</span>(src_vocab), d_model)</span><br><span class="line">        self.tgt_embedding = nn.Embedding(<span class="built_in">len</span>(tgt_vocab), d_model)</span><br><span class="line">        self.positional_encoding = PositionalEncoding(d_model, dropout)</span><br><span class="line">        self.fc_out = nn.Linear(d_model, <span class="built_in">len</span>(tgt_vocab))</span><br><span class="line">        self.src_vocab = src_vocab</span><br><span class="line">        self.tgt_vocab = tgt_vocab</span><br><span class="line">        self.d_model = d_model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src, tgt</span>):</span><br><span class="line">        <span class="comment"># 调整src和tgt的维度</span></span><br><span class="line">        src = src.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># (seq_len, batch_size)</span></span><br><span class="line">        tgt = tgt.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># (seq_len, batch_size)</span></span><br><span class="line"></span><br><span class="line">        src_mask = self.transformer.generate_square_subsequent_mask(src.size(<span class="number">0</span>)).to(src.device)</span><br><span class="line">        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(<span class="number">0</span>)).to(tgt.device)</span><br><span class="line"></span><br><span class="line">        src_padding_mask = (src == self.src_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        tgt_padding_mask = (tgt == self.tgt_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        src_embedded = self.positional_encoding(self.src_embedding(src) * math.sqrt(self.d_model))</span><br><span class="line">        tgt_embedded = self.positional_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model))</span><br><span class="line"></span><br><span class="line">        output = self.transformer(src_embedded, tgt_embedded,</span><br><span class="line">                                  src_mask, tgt_mask, <span class="literal">None</span>, src_padding_mask, tgt_padding_mask, src_padding_mask)</span><br><span class="line">        <span class="keyword">return</span> self.fc_out(output).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>然后在主函数里定义 Transformer 模型调用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = TransformerModel(src_vocab, tgt_vocab, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP入门</title>
      <link href="/2024/08/04/NLP%E5%85%A5%E9%97%A8/"/>
      <url>/2024/08/04/NLP%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="机器翻译的发展历程"><a href="#机器翻译的发展历程" class="headerlink" title="机器翻译的发展历程"></a>机器翻译的发展历程</h1><p>机器翻译（Machine Translation，简称MT）是自然语言处理领域的一个重要分支，其目标是<strong>将一种语言的文本自动转换为另一种语言的文本</strong>。机器翻译的发展可以追溯到20世纪50年代，经历了从基于规则的方法、统计方法到深度学习方法的演变过程。</p><p><img src="/img/8.4.1.png" alt="Lena"></p><ol><li><strong>基于规则的机器翻译（1950s-1980s）</strong>：</li></ol><p>早期的机器翻译系统主要采用基于规则的方法，即利用<strong>语言学家编写的语法规则和词典进行翻译</strong>。这种方法需要对源语言和目标语言的语法和词汇有深入的理解，但其灵活性和适应性较差，难以处理复杂的语言结构和多义词问题。</p><p>基于规则的机器翻译是机器翻译任务的第一套解决方案，它基于“每一种语义在不同的语言当中都存在与其相对应的符号”这一假设。对于某种语言中的大多数单词而言，通常都能够在另一种语言当中找到表达相同含义的对应的单词。在这类方法当中，翻译过程通常被看作一个源语言的词替换过程。</p><p>之所以被称为“基于规则的方法”，是因为同一种语义在不同的语言当中通常会以不同的词序去表达，词替换过程相对应地需要两种语言的句法规则作为指导。源语言中的每一个单词需要被放置在目标语言中相对应的位置。基于规则的机器翻译方法的理论非常简洁清晰，但在实践中的性能却不尽如人意。这是由于选择与给定源语言相适配的句法规则在计算上非常低效。同时，为了应对多样的语言现象，语言学家们设计了规模庞大的句法规则。</p><p>但是，这些规则很难被有效地组织，甚至会出现不同规则相互矛盾的情况。基于规则的方法最严重的缺陷在于其缺乏翻译过程中对上下文信息的建模，这使得基于规则的翻译模型的鲁棒性不佳。</p><ol start="2"><li><strong>基于统计的机器翻译（1990s-2000s）</strong>：</li></ol><p>随着计算机性能的提升和大规模平行语料库的出现，统计机器翻译开始兴起。这种方法<strong>通过分析大量双语文本，自动学习源语言和目标语言之间的对应关系</strong>，从而实现翻译。统计机器翻译在处理多义词和语言变异方面表现出更好的效果，但由于其依赖于大量训练数据，对于资源匮乏的语言支持不足。</p><p>与基于规则的机器翻译方法不同，统计机器翻译完全从数据驱动的角度建模机器翻译任务。具体来说，通过对双语语料库的统计找到表达相同含义的单词或短语。给定一个源语言句子，统计机器翻译首先将其分割成若干个子句，接下来每个部分可以被目标语言的单词或短语替代。</p><p>统计机器翻译中最主流的方法是基于词的统计机器翻译（Word-based MT）以及基于短语的统计机器翻译（Phrase-based SMT），总体上来看包含预处理、句子对齐、词对齐、短语抽取、短语特征准备、语言模型训练等步骤。</p><ol start="3"><li><strong>基于神经网络机器翻译（2010s-present）</strong>：</li></ol><p>神经网络方法在机器翻译任务上的应用可以追溯到上世纪八九十年代。但受限于当时的计算资源和数据规模的限制，神经网络方法的性能差强人意，故而其发展停滞了很多年。</p><p>近年来，深度学习技术的快速发展推动了神经网络机器翻译（Neural Machine Translation，简称NMT）的兴起。NMT使用深度神经网络模型，如<strong>长短期记忆网络（LSTM）和 Transformer</strong>，能够自动学习源语言和目标语言之间的复杂映射关系，无需人工设计特征或规则。NMT在翻译质量、速度和适应性方面取得了显著进步，成为当前机器翻译领域的主流方法。</p><ol start="4"><li><strong>未来发展趋势</strong>：</li></ol><p>当前，机器翻译正朝着更加智能化和个性化方向发展。一方面，结合上下文理解、情感分析等技术，提高翻译的准确性和自然度；另一方面，通过用户反馈和个性化学习，提供更加符合用户需求的翻译服务。同时，跨语言信息检索、多模态翻译等新兴领域也正在成为研究热点。</p><p>总的来说，机器翻译的发展历程是从规则驱动到数据驱动，再到智能驱动的过程，反映了自然语言处理技术的进步和应用需求的变化。</p><h1 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h1><p>在机器学习和深度学习项目中，数据集通常被划分为三个部分：训练集（Training Set）、开发集（Development Set，也常被称为验证集，Validation Set）和测试集（Test Set）。这种划分的主要目的是为了评估模型的性能并防止过拟合，确保模型具有良好的泛化能力。下面是这三个数据集的具体作用：</p><ol><li><p><strong>训练集（Training Set）</strong>：</p><ol><li><p>作用：训练集用于训练模型，使模型能够学习输入数据与输出结果之间的映射关系。模型会根据训练集中的样本调整其参数，以最小化预测误差。</p></li><li><p>目标：让模型在训练数据上尽可能地拟合好，学习到数据的内在规律。</p></li></ol></li><li><p><strong>开发集&#x2F;验证集（Development&#x2F;Validation Set）</strong>：</p><ol><li><p>作用：开发集用于在模型训练过程中调整超参数、选择模型架构以及防止过拟合。它作为独立于训练集的数据，用于评估模型在未见过的数据上的表现。</p></li><li><p>目标：通过在开发集上的性能评估，选择最佳的模型配置，避免模型在训练集上过度拟合，确保模型的泛化能力。</p></li></ol></li><li><p><strong>测试集（Test Set）</strong>：</p><ol><li><p>作用：测试集用于最终评估模型的性能，是在模型训练和调参完全完成后，用来衡量模型实际应用效果的一组数据。它是最接近真实世界数据的评估标准。</p></li><li><p>目标：提供一个公正、无偏见的性能估计，反映模型在未知数据上的泛化能力。</p></li></ol></li></ol><h1 id="赛题解析"><a href="#赛题解析" class="headerlink" title="赛题解析"></a>赛题解析</h1><h3 id="赛事背景"><a href="#赛事背景" class="headerlink" title="赛事背景"></a>赛事背景</h3><p>目前<strong>神经机器翻译</strong>技术已经取得了很大的突破，但<strong>在特定领域或行业中，由于机器翻译难以保证术语的一致性，导致翻译效果还不够理想</strong>。对于术语名词、人名地名等机器翻译不准确的结果，可以<strong>通过术语词典进行纠正</strong>，避免了混淆或歧义，最大限度提高翻译质量。</p><h3 id="赛事任务"><a href="#赛事任务" class="headerlink" title="赛事任务"></a>赛事任务</h3><p><strong>基于术语词典干预的机器翻译挑战赛</strong>选择以英文为源语言，中文为目标语言的机器翻译。本次大赛除英文到中文的双语数据，还提供英中对照的术语词典。参赛队伍需要基于提供的训练数据样本从<strong>多语言机器翻译模型的构建与训练，并基于测试集以及术语词典，提供最终的翻译结果</strong></p><h3 id="赛题数据"><a href="#赛题数据" class="headerlink" title="赛题数据"></a>赛题数据</h3><ul><li><p>训练集：双语数据 - 中英14万余双语句对</p></li><li><p>开发集：英中1000双语句对</p></li><li><p>测试集：英中1000双语句对</p></li><li><p>术语词典：英中2226条</p></li><li><p><strong>训练集（training set）</strong>用于运行你的学习算法。</p></li><li><p><strong>开发集（development set）</strong>用于调整参数，选择特征，以及对学习算法作出其它决定。有时也称为<strong>留出交叉验证集（hold-out cross validation set）</strong>。</p></li><li><p><strong>测试集（test set）</strong>用于评估算法的性能，但不会据此改变学习算法或参数。</p></li></ul><h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><p>对于参赛队伍提交的测试集翻译结果文件，采用自动评价指标 <strong>BLE**<strong>U</strong></strong>-4** 进行评价，具体工具使用 <strong>sacrebleu开源版本</strong>。</p><p>什么是 <strong>BLEU-4</strong></p><p><code>BLEU</code>，全称为<code>Bilingual Evaluation Understudy</code>（双语评估替换），是一种对<code>生成语句</code>进行<code>评估的指标</code>。BLEU 评分是由Kishore Papineni等人2002年的论文<a href="http://www.aclweb.org/anthology/P02-1040.pdf">《BLEU: a Method for Automatic Evaluation of Machine Translation》</a>中提出的。</p><p>在机器翻译领域，BLEU（Bilingual Evaluation Understudy）是一种常用的自动评价指标，用于衡量<strong>计算机生成的翻译与一组参考译文之间的相似度</strong>。这个指标特别关注 <strong>n-grams</strong>（连续的n个词）的精确匹配，可以被认为是对翻译准确性和流利度的一种统计估计。计算BLEU分数时，首先会统计生成文本中n-grams的频率，然后将这些频率与参考文本中的n-grams进行比较。如果生成的翻译中包含的n-grams与参考译文中出现的相同，则认为是匹配的。最终的BLEU分数是一个介于0到1之间的数值，其中1表示与参考译文完美匹配，而0则表示完全没有匹配。</p><p><strong>BLEU-4</strong> 特别指的是在计算时考虑四元组（即连续四个词）的匹配情况。</p><p><strong>BLEU</strong> 评估指标的特点：</p><ul><li><p>优点：计算速度快、计算成本低、容易理解、与具体语言无关、和人类给的评估高度相关。</p></li><li><p>缺点：不考虑语言表达（语法）上的准确性；测评精度会受常用词的干扰；短译句的测评精度有时会较高；没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定。</p></li></ul><p>除了翻译之外，BLEU评分结合深度学习方法可应用于其他的语言生成问题，例如：语言生成、图片标题生成、文本摘要、语音识别。</p><h2 id="基于-Seq2Seq-的-Baseline-详解"><a href="#基于-Seq2Seq-的-Baseline-详解" class="headerlink" title="基于 Seq2Seq 的 Baseline 详解"></a>基于 <strong>Seq2Seq 的</strong> Baseline 详解</h2><hr><h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><p>运行环境我们还是基于<a href="https://modelscope.cn/my/mynotebook/preset">魔搭</a>平台进行模型训练，这里不再重复说明。另外，有几个包需要额外安装：</p><ul><li><p><strong>torchtext</strong> ：是一个用于自然语言处理（NLP）任务的库，它提供了丰富的功能，包括数据预处理、词汇构建、序列化和批处理等，特别适合于文本分类、情感分析、机器翻译等任务</p></li><li><p>**<code>jieba</code>**<strong>：</strong>是一个中文分词库，用于将中文文本切分成有意义的词语</p></li><li><p><strong>sacrebleu</strong>：用于评估机器翻译质量的工具，主要通过计算BLEU（Bilingual Evaluation Understudy）得分来衡量生成文本与参考译文之间的相似度</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!pip install torchtext    </span><br><span class="line">!pip install jieba</span><br><span class="line">!pip install sacrebleu</span><br></pre></td></tr></table></figure><ul><li><strong>spacy</strong>：是一个强大的自然语言处理库，支持70+语言的分词与训练</li></ul><p>这里，我们需要安装 spacy 用于英文的 <strong>tokenizer（分词，就是将句子、段落、文章这种长文本，分解为以字词为单位的数据结构</strong>，方便后续的处理分析工作），不同环境的安装请参考：<a href="https://spacy.io/usage">https://spacy.io/usage</a></p><p>将下载到本地的压缩包上传到你的魔搭平台上的 dataset 目录下:<br><img src="/img/8.4.2.png" alt="Lena"></p><p>然后使用 <code>!pip install ../dataset/en_core_web_trf</code>安装英文语言包：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!pip install -U pip setuptools wheel -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install -U &#x27;spacy[cuda12x,transformers,lookups]&#x27; -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">!pip install ../dataset/en_core_web_trf-3.7.3-py3-none-any.whl</span><br></pre></td></tr></table></figure><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>机器翻译任务的预处理是确保模型能够有效学习源语言到目标语言映射的关键步骤。预处理阶段通常包括多个步骤，旨在清理、标准化和转换数据，使之适合模型训练。以下是机器翻译任务预处理中常见的几个处理步骤：</p><ul><li><p><strong>清洗和规范化数据</strong></p><ul><li><p><strong>去除无关信息</strong>：删除HTML标签、特殊字符、非文本内容等，确保文本的纯净性（本赛题的训练集中出现了非常多的脏数据，如“Joey. （掌声） （掌声） 乔伊”、“Thank you. （马嘶声） 谢谢你们”等这种声音词）</p></li><li><p><strong>统一格式</strong>：转换所有文本为小写，确保一致性；标准化日期、数字等格式。</p></li><li><p><strong>分句和分段</strong>：将长文本分割成句子或段落，便于处理和训练。</p></li></ul></li><li><p><strong>分词</strong></p><ul><li><strong>分词</strong>：将句子分解成<strong>单词或词素</strong>（构成单词的基本组成部分，一个词素可以是一个完整的单词，也可以是单词的一部分，但每一个词素都至少携带一部分语义或语法信息），这是NLP中最基本的步骤之一。我们这里使用了使用<code>jieba</code> 对中文进行分词，使用<code>spaCy</code>对英文进行分词。</li></ul></li><li><p><strong>构建词汇表和词向量</strong></p><ul><li><p><strong>词汇表构建</strong>：从训练数据中收集所有出现过的词汇，<strong>构建词汇表，并为每个词分配一个唯一的索引</strong>。</p></li><li><p><strong>词向量</strong>：使用预训练的词向量或自己训练词向量，将词汇表中的词映射到高维空间中的向量，以捕捉语义信息（当前大模型领域训练的 embedding 模型就是用来完成此任务的）。</p></li></ul></li><li><p><strong>序列截断和填充</strong></p><ul><li><p><strong>序列截断</strong>：限制输入序列的长度，过长的序列可能增加计算成本，同时也可能包含冗余信息。</p></li><li><p><strong>序列填充</strong>：将所有序列<strong>填充至相同的长度，便于批量处理</strong>。通常使用<code>&lt;PAD&gt;</code>标记填充。</p></li></ul></li><li><p><strong>添加特殊标记</strong></p><ul><li><p><strong>序列开始和结束标记</strong>：在<strong>序列两端</strong>添加<code>&lt;SOS&gt;</code>（Sequence Start）和<code>&lt;EOS&gt;</code>（Sequence End）标记，帮助模型<strong>识别序列的起始和结束</strong>。</p></li><li><p><strong>未知词标记</strong>：为不在词汇表中的词添加<code>&lt;UNK&gt;</code>（Unknown）标记，使模型能够<strong>处理未见过的词汇</strong>。</p></li></ul></li><li><p><strong>数据增强</strong></p><ul><li><p><strong>随机替换或删除词</strong>：在训练数据中随机替换或删除一些词，增强模型的鲁棒性。</p></li><li><p><strong>同义词替换</strong>：使用同义词替换原文中的词，增加训练数据的多样性。</p></li></ul></li><li><p><strong>数据分割</strong></p><ul><li><strong>划分数据集</strong>：将数据划分为训练集、验证集和测试集，分别用于模型训练、参数调整和最终性能评估（该赛题中已划分好，不需要自己进行划分）</li></ul></li></ul><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>说到<strong>神经机器翻译</strong>就不得不提<strong>编码器-解码器模型</strong>，或编码器-解码器框架（EncoderDecoder Paradigm）。本质上，编码器­解码器模型是描述输入­输出之间关系的一种方式。编码器­解码器这个概念在日常生活中并不少见。</p><p>例如，在电视系统上为了便于视频的传播，会使用各种编码器将视频编码成数字信号，在客户端，相应的解码器组件会把收到的数字信号解码为视频。另外一个更贴近生活的例子是电话，它通过对声波和电信号进行相互转换，达到传递声音的目的。</p><p>这种“<strong>先编码，再解码</strong>”的思想被应用到密码学、信息论等多个领域。不难看出，机器翻译问题也完美的贴合编码器­解码器结构的特点。可以将源语言编码为类似信息传输中的数字信号，然后利用解码器对其进行转换，生成目标语言。下面就来看一下神经机器翻译是如何在编码器­解码器框架下进行工作的。</p><p>下面是一个应用编码器­解码器结构来解决汉译英的例子：<br><img src="/img/8.4.3.png" alt="Lena"></p><p>给定一个中文句子“我&#x2F;对&#x2F;你&#x2F;感到&#x2F;满意”，<strong>编码器</strong>会将这句话编码成一个<strong>实数向量(0.2, −1, 6, 5, 0.7, −2)<strong>，这个向量就是源语言句子的“表示”结果。虽然有些不可思议，但是神经机器翻译模型把这个向量等同于输入序列。向量中的数字并没有实际的意义，然而</strong>解码器</strong>却能从中提取到源语言句子中所包含的信息。也有研究人员<strong>把向量的每一个维度看作是一个“特征”</strong>，这样源语言句子就被表示成多个“特征”的联合，而且这些特征可以被自动学习。有了这样的源语言句子的“表示”，解码器可以把这个实数向量作为输入，然后逐词生成目标语言句子“I am satisfied with you”。</p><p>在源语言句子的表示形式确定之后，需要设计相应的编码器和解码器结构。在当今主流的神经机器翻译系统中，<strong>编码器由词嵌入层和中间网络层组成：</strong></p><ul><li><p>当输入一串单词序列时，词嵌入层(embedding)会<strong>将每个单词映射到多维实数表示空间</strong>，这个过程也被称为<strong>词嵌入</strong>。</p></li><li><p>之后<strong>中间层</strong>会对词嵌入向量进行更深层的抽象，得到输入单词序列的中间表示。中间层的实现方式有很多，比如：<strong>循环神经网络、卷积神经网络、自注意力机制</strong>等都是模型常用的结构。</p></li></ul><p><strong>解码器的结构基本上和编码器是一致的</strong>，在基于循环神经网络的翻译模型中，解码器只比编码器多了输出层，用于输出每个目标语言位置的单词生成概率，而在基于自注意力机制的翻译模型中，除了输出层，解码器还比编码器多一个编码­解码注意力子层，用于帮助模型更好地利用源语言信息。</p><p>我们以 <strong>基于循环神经网络的机器翻译模型为例，说明其整体结构。其中，左侧为</strong>编码器部分，源语言单词按照其在文本序列中的先后顺序被依次送入到循环神经网络（RNN）当中。在每个时间步 t 中，模型依据送入的源语言单词xt对应修改并维护其模型内部的隐状态 ht，这个隐状态编码了输入的源语言序列前 t 个时刻的所有必要信息。按照这种方式当 m 个输入全部被送入到编码器之后，所对应的 hm可以认为包含了源语言序列的所有信息。<br><img src="/img/8.4.4.png" alt="Lena"></p><p>右半部分是 <strong>RNN 解码器部分</strong>，它接收编码器输出的编码源语言句子信息的向量 hm作为初始隐状态 s0。由于 RNN 的循环过程在每个时间步都要求一个输入单词，为了启动解码过程，一般会使用一个保留的特殊符号 “[Start]” 作为翻译开始的标记送入到 RNN 解码器当中并解码出目标语言序列的第一个单词 $$$$。接下来，z1 会作为下一个时刻的输入被送入到循环神经网络当中，并按照不断迭代产生后续的预测。由于目标语言序列的长度无法被提前预知，因此使用另一个保留符号 “[Stop]” 作为预测结束的标志。当某一个时刻 t 预测出的目标语言单词为 zt &#x3D;“[Stop]” 时，解码过程动态地停止。在上述过程当中，主要涉及到两步运算，第一步是 RNN 接收前一时刻隐状态 st-1 并依据当前时刻输入 zt-1（目标语言单词 zt-1 对应的语义嵌入）对隐状态进行维护并生成st的运算过程，第二步是依据当前时刻隐状态生成目标语言单词的过程：<br><img src="/img/8.4.5.png" alt="Lena"></p><p>其中 U,W,V 是可学习的参数。<strong>U,W 负责维护循环状态，而 V 负责将当前时刻状态转换到词表大小的概率分布</strong><br>$$P \in R^{vocab_size} $$，从中可以采样得到目标语言单词 zt。</p><p>通过循环网络对源语言文本进行编码，并生成目标语言翻译结果的过程十分简单。然而，它<strong>仅仅使用一个定长的向量</strong> hm <strong>编码整个源语言序列。这对于较短的源语言文本没有什么问题，但随着文本序列长度的逐渐加长，单一的一个向量 hm 可能不足以承载源语言序列当中的所有信息</strong>。</p><p><img src="/img/8.4.6.png" alt="Lena"></p><p>蓝色的线代表上述简单循环神经网络性能随源语言文本长度的变化趋势。当文本长度在 20 个单词以内时，单一向量能够承载源语言文本中的必要信息。随着文本序列的进一步增加，翻译性能的评价指标 BLEU 的值就开始出现明显地下降。因此，这就启发我们使用更加有效地机制从编码器向解码器传递源语言信息，这就是接下来要讲到的注意力机制。</p><p>引入注意力机制的循环机器翻译架构与基于简单循环网络的机器翻译模型大体结构相似，均采用循环神经网络作为编码器与解码器的实现。关键的不同点在于<strong>注意力机制的引入使得不再需要把原始文本中的所有必要信息压缩到一个向量当中</strong>。引入注意力机制的循环神经网络机器翻译架构如图所示:</p><p>  <img src="/img/8.4.7.png" alt="Lena"></p><p>传统的 Seq2Seq 模型在解码阶段仅依赖于编码器产生的最后一个隐藏状态，这在<strong>处理长序列时效果不佳</strong>。注意力机制允许解码器在生成每个输出词时，关注编码器产生的所有中间状态，从而更好地利用源序列的信息。具体来说，给定源语言序列经过编码器输出的向量序列 $$h_{1},h_{2},h_{3},…,h_{m}$$，<strong>注意力机制旨在依据解码端翻译的需要，自适应地从这个向量序列中查找对应的信息</strong>。</p><p><strong>我们的 baseline 代码中实现了一个经典的序列到序列(Seq2Seq)模型，中间层使用的GRU网络，并且网络中加入了注意力机制(Attention Mechanism)，请你参考上述基于注意力机制的循环神经网络机器翻译，以及GRU的相关知识，画出基于注意力机制的 GRU 神经网络机器翻译！</strong></p><ul><li>GRU 知识讲解：<a href="https://zh.d2l.ai/chapter_recurrent-modern/gru.html">https://zh.d2l.ai/chapter_recurrent-modern/gru.html</a></li></ul><h3 id="翻译质量评价"><a href="#翻译质量评价" class="headerlink" title="翻译质量评价"></a>翻译质量评价</h3><p>人们在使用机器翻译系统时需要评估系统输出结果的质量。这个过程也被称作<strong>机器翻译译文质量评价</strong>，简称为<strong>译文质量评价</strong>（Quality Evaluation of Translation）。在机器翻译的发展进程中，译文质量评价有着非常重要的作用。不论在系统研发的反复迭代中，还是在诸多的机器翻译应用场景中，都存在大量的译文质量评价环节。从某种意义上说，没有译文质量评价，机器翻译也不会发展成今天的样子。比如，本世纪初研究人员提出了译文质量自动评价方法 <strong>BLEU（Bilingual Evaluation Understudy）（Task 1知识文档已详细介绍过）</strong>。该方法使得机器翻译系统的评价变得自动、快速、便捷，而且评价过程可以重复。正是由于 BLEU 等自动评价方法的提出，机器翻译研究人员可以在更短的时间内得到译文质量的评价结果，加速系统研发的进程。</p><p>传统观点把翻译分为&#x3D;&#x3D;“信” “达” “雅” *&#x3D;&#x3D; 三个层次，而<strong>忠诚度</strong>体现的是一种“信”的思想，而<strong>流畅度</strong>体现的是一种“达”的思想。不过“雅”在机器翻译评价中还不是一个常用的标准，而且机器翻译还没有达到“雅”的水平，是未来所追求的目标。给定评价标准，译文质量评价有很多实现方式，下图给出了机器翻译译文评价方法的逻辑关系图：</p><p>  <img src="/img/8.4.8.png" alt="Lena"></p><ul><li><p>人工评价。当需要对系统进行准确的评估时，往往采用人工评价。比如，对于机器翻译的一些互联网应用，在系统上线前都会采用人工评价对机器翻译系统性能进行测试。当然，这种方法的时间和人力成本是最高的。</p></li><li><p>有参考答案的自动评价。由于机器翻译系统研发过程中需要频繁地对系统性能进行评价，这时可以让人标注一些正确的译文，之后把这些译文作为参考答案与机器翻译系统输出的结果进行比对。这种自动评价的结果获取成本低，可以多次重复，而且可以用于对系统结果的快速反馈，指导系统优化的方向。</p></li><li><p>无参考答案的自动评价。在很多应用场景中，在系统输出译文时，使用者希望提前知道译文的质量，即使这时并没有可比对的参考答案。这样，系统使用者可以根据这个对质量的“估计”结果有选择地使用机器翻译译文。严格意义上说，这并不是一个传统的译文质量评价方法，而是一种对译文置信度和可能性的估计。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>超算简介</title>
      <link href="/2024/05/29/%E8%B6%85%E7%AE%97%E7%AE%80%E4%BB%8B/"/>
      <url>/2024/05/29/%E8%B6%85%E7%AE%97%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是超级计算技术？"><a href="#什么是超级计算技术？" class="headerlink" title="什么是超级计算技术？"></a>什么是超级计算技术？</h1><p>超级计算技术包括超级计算机，世界上最快的计算机。 超级计算机由互连、输入&#x2F;输出系统、内存和处理器核心组成。</p><p>不同于传统的计算机，超级计算机使用多个中央处理器 (CPU)。 这些 CPU 分组成多个计算节点，包含一个处理器或一组处理器（对称多处理 (SMP)）和一个内存块。 在规模上，超级计算机可以包含数万个节点。 凭借互连通信能力，这些节点可以协作解决特定问题。 节点也使用互连功能与输入&#x2F;输出系统通信，比如<a href="https://www.ibm.com/cn-zh/topics/data-storage">数据存储</a> 和<a href="https://www.ibm.com/cn-zh/cloud/learn/networking-a-complete-guide">联网</a>。</p><p>需要注意的一点是，由于现代超级计算机的功耗，数据中心需要冷却系统和合适的设施来容纳所有的这些设备。</p><hr><h1 id="超级计算有什么用？"><a href="#超级计算有什么用？" class="headerlink" title="超级计算有什么用？"></a>超级计算有什么用？</h1><p>医疗方向：机器学习算法将帮助医学研究人员全面了解美国抗癌人患者的详细情况。当然巨大的算力，也就意味着超级计算有着举足轻重的地位。<a href="https://www.ibm.com/blogs/research/2019/07/ai-tools-for-cancer-research/">对抗癌症</a><br>识别下一代材料：深度学习可以帮助科学家识别更好的电池材料，更具弹性的建筑材料和更搞笑的半导体材料。<a href="https://research.ibm.com/blog/ibm-molecule-generation-experience">识别下一代材料</a><br>了解疾病类型：通过混合使用人工智能技术，研究人员将确定人类蛋白质和细胞系统的功能、合作和进化模式。<a href="https://newsroom.ibm.com/IBM-helps-bring-supercomputers-into-the-global-fight-against-COVID-19">了解疾病类型</a></p><hr><h1 id="超级计算和人工智能"><a href="#超级计算和人工智能" class="headerlink" title="超级计算和人工智能"></a>超级计算和人工智能</h1><p>因为超级计算机经常用来运行<a href="https://www.ibm.com/cn-zh/cloud/learn/what-is-artificial-intelligence">人工智能</a> 程序，所以超级计算已经成为人工智能的代名词。 这种常规的用法是因为人工智能程序需要超计算机提供的高性能计算。 换言之，超级计算机可以处理人工智能应用程序通常需要的工作负载类型。</p><p>IBM 专门针对大数据和人工智能工作负载构建了 <a href="https://www.ibm.com/thought-leadership/summit-supercomputer/">Summit 和 Sierra 超级计算机</a> 。 它们将帮助我们模拟超新星，开拓新材料，探索癌症治疗、遗传学与环境 - 利用面向所有业务领域的技术。</p><hr><p>超级计算有多快？</p><p>超级计算以每秒浮点运算次数 (FLOPS) 衡量。 Petaflops 是计算机处理速度的一种度量单位，等同于每秒千万亿次浮点运算。 速度为 1 petaflop 的计算机系统每秒可以执行百万的四次方次浮点运算 (1015)。 从另一个角度来说，超级计算机的处理能力比最快的笔记本电脑高出一百万倍。  </p><p>最快的超级计算机是什么？</p><p>根据 <a href="https://www.top500.org/lists/top500/2021/06/">500 强名单</a> （链接位于 ibm.com 外部），世界上最快的超级计算机是日本的 Fugaku，截至 2021 年 6 月统计的速度是 442 petaflop。 IBM 超级计算机 Summit 和 Sierra 分别位列第二名和第三名，速度分别是 148.8 和 94.6 petaflop。 Summit 位于橡树岭国家实验室，这是美国能源部在田纳西州设立的设施。 Sierra 位于加利福尼亚州的劳伦斯利弗莫尔国家实验室。</p><p>为了清楚地认识现在的速度，1976 年在洛斯阿拉莫斯国家实验室安装 Cray-1 时，它的速度能达到约 160 megaflop。 1 megaflop 可以执行一百万次 (106) 浮点运算。</p><hr><h1 id="超级计算与……"><a href="#超级计算与……" class="headerlink" title="超级计算与……"></a>超级计算与……</h1><p>超级计算一词有时用于指代其他类型的计算。 但是其他时候，这些同义词可能会令人困惑。 为了阐明计算类型之间的一些异同，下面介绍一些常见的比较。  </p><h2 id="超级计算与高性能计算"><a href="#超级计算与高性能计算" class="headerlink" title="超级计算与高性能计算"></a>超级计算与高性能计算</h2><p>超级计算通常是指超级计算机使用的复杂的大型计算过程，而<a href="https://www.ibm.com/cn-zh/topics/hpc">高性能计算</a>（HPC）是指使用多台超级计算机来处理复杂的大型计算。 这两个术语经常互换使用。</p><h2 id="超级计算与并行计算"><a href="#超级计算与并行计算" class="headerlink" title="超级计算与并行计算"></a>超级计算与并行计算</h2><p>超级计算机有时也被称为并行计算机，因为超级计算机可以使用并行处理。 并行处理是指多个 CPU 在给定时间共同对单个计算求解。 然而，HPC 场景也使用并行性，但不一定使用超级计算机。</p><p>另一个例外是，超级计算机可以使用其他处理器系统，例如向量处理器、标量处理器或多线程处理器。</p><p><a href="https://www.ibm.com/quantum-computing">量子计算</a>是一种计算模型，它利用量子力学定律来处理数据，根据概率执行计算。 它旨在解决世界上最强大的超级计算机无法且永远不会解决的复杂问题。</p><hr><h1 id="超级计算的历史"><a href="#超级计算的历史" class="headerlink" title="超级计算的历史"></a>超级计算的历史</h1><h2 id="超级计算是什么时候出现的？"><a href="#超级计算是什么时候出现的？" class="headerlink" title="超级计算是什么时候出现的？"></a>超级计算是什么时候出现的？</h2><p>超级计算已有多年的发展历史。20 世纪 40 年代，当巨人计算机被运到布莱切利园并正式开始使用时，超级计算就诞生了。 巨人计算机是第一台具有一定功能的电子数字计算机，由邮政总局 (GPO) 研究电话工程师 Tommy Flowers 设计。</p><h2 id="超级计算机最早是什么时候发明的？"><a href="#超级计算机最早是什么时候发明的？" class="headerlink" title="超级计算机最早是什么时候发明的？"></a>超级计算机最早是什么时候发明的？</h2><p><em>超级计算机</em> 一词最早是在 20 世纪 60 年代初开始使用，当时 IBM 推出了 IBM 7030 Stretch，同时 Sperry Rand 公开了 UNIVAC LARC，这是最早的两台专门的超级计算机，其功能远远超过当时最快的商用电脑。 真正影响超级计算机发展进程的事件是 20 世纪 50 年代末美国政府开始定期拨款，资助开发前沿的高性能计算机技术以用于军事应用。</p><p>尽管超级计算机最初生产数量有限，并且仅为政府所用，但这项逐渐进步的技术最终在工业和商业主流中找到了用武之地。 例如，Control Data Corporation (CDC) 和 Cray Research 这两家美国公司从六十年代中期到七十年代末期，一直领导着商业超级计算机行业。 由 Seymour Cray 设计的 CDC 6600 被认为是第一台成功的商用超级计算机。 IBM 后来居上，从 20 世纪 90 年代到今天一直是商业行业的领导者。</p><h1 id="太湖之光"><a href="#太湖之光" class="headerlink" title="太湖之光"></a>太湖之光</h1><h2 id="研发背景"><a href="#研发背景" class="headerlink" title="研发背景"></a>研发背景</h2><p>超级计算机，被称为“国之重器”，超级计算属于战略高技术领域，是世界各国竞相角逐的科技制高点，也是一个国家科技实力的重要标志之一 [3]。</p><p>神威·太湖之光超级计算机作为国家863计划信息技术领域重大项目支持的课题之一，2014年由科技部立项，科技部的要求是建成全球一流的超级计算机和全球一流的超算中心 [4-5]。</p><h2 id="组成结构"><a href="#组成结构" class="headerlink" title="组成结构"></a>组成结构</h2><p><img src="/img/529-1.webp" alt="Lena"></p><p align="center">内部构造</p>神威·太湖之光超级计算机由40个运算机柜和8个[网络机柜](https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E6%9C%BA%E6%9F%9C/1857102?fromModule=lemma_inlink)组成。每个运算机柜比家用的双门冰箱略大，打开柜门，4块由32块运算插件组成的超节点分布其中。每个插件由4个运算节点板组成，一个运算节点板又含2块“[申威26010](https://baike.baidu.com/item/%E7%94%B3%E5%A8%8126010/0?fromModule=lemma_inlink)”高性能处理器。一台机柜就有1024块[处理器](https://baike.baidu.com/item/%E5%A4%84%E7%90%86%E5%99%A8/914419?fromModule=lemma_inlink)，整台“神威·太湖之光”共有40960块处理器 [6]。<hr><h2 id="主要性能"><a href="#主要性能" class="headerlink" title="主要性能"></a>主要性能</h2><p>1.峰值性能12.5亿亿次每秒 [19]</p><p>2.持续性能9.3亿亿次每秒 [19]</p><p>3.性能功耗比6051MFlops&#x2F;W [6]</p><h2 id="世界排名"><a href="#世界排名" class="headerlink" title="世界排名"></a>世界排名</h2><p>2016年6月20日，德国法兰克福国际超算大会（ISC）公布了新一期全球超级计算机TOP500榜单，由国家并行计算机工程技术研究中心研制的“神威·太湖之光”以超第二名近三倍的运算速度夺得第一 [6]。</p><p>2016年11月14日，新一期全球超级计算机500强（TOP500）榜单，中国“神威·太湖之光”以较大的运算速度优势轻松蝉联冠军。算上此前“<a href="https://baike.baidu.com/item/%E5%A4%A9%E6%B2%B3%E4%BA%8C%E5%8F%B7/0?fromModule=lemma_inlink">天河二号</a>”的六连冠，中国已连续4年占据全球超算排行榜的最高席位 [7]。</p><p>2017年6月19日，在德国法兰克福召开的I SC2017国际高性能计算大会上，“神威·太湖之光”超级计算机以每秒12.54亿亿次的峰值计算能力以及每秒9.3亿亿次的持续计算能力，再次斩获世界超级计算机排名榜单TOP500第一名 [8]。</p><p>2017年11月13日，新一期全球超级计算机500强榜单发布，中国超级计算机“神威·太湖之光”和“天河二号”连续第四次分列冠亚军，且中国超级计算机上榜总数又一次反超美国，夺得第一 [9]。</p><p>2018年11月12日，新一期全球超级计算机500强榜单在美国达拉斯发布，中国超算“神威·太湖之光”位列第三名 [10]。</p><p>2020年6月，全球超级计算机Top500榜单公布，神威·太湖之光排名第四 [11]。</p><p>2021年，最新一期的全球超级计算机500强榜单公布，中国超级计算机“神威·太湖之光”，本次排名第四位。 [16]</p><p>2023年，最新的全球超级计算机500强榜单公布，中国超级计算机“神威·太湖之光”，本次排名第七位。</p><hr><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>以<a href="https://baike.baidu.com/item/%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6/111764?fromModule=lemma_inlink">清华大学</a>为主体的科研团队首次实现了百万核规模的全球10公里高分辨率地球系统数值模拟，将全面提高中国应对极端气候和自然灾害的减灾防灾能力；<a href="https://baike.baidu.com/item/%E5%9B%BD%E5%AE%B6%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6%E5%AE%9E%E9%AA%8C%E5%AE%A4/0?fromModule=lemma_inlink">国家计算流体力学实验室</a>对“<a href="https://baike.baidu.com/item/%E5%A4%A9%E5%AE%AB%E4%B8%80%E5%8F%B7/0?fromModule=lemma_inlink">天宫一号</a>”返回路径的数值模拟将为“<a href="https://baike.baidu.com/item/%E5%A4%A9%E5%AE%AB%E4%B8%80%E5%8F%B7/0?fromModule=lemma_inlink">天宫一号</a>”顺利回家提供精确预测；上海药物所开展的药物筛选和疾病机理研究，大大加速了白血病、<a href="https://baike.baidu.com/item/%E7%99%8C%E7%97%87/151056?fromModule=lemma_inlink">癌症</a>、<a href="https://baike.baidu.com/item/%E7%A6%BD%E6%B5%81%E6%84%9F/233181?fromModule=lemma_inlink">禽流感</a>等方向的药物设计进度 [6]。</p><p><img src="/img/529-2.webp" alt="Lena"></p><p align="center">戈登贝尔奖获奖</p>2016年11月18日凌晨4：20时许（北京时间），2016年度“戈登·贝尔”奖的谜底终于在美国[盐湖城](https://baike.baidu.com/item/%E7%9B%90%E6%B9%96%E5%9F%8E/8808871?fromModule=lemma_inlink)举行的[国际超算大会](https://baike.baidu.com/item/%E5%9B%BD%E9%99%85%E8%B6%85%E7%AE%97%E5%A4%A7%E4%BC%9A/0?fromModule=lemma_inlink)（SC16）上揭晓。[中科院软件所](https://baike.baidu.com/item/%E4%B8%AD%E7%A7%91%E9%99%A2%E8%BD%AF%E4%BB%B6%E6%89%80/0?fromModule=lemma_inlink)杨超研究员与清华大学副教授[薛巍](https://baike.baidu.com/item/%E8%96%9B%E5%B7%8D/13884453?fromModule=lemma_inlink)、[付昊桓](https://baike.baidu.com/item/%E4%BB%98%E6%98%8A%E6%A1%93/0?fromModule=lemma_inlink)等人联合北师大组成的研究团队凭借在“神威·太湖之光”上运行的“全球大气非静力云分辨模拟”应用一举摘得该项锦标。此次全球共有6项应用成果入围“戈登·贝尔”奖最终提名，其中3项都是依托“神威·太湖之光”完成的。其余2项应用分别为[国家海洋局](https://baike.baidu.com/item/%E5%9B%BD%E5%AE%B6%E6%B5%B7%E6%B4%8B%E5%B1%80/9930877?fromModule=lemma_inlink)海洋一所与[清华大学](https://baike.baidu.com/item/%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6/111764?fromModule=lemma_inlink)合作的“高分辨率海浪数值模拟”和[中科院网络中心](https://baike.baidu.com/item/%E4%B8%AD%E7%A7%91%E9%99%A2%E7%BD%91%E7%BB%9C%E4%B8%AD%E5%BF%83/5912200?fromModule=lemma_inlink)的“[钛合金](https://baike.baidu.com/item/%E9%92%9B%E5%90%88%E9%87%91/1170982?fromModule=lemma_inlink)微结构演化相场模拟” [12]。]]></content>
      
      
      <categories>
          
          <category> 前沿 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 专业前沿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo框架原理</title>
      <link href="/2024/05/28/hexo%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/"/>
      <url>/2024/05/28/hexo%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>随着<a href="https://cloud.baidu.com/product/et.html">网络</a>技术的不断发展，博客作为一种重要的信息发布和交流方式，受到了越来越多人的青睐。Hexo是一款基于Node.js的博客框架，具有快速、简单、强大等特点，成为了许多博客爱好者的首选。那么，Hexo是如何实现这些功能的呢？本文将详细解析Hexo的底层原理，帮助读者更好地理解Hexo，并掌握如何使用Hexo搭建自己的博客。</p><h1 id="Hexo的目录结构"><a href="#Hexo的目录结构" class="headerlink" title="Hexo的目录结构"></a>Hexo的目录结构</h1><p>Hexo的目录结构清晰简洁，易于理解和管理。Hexo的根目录下主要包含以下几个文件夹：</p><ul><li>source：存放博客文章的源文件，即用户编写的博文都放在该目录下,每个文章都是一个独立的Markdown文件，文件名即为文章的URL。下面我们介绍几个子目录分别看一下</li></ul><ol><li>_post，用于存放博文，基本上每篇文章都是由 Markdown 语法编写的。</li><li>tags，存放 tag 的文件。hexo 中的 tags 是自动生成的，所以我们不用手动修改 tags 目录下的 index.md 文件，在发布时它会自动生成。</li><li>categories，存放<strong>分类</strong>。它与 tags 是类似的，也是自动生成的，所以不需要我们手工修改。</li></ol><ul><li>themes：存放Hexo的主题文件，Hexo支持自定义主题，用户可以根据自己的喜好选择或开发主题。</li><li>plugins：存放Hexo的插件文件，Hexo提供了丰富的插件生态，用户可以根据自己的需求安装插件来扩展Hexo的功能。</li><li>public：存放Hexo生成的静态文件，包括HTML、CSS、JavaScript等，这些文件可以直接被Web服务器解析并展示给用户。</li></ul><h1 id="Hexo的配置文件"><a href="#Hexo的配置文件" class="headerlink" title="Hexo的配置文件"></a>Hexo的配置文件</h1><p>Hexo的配置文件是_config.yml，该文件位于Hexo的根目录下。_config.yml文件是一个YAML格式的文件，用于配置Hexo的各项参数，如站点名称、站点URL、主题、插件等。Hexo在生成静态文件时，会根据_config.yml文件中的配置信息来生成相应的HTML文件。</p><h1 id="Hexo的主题和插件机制"><a href="#Hexo的主题和插件机制" class="headerlink" title="Hexo的主题和插件机制"></a>Hexo的主题和插件机制</h1><p>Hexo的主题和插件机制是Hexo强大的功能之一。Hexo支持自定义主题，用户可以通过修改主题文件来改变博客的外观和布局。Hexo的主题文件主要包括layout、source和template三个文件夹，分别用于存放布局文件、源文件和模板文件。</p><p>除了主题，Hexo还提供了丰富的插件生态。用户可以根据自己的需求安装插件来扩展Hexo的功能，如添加评论功能、搜索功能、统计功能等。Hexo的插件机制使得Hexo具有极高的可扩展性，用户可以根据自己的需求来定制自己的博客。</p><h1 id="Hexo的工作流程"><a href="#Hexo的工作流程" class="headerlink" title="Hexo的工作流程"></a>Hexo的工作流程</h1><p>Hexo的工作流程可以分为以下几个步骤：</p><ol><li>编写Markdown格式的博客文章，保存到source文件夹中。</li><li>根据_config.yml文件中的配置信息，Hexo会解析Markdown文件，并将其转换为HTML文件。而生成html的步骤也并非一步完成，首先是将Markdown程序转换为以下JSON对象：<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">article<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  title<span class="punctuation">:</span></span><br><span class="line">  date<span class="punctuation">:</span></span><br><span class="line">  tags<span class="punctuation">:</span></span><br><span class="line">  categories<span class="punctuation">:</span></span><br><span class="line">  content<span class="punctuation">:</span></span><br><span class="line">  ...</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>然后根据上面生成的JSON对象生成HTML页面</li><li>Hexo会根据当前启用的主题，将生成的HTML文件渲染成最终的网页。</li><li>Hexo将生成的静态文件保存到public文件夹中，用户可以将public文件夹中的内容部署到Web服务器上，供用户访问。</li></ol><p>下面我们再来看看 <strong>hexo</strong> 的组成，它由三部分组成: <strong>hexo-cli</strong>、<strong>hexo-core</strong> 以及 <strong>hexo plugs</strong>。在这三部分中最核心的是 hexo-core 模块，它的作用就是执行上面讲的两步转换，从而生成目标文件；hexo-cli 为我们供了一些非常方便的命令。当我们敲入命令时，它会根据命令调用不同的模块；hexo plugin 是 hexo 的扩展，当 hexo 本身不能完成某项任务时，它允许你自己开发一个插件来完成。当然你也可以使用其它人写好的插件。</p><h1 id="hexo常用命令"><a href="#hexo常用命令" class="headerlink" title="hexo常用命令"></a>hexo常用命令</h1><p><strong>hexo</strong> 提供了几个常用命令，如<code>hexo clean</code>、<code>hexo g</code>、<code>hexo s</code>等等。下面我们分别看一下这几个命令的具体作用是什么：</p><ul><li><p>hexo clean: 删除 hexo 生成的所有文档。当我们执行这个命令后，你会发现 public 目录被删除了。</p></li><li><p>hexo g: 根据 source 目录中的文件生成 html 等可以发布的文件。</p></li><li><p>hexo s: 在本地起动 <strong>http</strong> 服务，将生成的 html 等输出文件布署到本地服务器上。</p></li><li><p>hexo d: 将生成的 html 代码推送到 github 上</p></li><li><p>hexo n “新的文章标题” ：生成一篇框架完整的新的markdown文件</p></li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Hexo作为一个基于Node.js的博客框架，具有快速、简单、强大等特点。通过深入了解Hexo的底层原理，我们可以更好地理解Hexo的工作原理，并掌握如何使用Hexo搭建自己的博客。同时，Hexo的主题和插件机制也为我们提供了丰富的定制选项，使得我们可以根据自己的需求来定制自己的博客。希望本文能够帮助读者更好地理解Hexo，并激发大家使用Hexo搭建博客的热情。</p>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Web3介绍</title>
      <link href="/2024/05/22/Web3%E4%BB%8B%E7%BB%8D/"/>
      <url>/2024/05/22/Web3%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h1 id="Web3-简介"><a href="#Web3-简介" class="headerlink" title="Web3 简介"></a>Web3 简介</h1><p>集中化帮助数十亿人接入万维网，并创建了万维网赖以生存的稳定、强大的基础设施。 与此同时，少数中心化实体在万维网的大片地区拥有据点，单方面决定什么应该被允许，什么不应该被允许。</p><p>Web3 就是这个困境的答案。 Web3 不是由大型科技公司垄断的 Web，而是拥抱去中心化，并由其用户构建、运营和拥有。 Web3 将权力交给个人而不是公司。<br>在讨论 Web3 之前，让我们先探讨一下我们是如何走到这一步的。</p><Divider /><h2 id="早期的网络"><a href="#早期的网络" class="headerlink" title="早期的网络"></a>早期的网络</h2><p>大多数人认为网络是现代生活的一个持续的支柱——它被发明并从那时起就存在了。 然而，我们大多数人今天所知道的网络与最初想象的有很大不同。 为了更好地理解这一点，将 Web 的短暂历史分为松散的时期（Web 1.0 和 Web 2.0）会很有帮助。</p><h3 id="Web-1-0：只读（1990-2004"><a href="#Web-1-0：只读（1990-2004" class="headerlink" title="Web 1.0：只读（1990-2004)"></a>Web 1.0：只读（1990-2004)</h3><p>1989 年，在日内瓦欧洲核子研究组织 (CERN)，蒂姆·伯纳斯·李 (Tim Berners-Lee) 正忙于开发后来成为万维网的协议。 他的想法？ 创建开放、去中心化的协议，允许在地球上任何地方共享信息。</p><p>伯纳斯-李的第一次创作，现在被称为“Web 1.0”，大约发生在 1990 年至 2004 年之间。Web 1.0 主要是公司拥有的静态网站，用户之间几乎为零互动——个人很少制作内容——导致 它被称为只读网络。</p><p><img src="/img/Web1.png" alt="Lena"></p><p align="center">客户端-服务器架构，代表Web 1.0</p><h3 id="Web-2-0：读写（2004-年至今）"><a href="#Web-2-0：读写（2004-年至今）" class="headerlink" title="Web 2.0：读写（2004 年至今）"></a>Web 2.0：读写（2004 年至今）</h3><p>随着社交媒体平台的出现，Web 2.0 时期开始于 2004 年。 网络不再是只读的，而是变成了读写的。 公司不再向用户提供内容，而是开始提供平台来共享用户生成的内容并进行用户与用户的交互。 随着越来越多的人上网，少数顶级公司开始控制网络上不成比例的流量和价值。 Web 2.0 还催生了广告驱动的收入模式。 虽然用户可以创建内容，但他们并不拥有该内容或从其货币化中受益。</p><p><img src="/img/web2.png" alt="Lena"></p><p align="center">客户端-服务器架构，代表Web 2.0</p><Divider /><h2 id="Web-3-0：读写自有"><a href="#Web-3-0：读写自有" class="headerlink" title="Web 3.0：读写自有"></a>Web 3.0：读写自有</h2><p>“Web 3.0”的前提是以太坊 (Ethereum)(&#x2F;what-is-ethereum&#x2F;) 联合创始人 Gavin Wood 在 2014 年以太坊推出后不久提出的。Gavin 针对许多早期加密货币采用者所感受到的问题提出了一个解决方案： 网络需要太多的信任。 也就是说，人们今天所了解和使用的大多数网络都依赖于信任少数私营公司，它们会按照公众的最佳利益行事。</p><p><img src="/img/web33.png" alt="Lena"></p><p align="center">去中心化节点架构，代表Web3</p><Divider /><h3 id="什么是-Web3？"><a href="#什么是-Web3？" class="headerlink" title="什么是 Web3？"></a>什么是 Web3？</h3><p>Web3 已经成为一个包罗万象的术语，代表着一个新的、更好的互联网的愿景。 Web3 的核心是利用区块链、加密货币和 NFT 将权力以所有权的形式返还给用户。 <a href="https://twitter.com/himgajria/status/1266415636789334016">Twitter 上的 2020 年帖子</a> 说得最好：Web1 是只读的，Web2 是读写的，Web3 将是读写自己的。</p><h4 id="Web3-的核心思想"><a href="#Web3-的核心思想" class="headerlink" title="Web3 的核心思想"></a>Web3 的核心思想</h4><p>尽管为 Web3 提供严格的定义具有挑战性，但有一些核心原则指导其创建。</p><ul><li><strong>Web3 是去中心化的：</strong> 互联网的大片区域不是由中心化实体控制和拥有，而是所有权分布在其构建者和用户之间。</li><li><strong>Web3 是无需许可的：</strong> 每个人都有平等的机会参与 Web3，没有人会被排除在外。</li><li><strong>Web3 具有原生支付功能：</strong> 它使用加密货币进行在线支出和汇款，而不是依赖银行和支付处理器的过时基础设施。</li><li><strong>Web3 是无需信任的：</strong> 它使用激励和经济机制运行，而不是依赖可信的第三方。</li></ul><h3 id="为什么-Web3-很重要？"><a href="#为什么-Web3-很重要？" class="headerlink" title="为什么 Web3 很重要？"></a>为什么 Web3 很重要？</h3><p>尽管 Web3 的杀手级功能不是孤立的，也不适合简单的类别，但为了简单起见，我们尝试将它们分开以使它们更容易理解。</p><h4 id="所有权"><a href="#所有权" class="headerlink" title="所有权"></a>所有权</h4><p>Web3 以前所未有的方式让您拥有数字资产的所有权。 例如，假设您正在玩 web2 游戏。 如果您购买游戏内物品，它将直接与您的帐户绑定。 如果游戏创建者删除您的帐户，您将丢失这些物品。 或者，如果您停止玩游戏，您就会失去投资于游戏内物品的价值。</p><p>Web3 允许通过<a href="/glossary/#nft">不可替代代币 (NFT)</a> 实现直接所有权。 任何人，甚至游戏的创作者，都无权剥夺您的所有权。 而且，如果您停止玩游戏，您可以在公开市场上出售或交易您的游戏内物品并收回其价值。</p><InfoBanner shouldSpaceBetween emoji=":eyes:">   <div>了解有关 NFT 的更多信息</div>   <ButtonLink to="/nft/">     有关 NFT 的更多信息  </ButtonLink></InfoBanner><h4 id="审查制度抵抗"><a href="#审查制度抵抗" class="headerlink" title="审查制度抵抗"></a>审查制度抵抗</h4><p>平台和内容创作者之间的权力动态严重不平衡。</p><p>OnlyFans 是一个用户生成的成人内容网站，拥有超过 100 万内容创作者，其中许多人将该平台作为主要收入来源。 2021 年 8 月，OnlyFans 宣布计划禁止露骨色情内容。 这一消息引发了该平台创作者的愤怒，他们认为自己帮助创建的平台上的收入被剥夺了。 在强烈反对之后，这一决定很快被推翻。 尽管创作者赢得了这场战斗，但它凸显了 Web 2.0 创作者的一个问题：如果你离开一个平台，你就会失去声誉和关注度。</p><p>在 Web3 上，您的数据存储在区块链上。 当您决定离开某个平台时，您可以带走您的声誉，将其插入另一个更符合您价值观的界面。</p><p>Web 2.0 要求内容创建者信任平台不会改变规则，但抗审查性是 Web3 平台的固有功能。</p><h4 id="去中心化自治组织-DAO"><a href="#去中心化自治组织-DAO" class="headerlink" title="去中心化自治组织 (DAO)"></a>去中心化自治组织 (DAO)</h4><p>除了拥有 Web3 中的数据之外，您还可以使用类似于公司股票的代币作为一个集体拥有该平台。 DAO 可让您协调平台的去中心化所有权并对其未来做出决策。</p><p>DAO 在技术上被定义为商定的<a href="/glossary/#smart-contract">智能合约</a>，它可以在资源池（代币）上自动执行去中心化决策。 拥有代币的用户对资源的使用方式进行投票，代码自动执行投票结果。</p><p>然而，人们将许多 Web3 社区定义为 DAO。 这些社区都通过代码实现了不同程度的去中心化和自动化。 目前，我们正在探索 DAO 是什么以及它们未来如何发展。</p><InfoBanner shouldSpaceBetween emoji=":eyes:">   <div>了解有关 DAO 的更多信息</div>   <ButtonLink to="/dao/">     有关 DAO 的更多信息   </按钮链接></信息横幅><h3 id="身份"><a href="#身份" class="headerlink" title="身份"></a>身份</h3><p>传统上，您将为您使用的每个平台创建一个帐户。 例如，您可能拥有 Twitter 帐户、YouTube 帐户和 Reddit 帐户。 想要更改您的显示名称或个人资料图片吗？ 您必须在每个帐户上执行此操作。 在某些情况下，您可以使用社交登录，但这会带来一个熟悉的问题——审查制度。 只需单击一下，这些平台就可以将您锁定在整个在线生活之外。 更糟糕的是，许多平台要求您信任他们提供个人身份信息才能创建帐户。</p><p>Web3 允许您使用以太坊地址和<a href="/glossary/#ens">以太坊名称服务 (ENS)</a> 配置文件控制您的数字身份，从而解决了这些问题。 使用以太坊地址可以提供安全、抗审查和匿名的跨平台单一登录。</p><h3 id="原生支付"><a href="#原生支付" class="headerlink" title="原生支付"></a>原生支付</h3><p>Web2 的支付基础设施依赖于银行和支付处理商，不包括没有银行账户的人或恰好居住在错误国家&#x2F;地区的人。<br>Web3 使用 <a href="/glossary/#ether">ETH</a> 等代币直接在浏览器中汇款，无需受信任的第三方。</p><ButtonLink to="/eth/">   有关 ETH 的更多信息</按钮链接><h2 id="Web3-限制"><a href="#Web3-限制" class="headerlink" title="Web3 限制"></a>Web3 限制</h2><p>尽管当前形式的 Web3 有很多好处，但生态系统必须解决许多限制才能使其蓬勃发展。</p><h3 id="辅助功能"><a href="#辅助功能" class="headerlink" title="辅助功能"></a>辅助功能</h3><p>重要的 Web3 功能（例如使用以太坊登录）已经可供任何人以零成本使用。 但是，交易的相对成本仍然让许多人望而却步。 由于交易费用较高，Web3 在不太富裕的发展中国家不太可能被使用。 在以太坊上，这些挑战正在通过<a href="/roadmap/">路线图</a>和<a href="/glossary/#layer-2">第 2 层扩展解决方案</a>得到解决。 该技术已经准备就绪，但我们需要在第 2 层上进行更高水平的采用，以使每个人都可以访问 Web3。</p><h3 id="用户体验"><a href="#用户体验" class="headerlink" title="用户体验"></a>用户体验</h3><p>目前使用 Web3 的技术门槛太高。 用户必须理解安全问题，理解复杂的技术文档，并浏览不直观的用户界面。 <a href="/wallets/find-wallet/">钱包提供商</a> 特别致力于解决这个问题，但在 Web3 被大规模采用之前还需要取得更多进展。</p><h3 id="教育"><a href="#教育" class="headerlink" title="教育"></a>教育</h3><p>Web3 引入了新的范式，需要学习与 Web2.0 中使用的思维模型不同的思维模型。 20 世纪 90 年代末，随着 Web1.0 的流行，类似的教育活动也发生了。 万维网的支持者使用了大量的教育技术来教育公众，从简单的比喻（信息高速公路、浏览器、网上冲浪）到[电视广播](<a href="https://www.youtube.com/watch?v=">https://www.youtube.com/watch?v=</a> SzQLI7BxfYI)。 Web3 并不难，但它有所不同。 让 Web2 用户了解这些 Web3 范例的教育活动对于其成功至关重要。</p><h3 id="集中式基础设施"><a href="#集中式基础设施" class="headerlink" title="集中式基础设施"></a>集中式基础设施</h3><p>Web3 生态系统还很年轻并且发展迅速。 因此，它目前主要依赖于中心化基础设施（GitHub、Twitter、Discord 等）。 许多 Web3 公司都在急于填补这些空白，但构建高质量、可靠的基础设施需要时间。</p><h2 id="去中心化的未来"><a href="#去中心化的未来" class="headerlink" title="去中心化的未来"></a>去中心化的未来</h2><p>Web3 是一个年轻且不断发展的生态系统。 加文·伍德 (Gavin Wood) 在 2014 年创造了这个术语，但其中许多想法直到最近才成为现实。 仅去年一年，人们对加密货币的兴趣大幅增加，对第 2 层扩展解决方案的改进，对新治理形式的大规模实验以及数字身份的革命。</p><p>我们才刚刚开始使用 Web3 创建更好的 Web，但随着我们不断改进支持它的基础设施，Web 的未来看起来一片光明。</p><h2 id="我如何参与"><a href="#我如何参与" class="headerlink" title="我如何参与"></a>我如何参与</h2><ul><li><a href="/wallets/">Get a wallet</a></li><li><a href="/community/">Find a community</a></li><li><a href="/dapps/">Explore Web3 applications</a></li><li><a href="/dao/">Join a DAO</a></li><li><a href="/developers/">Build on Web3</a></li></ul><h2 id="进一步阅读"><a href="#进一步阅读" class="headerlink" title="进一步阅读"></a>进一步阅读</h2><p>Web3 没有严格定义。 不同的社区参与者对此有不同的看法。 这里有几个：</p><ul><li><a href="https://www.freecodecamp.org/news/what-is-web3/">What is Web3? The Decentralized Internet of the Future Explained</a> – <em>Nader Dabit</em></li><li><a href="https://medium.com/l4-media/making-sense-of-web-3-c1a9e74dcae">Making Sense of Web 3</a> – <em>Josh Stark</em></li><li><a href="https://future.a16z.com/why-web3-matters/">Why Web3 Matters</a> — <em>Chris Dixon</em></li><li><a href="https://onezero.medium.com/why-decentralization-matters-5e3f79f7638e">Why Decentralization Matters</a> - <em>Chris Dixon</em></li><li><a href="https://a16z.com/wp-content/uploads/2021/10/The-web3-Readlng-List.pdf">The Web3 Landscape</a> – <em>a16z</em></li><li><a href="https://www.notboring.co/p/the-web3-debate?s=r">The Web3 Debate</a> – <em>Packy McCormick</em></li></ul><QuizWidget quizKey="web3" />]]></content>
      
      
      <categories>
          
          <category> 前沿 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 专业前沿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自然语言处理NLP</title>
      <link href="/2024/05/20/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86NLP/"/>
      <url>/2024/05/20/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86NLP/</url>
      
        <content type="html"><![CDATA[<p><strong>本文旨在介绍前沿的自然语言处理技术-Bert。</strong></p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><strong>介绍</strong></h2><p><strong>2018</strong>年<strong>Google</strong>发布了<strong>BERT</strong>（来自Transformer的双向自编码器）<strong>预训练模型</strong>，旨在通过联合左侧和右侧的上下文，从未标记文本中预训练出一个深度双向表示模型。因此，BERT可以通过增加一个额外的输出层来进行微调，就可以达到为广泛的任务创建State-of-the-arts 模型的效果，比如QA、语言推理任务。</p><p>当时将预训练模应用于下游任务的<strong>策略</strong>通常有两种：<strong>基于特征的（feature-based）</strong>和<strong>基于微调（fine-tuning）</strong>；前者比如<strong>ELMo</strong><a href="https://zhuanlan.zhihu.com/p/130913995#ref_2">[2]</a>，后者比如<strong>OpenAI GPT</strong><a href="https://zhuanlan.zhihu.com/p/130913995#ref_3">[3]</a>;</p><p>这两种策略在预训练期间具有相同的目标函数，在预训练期间，它们使用单向语言模型来学习一般的语言表示。但当前对预训练方法的限制（尤其是对基于微调的方法）是标准语言模型是单向(unidirectional）的，所以限制了在预训练阶段可选的模型结构体系。</p><p>比如GPT是从左到右的，每个token只能关注到前一个token的self-attention layers。这种局限对于句子级任务(sentence-level tasks)来说还不是很打紧，但是对于token-level tasks（比如QA）就很致命，所以结合两个方向的上下文信息至关重要。</p><p><img src="/img/520-1.png" alt="Lena"></p><p>BERT对比这两个算法的优点是，只有BERT表征会基于所有层中的左右两侧语境，而能做到这一点得益于Transformer中Attention机制将任意位置的两个单词的距离转换成了1。<br>那么BERT具体是如何实现的呢? 我们接着往下看</p><h2 id="BERT框架及其详细实现"><a href="#BERT框架及其详细实现" class="headerlink" title="BERT框架及其详细实现"></a>BERT框架及其详细实现</h2><p>我们在本节中介绍BERT及其详细实现，训练框架主要由两个步骤构成：预训练和微调。</p><p><a href="https://so.csdn.net/so/search?q=BERT&spm=1001.2101.3001.7020">BERT</a>，基于transformer的双向编码表示，它是一个预训练模型，模型训练时的两个任务是预测句子中被掩盖的词以及判断输入的两个句子是不是上下句。在预训练好的BERT模型后面根据特定任务加上相应的网络，可以完成NLP的下游任务，比如文本分类、机器翻译等。</p><p>       虽然BERT是基于transformer的，但是它只使用了transformer的encoder部分，它的整体框架是由多层transformer的encoder堆叠而成的。每一层的encoder则是由一层muti-head-attention和一层feed-forword组成，大的模型有24层，每层16个attention，小的模型12层，每层12个attention。每个attention的主要作用是通过目标词与句子中的所有词汇的相关度，对目标词重新编码。所以每个attention的计算包括三个步骤：计算词之间的相关度，对相关度归一化，通过相关度和所有词的编码进行加权求和获取目标词的编码。</p><p>        在通过attention计算词之间的相关度时，首先通过三个权重矩阵对输入的序列向量(512*768)做线性变换，分别生成query、key和value三个新的序列向量，用每个词的query向量分别和序列中的所有词的key向量做乘积，得到词与词之间的相关度，然后这个相关度再通过softmax进行归一化，归一化后的权重与value加权求和，得到每个词新的编码。</p><h3 id="模型输入"><a href="#模型输入" class="headerlink" title="模型输入"></a>模型输入</h3><p>      在BERT中，输入的向量是由三种不同的embedding求和而成，分别是：</p><ol><li><p><strong>wordpiece embedding</strong>：单词本身的向量表示。WordPiece是指将单词划分成一组有限的公共子词单元，能在单词的有效性和字符的灵活性之间取得一个折中的平衡。</p></li><li><p><strong>position embedding</strong>：将单词的位置信息编码成特征向量。因为我们的网络结构没有RNN 或者LSTM，因此我们无法得到序列的位置信息，所以需要构建一个position embedding。构建position embedding有两种方法：BERT是初始化一个position embedding，然后通过训练将其学出来；而Transformer是通过制定规则来构建一个position embedding</p></li><li><p><strong>segment embedding</strong>：用于区分两个句子的向量表示。这个在问答等非对称句子中是用区别的。</p><p> BERT模型的输入就是wordpiece token embedding + segment embedding + position embedding，如图所示：</p></li></ol><p>        <img src="/img/520-2.png" alt="Lena"><br>        对于每一种向量的具体表现形式，可以参考这篇文章，可视化的给出了BERT中各种embedding的表现：</p><p>        <a href="https://mp.weixin.qq.com/s/DfIAuo775_sHGYi5z9IZyw" title="BERT的嵌入层是如何实现的？看完你就明白了">BERT的嵌入层是如何实现的？看完你就明白了</a></p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>        BERT的主要结构是transformer（如图1所示），一个BERT预训练模型的基础结构是标准transformer结构的encoder部分，一个标准transformer结构如图2所示，其中左边的部分就是BERT中使用的encoder部分。<br>   <img src="/img/520-3.png" alt="Lena"><br>   <p align="center">Bert网络结构</p><br>   一个transformer的encoder单元由一个multi-head-Attention + <a href="https://so.csdn.net/so/search?q=Layer&spm=1001.2101.3001.7020">Layer</a> Normalization + feedforword + Layer Normalization 叠加产生，BERT的每一层由一个这样的encoder单元构成。在比较大的BERT模型中，有24层encoder，每层中有16个Attention，词向量的维度是1024。在比较小的BERT模型中，有12层encoder，每层有12个Attention，词向量维度是768。在所有情况下，将feed-forward&#x2F;filter 的大小设置为 4H（H为词向量的维度），即H &#x3D; 768时为3072，H &#x3D; 1024时为4096。</p><p>        这种transformer的结构可以使用上下文来预测mask的token，从而捕捉双向关系。<br>       <br>  <img src="/img/520-4.png" alt="Lena"><br>  <p align="center">标准的transformer结构（左边是encoder部分）</p></p><h3 id="训练框架"><a href="#训练框架" class="headerlink" title="训练框架"></a>训练框架</h3><p><img src="/img/520-5.png" alt="Lena"><br>BERT的总体预培训和微调程序。除了输出层，预训练和微调中都使用相同的体系结构。相同的预训练模型参数用于初始化不同下游任务的模型。在微调期间，所有参数都会微调。[CLS]是在每个输入示例前面添加的特殊符号，【SEP】是一个特殊的分隔符令牌（例如，分隔问题&#x2F;答案）。</p><ul><li><strong>Pre-training预训练：</strong></li></ul><p>在预训练阶段，BERT用大量的<strong>无监督</strong>文本通过自监督训练的方式(通过使用受完形填空任务启发的<strong>Masked Language Model</strong><a href="https://zhuanlan.zhihu.com/p/130913995#ref_4">[4]</a>预训练目标)训练，把文本中包含的语言知识（包括：词法、语法、语义等特征）以参数的形式编码到Transformer-encoder layer中。预训练模型学习到的是文本的通用知识，不依托于某一项NLP任务；（2.4小节展开详述）</p><ul><li><strong>Fine-Tuning微调：</strong></li></ul><p>NLP 问题被证明同图像一样，可以通过 finetune 在垂直领域取得效果的提升。Bert 模型本身极其依赖计算资源，从 0 训练对大多数开发者都是难以想象的事。在节省资源避免重头开始训练的同时，为更好的拟合垂直领域的语料，我们有了 finetune 的动机。</p><p>在微调阶段，BERT首先使用预训练的参数初始化模型，所有参数都使用下游任务的标签数据进行微调，每个不同的下游任务都有单独的微调模型（2.5小节展开详述）</p><h3 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a><strong>模型架构</strong></h3><p>BERT的模型体系结构是基于Vaswani等人描述的原始实现的多层双向变压器编码器<a href="https://zhuanlan.zhihu.com/p/130913995#ref_5">[5]</a></p><p>关于大名鼎鼎的底座模型Transformer这边就不展开赘述了，详情可参考优秀指南<br><a href="https://link.zhihu.com/?target=http://nlp.seas.harvard.edu/2018/04/03/attention.html">http://nlp.seas.harvard.edu/2018/04/03/attention.html​nlp.seas.harvard.edu/2018/04/03/attention.html<img src="https://pic1.zhimg.com/v2-5db46b14342e33f39d2b6507100efb94_120x160.jpg"></a></p><p>首先明确几个概念，在本工作中，我们命名表示层数为L（Transformer Blocks），隐藏层数为H，自注意力头数量为A。我们主要报告的型号尺寸为</p><ul><li>BERT_base(L&#x3D;12,H&#x3D;768,A&#x3D;12; parameters&#x3D;110M)</li><li>BERT_large(L&#x3D;24,H&#x3D;1024,A&#x3D;16; parameters&#x3D;340M)</li></ul><p>后者的大小和OpenAI GPT是相同的，以便比较效果。</p><h3 id="输入-x2F-输出表示"><a href="#输入-x2F-输出表示" class="headerlink" title="输入&#x2F;输出表示"></a><strong>输入&#x2F;输出表示</strong></h3><p><img src="/img/520-6.png" alt="Lena"><br>如上图所示，BERT模型有两个特殊的token：<strong>CLS</strong> （用于分类任务）、 <strong>SEP</strong>（用于断句），以及三个类型的<strong>embedding</strong>：</p><ul><li><strong>Token embedding：</strong>输入的文本经过tokenization之后，将CLS插入tokenization结果的开头，SEP插入到tokenization结果的结尾。然后进行token embedding look up。shape为：[seq_length, embedding_dims]。流程如下图所示：</li></ul><p><img src="/img/520-7.png" alt="Lena"></p><ul><li><p><strong>Segment embedding：</strong>在NSP任务中，用于区分第一句和第二句。segment embedding中只有 0 和 1两个值，第一句所有的token（包括cls和紧随第一句的sep）的segment embedding的值为0，第二句所有的token（包括紧随第二句的sep）的segment embdding的值为1。shape为：[seq_length, embedding_dims]。流程如下图所示：<br><img src="/img/520-8.png" alt="Lena"><br> Segment Embeddings 层只有两种向量表示。前一个向量是把0赋给第一个句子中的各个token, 后一个向量是把1赋给第二个句子中的各个token。如果输入仅仅只有一个句子，那么它的segment embedding就是全0 </p></li><li><p>position Embedding</p></li></ul><p>Transformers无法编码输入的序列的顺序性,加入position embeddings会让BERT理解下面下面这种情况, I think, therefore I am,第一个 “I” 和第二个 “I”应该有着不同的向量表示</p><p>BERT能够处理最长512个token的输入序列。论文作者通过让BERT在各个位置上学习一个向量表示来讲序列顺序的信息编码进来。这意味着Position Embeddings layer 实际上就是一个大小为 (512, 768) 的lookup表，表的第一行是代表第一个序列的第一个位置，第二行代表序列的第二个位置，以此类推。因此，如果有这样两个句子“Hello world” 和“Hi there”, “Hello” 和“Hi”会由完全相同的position embeddings，因为他们都是句子的第一个词。同理，“world” 和“there”也会有相同的position embedding</p><p>我们已经介绍了长度为n的输入序列将获得的三种不同的向量表示，分别是：</p><p>Token Embeddings， (1, n, 768) ，词的向量表示<br>Segment Embeddings， (1, n, 768)，辅助BERT区别句子对中的两个句子的向量表示<br>Position Embeddings ，(1, n, 768) ，让BERT学习到输入的顺序属性<br>这些表示会被按元素相加，得到一个大小为(1, n, 768)的合成表示。这一表示就是BERT编码层的输入了<br>因此，BERT的输入为：</p><p><strong>token_embedding + segment_embedding + position_embedding</strong></p><h2 id="预训练任务"><a href="#预训练任务" class="headerlink" title="预训练任务"></a><strong>预训练任务</strong></h2><p><strong>（1）masked language model</strong></p><p>         随机掩盖掉一些单词，然后通过上下文预测该单词。BERT中有15%的wordpiece token会被随机掩盖，这15%的token中80%用[MASK]这个token来代替，10%用随机的一个词来替换，10%保持这个词不变。这种设计使得模型具有捕捉上下文关系的能力，同时能够有利于token-level tasks例如序列标注。</p><p>Q：为什么选中的15%的wordpiece token不能全部用 [MASK]代替，而要用 10% 的 random token 和 10% 的原 token</p><p>       [MASK] 是以一种显式的方式告诉模型『这个词我不告诉你，你自己从上下文里猜』，从而防止信息泄露。如果 [MASK] 以外的部分全部都用原 token，模型会学到『如果当前词是 [MASK]，就根据其他词的信息推断这个词；如果当前词是一个正常的单词，就直接抄输入』。这样一来，在 finetune 阶段，所有词都是正常单词，模型就照抄所有词，不提取单词间的依赖关系了。</p><p>        以一定的概率填入 random token，就是让模型时刻堤防着，在任意 token 的位置都需要把当前 token 的信息和上下文推断出的信息相结合。这样一来，在 finetune 阶段的正常句子上，模型也会同时提取这两方面的信息，因为它不知道它所看到的『正常单词』到底有没有被动过手脚的。</p><p>Q：最后怎么利用[MASK] token做的预测？</p><p>       最终的损失函数只计算被mask掉的token的，每个句子里 [MASK] 的个数是不定的。实际代码实现是每个句子有一个 maximum number of predictions，取所有 [MASK] 的位置以及一些 PADDING 位置的向量拿出来做预测（总共凑成 maximum number of predictions 这么多个预测，是定长的），然后再用掩码把 PADDING 盖掉，只计算[MASK]部分的损失。</p><p><strong>（2）next sentence prediction</strong></p><p>        语料中50%的句子，选择其相应的下一句一起形成上下句，作为正样本；其余50%的句子随机选择一句非下一句一起形成上下句，作为负样本。这种设定，有利于sentence-level tasks，例如问答。注意：作者特意说了语料的选取很关键，要选用document-level的而不是sentence-level的，这样可以具备抽象连续长序列特征的能力。</p><h3 id="模型训练设置"><a href="#模型训练设置" class="headerlink" title="模型训练设置"></a>模型训练设置</h3><ul><li><strong>pre-train阶段</strong></li></ul><p>（1）256个句子作为一个batch,每个句子最多512个token。</p><p>（2）迭代100万步。</p><p>（3）总共训练样本超过33亿。</p><p>（4）迭代40个epochs。</p><p>（5）用adam学习率， 1 &#x3D; 0.9, 2 &#x3D; 0.999。</p><p>（6）学习率头一万步保持固定值，之后线性衰减。</p><p>（7）L2衰减，衰减参数为0.01。</p><p>（8）drop out设置为0.1。</p><p>（9）激活函数用GELU代替RELU。</p><p>（10）Bert base版本用了16个TPU，Bert large版本用了64个TPU，训练时间4天完成。</p><p>（论文定义了两个版本，一个是base版本，一个是large版本。Large版本（L&#x3D;24, H&#x3D;1024, A&#x3D;16, Total Parameters&#x3D;340M）。base版本（ L&#x3D;12, H&#x3D;768, A&#x3D;12, Total Pa- rameters&#x3D;110M）。L代表网络层数，H代表隐藏层数，A代表self attention head的数量。）</p><p>因为序列长度太大（512）会影响训练速度，所以90%的steps都用seq_len&#x3D;128训练，余下的10%步数训练512长度的输入。</p><ul><li><p><strong>fine-tune 阶段</strong></p><p>  微调阶段根据不同任务使用不同网络模型。在微调阶段，大部分模型的超参数跟预训练时差不多，除了batchsize，学习率，epochs。</p><p>  微调参数建议：</p><p>  Batch size: 16, 32</p><p>  Learning rate (Adam): 5e-5, 3e-5, 2e-5</p><p>  Number of epochs: 3, 4</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="模型特点"><a href="#模型特点" class="headerlink" title="模型特点"></a>模型特点</h3><p>（1）使用transformer作为算法的主要框架，transformer能<strong>更彻底的捕捉语句中的双向关系</strong>；</p><p>（2）使用了mask language model 和next sentence prediction的多任务训练目标，<strong>是一个自监督的过程，不需要数据的标注</strong>；</p><p>（3）使用tpu这种强大的机器训练了大规模的预料，是NLP的很多任务达到了全新的高度。</p><p>       BERT本质上是在海量语料的基础上，通过自监督学习的方法为单词学习一个好的特征表示。该模型的优点是可以根据具体的人物进行微调，或者直接使用预训练的模型作为特征提取器。</p><h3 id="可优化空间"><a href="#可优化空间" class="headerlink" title="可优化空间"></a>可优化空间</h3><p>（1）如何让模型有<strong>捕捉Token序列关系</strong>的能力，而不是简单依靠位置嵌入。</p><p>（2）模型太大，太耗机器（后续的Albert有做改进）</p>]]></content>
      
      
      <categories>
          
          <category> 大模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 专业前沿 </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>脑机接口在神经康复中的应用</title>
      <link href="/2024/05/19/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E5%9C%A8%E7%A5%9E%E7%BB%8F%E5%BA%B7%E5%A4%8D%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"/>
      <url>/2024/05/19/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E5%9C%A8%E7%A5%9E%E7%BB%8F%E5%BA%B7%E5%A4%8D%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="脑机接口在神经康复中的应用：技术、挑战与未来"><a href="#脑机接口在神经康复中的应用：技术、挑战与未来" class="headerlink" title="脑机接口在神经康复中的应用：技术、挑战与未来"></a>脑机接口在神经康复中的应用：技术、挑战与未来</h2><p><strong>摘要：</strong>脑机接口（Brain-Computer Interface, BCI）技术在神经康复中的应用是近年来快速发展的前沿领域，旨在通过解读大脑信号来辅助神经系统损伤患者的康复。本文综述了BCI技术的基本概念和理论基础，探讨了其在中风和脊髓损伤等神经康复中的实际应用。文章分析了BCI技术在信号获取、处理及用户体验等方面面临的挑战，并提出了潜在的解决方案。通过对现有研究成果的比较和分析，本文展望了BCI技术在神经康复中的未来发展趋势和应用前景，指出了值得深入研究的方向。BCI技术在促进患者康复、推动神经科学研究和多学科融合发展方面具有重要意义，未来将成为神经康复领域的重要技术手段。</p><p><strong>关键词：<a href="https://kns.cnki.net/kcms2/keyword/detail?v=mjz80qGfPOWHIm7Y6wjHOodvlHNbQF1XHO8qAZaSe7ITFS_DxrIP1u3pl5_64E85R7iP2zkYaTSj6In8I63uas8gxOR8JAuyiJEX8jyLeXgf0H8GJmZQ62BuJBlcGSEF&uniplatform=NZKPT&language=CHS">突触可塑性;</a> <a href="https://kns.cnki.net/kcms2/keyword/detail?v=mjz80qGfPOWHIm7Y6wjHOodvlHNbQF1XLIZmbyT8nOfHgNIgjzvfYD6RsXg63Ii2pU8XvMfFGEpTu33vrjIQhpDSqCwE7LHN&uniplatform=NZKPT&language=CHS">卒中;</a> <a href="https://kns.cnki.net/kcms2/keyword/detail?v=mjz80qGfPOWHIm7Y6wjHOodvlHNbQF1XYotKzrLtQOYhj9oNbQJmlVXG8dJpyif135Qb2EmiZ97J5ZlVO8YUM0ehblvzx6d0N9puduN-uN2ZY9cmAE1F_A==&uniplatform=NZKPT&language=CHS">功能重组;</a> <a href="https://kns.cnki.net/kcms2/keyword/detail?v=mjz80qGfPOWHIm7Y6wjHOodvlHNbQF1XWJMa7IUAZ973RfvqZOwnMJl-dO4111cNqwSHsM-lDI4DIMpsZ7Su1GNG_rWvJT3EZ-R6hf-O5dKS3b6bdUcrrg==&uniplatform=NZKPT&language=CHS">神经康复;</a></strong></p><h3 id="1-研究意义"><a href="#1-研究意义" class="headerlink" title="1. 研究意义"></a>1. 研究意义</h3><p>脑机接口（Brain-Computer Interface, BCI）技术在神经康复中的应用为神经系统损伤患者提供了一种全新的康复途径。通过直接读取大脑信号并将其转化为外部设备的控制命令，BCI技术可以帮助患者恢复运动功能、认知能力和语言能力，显著改善患者的生活质量。研究这一技术的应用不仅有助于推动神经康复领域的发展，还能为更多的神经系统疾病提供有效的康复手段。<br><img src="/img/519-1.png" alt="Lena"></p><h4 id="1-1-提升神经康复效果"><a href="#1-1-提升神经康复效果" class="headerlink" title="1.1. 提升神经康复效果"></a>1.1. 提升神经康复效果</h4><p>传统的神经康复方法，如物理治疗和职业治疗，虽然有效，但常常依赖于患者的自主运动能力和认知状态。而BCI技术通过直接解读大脑信号并将其转化为控制指令，能够为那些严重运动障碍患者提供全新的康复路径。研究表明，BCI结合运动想象训练和虚拟现实技术，可以显著促进中风患者的运动功能恢复​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><h4 id="1-2-推动神经科学研究"><a href="#1-2-推动神经科学研究" class="headerlink" title="1.2. 推动神经科学研究"></a>1.2. 推动神经科学研究</h4><p>BCI技术的应用有助于深入理解大脑功能和神经可塑性机制。通过分析患者在康复训练中的脑电信号，研究人员可以获取有关大脑如何在神经损伤后重塑和恢复的宝贵数据。这不仅对神经康复有指导意义，也为神经科学的基础研究提供了重要的实验数据和研究模型​ (<a href="https://braininformatics.springeropen.com/articles/10.1186/s40708-023-00199-3">SpringerOpen</a>)​<br><img src="/img/519-2.png" alt="Lena"></p><p align="center">神经系统的基本组成（神经元、神经网络、突触）</p><h4 id="1-3-促进多学科融合发展"><a href="#1-3-促进多学科融合发展" class="headerlink" title="1.3. 促进多学科融合发展"></a>1.3. 促进多学科融合发展</h4><p>BCI技术的发展需要神经科学、计算机科学、工程学和临床医学等多个学科的协同合作。通过BCI在神经康复中的应用研究，可以促进这些学科之间的交流与合作，推动跨学科研究的进步。例如，信号处理和人工智能技术的进步直接影响到BCI系统的性能和应用效果​ (<a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.699428/full">Frontiers</a>)​。</p><h4 id="1-4-提供个性化康复方案"><a href="#1-4-提供个性化康复方案" class="headerlink" title="1.4. 提供个性化康复方案"></a>1.4. 提供个性化康复方案</h4><p>每位神经损伤患者的病情和恢复过程各不相同，BCI技术可以根据患者的脑电信号和康复需求，提供个性化的康复训练方案。这种定制化的康复方法能够更有效地满足患者的需求，提高康复效果和患者的生活质量​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><h4 id="1-5-促进康复医疗技术进步"><a href="#1-5-促进康复医疗技术进步" class="headerlink" title="1.5. 促进康复医疗技术进步"></a>1.5. 促进康复医疗技术进步</h4><p>BCI技术的研究和应用推动了康复医疗设备的发展。通过与机器人、虚拟现实和人工智能技术的结合，BCI系统正在变得越来越智能和高效。这不仅提高了康复训练的效果，也大大拓展了康复医疗设备的应用范围​ (<a href="https://braininformatics.springeropen.com/articles/10.1186/s40708-023-00199-3">SpringerOpen</a>)​。</p><h4 id="1-6-伦理和社会影响"><a href="#1-6-伦理和社会影响" class="headerlink" title="1.6. 伦理和社会影响"></a>1.6. 伦理和社会影响</h4><p>研究BCI技术在神经康复中的应用还具有重要的伦理和社会意义。如何确保患者数据的隐私和安全，如何制定合理的伦理规范和使用指南，都是BCI技术应用过程中需要解决的重要问题。通过相关研究，可以为制定政策和规范提供科学依据，确保BCI技术的安全和可持续发展​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><h3 id="2-概念、定义、理论基础"><a href="#2-概念、定义、理论基础" class="headerlink" title="2. 概念、定义、理论基础"></a>2. 概念、定义、理论基础</h3><p>脑机接口是一种通过检测和解释大脑信号来实现人机交互的技术。其核心理论基础包括：</p><p><strong>神经塑性（Neuroplasticity）</strong>：指大脑在受损后通过重新组织自身结构和功能来恢复正常功能的能力​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><p><strong>运动想象（Motor Imagery）</strong>：指不进行实际运动时，通过想象运动来激活相关脑区的方法，常用于BCI康复训练​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><h3 id="3-起源、背景、现状、问题"><a href="#3-起源、背景、现状、问题" class="headerlink" title="3. 起源、背景、现状、问题"></a>3. 起源、背景、现状、问题</h3><h4 id="3-1-起源与背景"><a href="#3-1-起源与背景" class="headerlink" title="3.1 起源与背景"></a>3.1 起源与背景</h4><p>BCI技术最早起源于20世纪60年代，最初用于探索如何通过大脑信号直接控制计算机和其他设备。随着科技的进步，BCI逐渐应用于医疗领域，特别是在神经康复中的应用。</p><h4 id="3-2-现状"><a href="#3-2-现状" class="headerlink" title="3.2 现状"></a>3.2 现状</h4><p>目前，BCI技术已经广泛应用于中风、脊髓损伤等患者的康复训练中。通过EEG等无创技术获取脑电信号，并结合虚拟现实、机器人等技术，BCI康复训练在临床上取得了显著效果​ (<a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.699428/full">Frontiers</a>)​​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。<br><img src="/img/519-3.png" alt="Lena"></p><p align="center">神经可塑性</p><h4 id="3-3-问题"><a href="#3-3-问题" class="headerlink" title="3.3 问题"></a>3.3 问题</h4><p><strong>技术挑战</strong>：信号噪声和伪影、数据处理复杂、实时性和准确性问题​ (<a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.699428/full">Frontiers</a>)​。</p><p><strong>临床应用挑战</strong>：个体差异、长期使用效果、用户适应性问题​ (<a href="https://braininformatics.springeropen.com/articles/10.1186/s40708-023-00199-3">SpringerOpen</a>)​。</p><p><strong>伦理和隐私问题</strong>：数据隐私和安全、知情同意和使用伦理​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><h3 id="4-研究方案、技术、结论及相关问题的比较和分析"><a href="#4-研究方案、技术、结论及相关问题的比较和分析" class="headerlink" title="4. 研究方案、技术、结论及相关问题的比较和分析"></a>4. 研究方案、技术、结论及相关问题的比较和分析</h3><h4 id="4-1-研究方案"><a href="#4-1-研究方案" class="headerlink" title="4.1 研究方案"></a>4.1 研究方案</h4><p>研究通常包括以下几个步骤：</p><p><strong>信号采集</strong>：通过EEG等设备采集大脑信号。</p><p><strong>信号处理</strong>：包括滤波、去噪、特征提取和分类。</p><p><strong>反馈机制</strong>：通过虚拟现实、机器人等设备提供实时反馈。</p><h4 id="4-2-技术"><a href="#4-2-技术" class="headerlink" title="4.2 技术"></a>4.2 技术</h4><p><strong>EEG技术</strong>：广泛应用于无创BCI系统，具有成本低、便携性强等优点​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><p><strong>信号处理算法</strong>：如支持向量机、神经网络、深度学习等，用于提高信号分类的准确性​ (<a href="https://braininformatics.springeropen.com/articles/10.1186/s40708-023-00199-3">SpringerOpen</a>)​。</p><h4 id="4-3-结论及比较"><a href="#4-3-结论及比较" class="headerlink" title="4.3 结论及比较"></a>4.3 结论及比较</h4><p><strong>中风康复</strong>：BCI结合运动想象和虚拟现实技术，显著改善患者的运动功能​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><p><strong>脊髓损伤康复</strong>：BCI控制外骨骼机器人，帮助患者恢复运动能力​ (<a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.699428/full">Frontiers</a>)​。</p><h4 id="5-发展趋势"><a href="#5-发展趋势" class="headerlink" title="5. 发展趋势"></a>5. 发展趋势</h4><p>未来，BCI技术在神经康复中的发展将主要集中在以下几个方面：</p><p><strong>人工智能和机器学习</strong>：利用AI优化信号处理和分类算法​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><p><strong>多模态融合</strong>：结合多种传感器和反馈机制，提高康复效果​ (<a href="https://braininformatics.springeropen.com/articles/10.1186/s40708-023-00199-3">SpringerOpen</a>)​。</p><p><strong>个性化康复方案</strong>：根据患者的具体情况，制定个性化的康复计划​ (<a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.699428/full">Frontiers</a>)​。</p><h3 id="6-值得深入研究的方向"><a href="#6-值得深入研究的方向" class="headerlink" title="6. 值得深入研究的方向"></a>6. 值得深入研究的方向</h3><p><strong>新型传感器技术</strong>：开发更高效、更精确的传感器以提高信号采集的质量​ (<a href="https://svn.bmj.com/content/7/6/541">BMJ SVNP</a>)​。</p><p><strong>长期使用效果</strong>：研究BCI系统的长期使用效果和安全性​ (<a href="https://braininformatics.springeropen.com/articles/10.1186/s40708-023-00199-3">SpringerOpen</a>)​。</p><p><strong>用户体验优化</strong>：改善用户界面设计，提高患者的使用体验和训练效果​ (<a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.699428/full">Frontiers</a>)​。</p><h3 id="7-脑机接口在神经康复中的重要应用和研究成果"><a href="#7-脑机接口在神经康复中的重要应用和研究成果" class="headerlink" title="7. 脑机接口在神经康复中的重要应用和研究成果"></a>7. 脑机接口在神经康复中的重要应用和研究成果</h3><p>对于轻度功能障碍，通过正确的强化训练、作业治疗等方法能帮助患者获得很好的功  能康复。但对于中重度功能障碍，患肢的运动功能往往十分受限甚至几乎完全丧失。为让这些患者能进行正确的主动康复训练，科学家引入了脑机接口技术。从对神经系统功能的影响看，脑机接口可分为三类：功能替代、功能辅助、功能增强与拓展。用于神经功能康复的脑机接口基本上是非侵入式的，主要起到辅助作用。若肢体运动功能障碍完全无法修复时，只能采用替代性脑机接口，如运动假体。</p><p>就神经康复脑机接口而言，它通过对神经界面采集到的脑活动信号进行实时解码，根据解码结果驱动外部设备，及时辅助肢体完成运动训练。根据赫布法则和脉冲时序依赖性可塑性，相关神经元的同步发放对于神经功能网络的修复是至关重要的。利用脑机接口进行运动康复训练的第一步就是用户要自主产生运动意图。1979年，奥地利神经科学家普尔特席勒（G.Pfurtscheller）发现，当被试者在执行一个简单的手指运动时，对应皮层肢体感觉运动功能区的脑电图信号会在α(8-12赫兹）和β（13-30赫兹）频段发生明显的能量衰减，这被称为事件相关去同步化，而在手指运动结束并保持静息状态时，该脑区的信号能量又会有一个明显的反弹性升高，即事件相关同步化[7]。进一步研究发现，除了运动指令传输到肢体执行了真实的动作之外，当被试者有肢体的运动计划或运动想象时，相应脑区也能记录到这两种现象。该生理特征为利用非侵入式脑电图信号识别运动意图奠定了基础，也促成研究者首次利用基于脑电图的脑机接口帮助四肢截瘫患者进行手指运动训练。此后，利用运动想象EEG信号开发神经康复脑机接口的研究持续增加。至今，运动想象和脑电图依然是主流的行为范式和神经界面技术。<br><img src="/img/519-4.png" alt="Lena"></p><p align="center">脑机接口辅助上肢运动康复训练</p><p>在记录到脑活动信号后，在线脑机接口需要对其依次进行预处理、特征提取和分类，方可完成神经解码。而得益于传统机器学习和近年复兴的深度学习算法的进步，非侵入式脑机接口解码技术已相当成熟。其中，常用的特征提取方法有时频分析和空间滤波，常用的分类方法有支持向量机和卷积神经网络。在神经控制环节，当确认被试者有运动意图，脑机接口会驱动外部设备及时辅助肢体进行相应的运动训练。根据外部设备类型，当前的脑机接口主要有两种：一种结合功能性电刺激，一种结合康复机器人。前者主要通过经皮电刺激引起肌肉和外周神经元兴奋，后者通过机械牵引。</p><p>综合来看，脑机接口一方面保证了中枢神经的充分激活，从而利于运动控制网络的修复；另一方面通过外部设备使得外周肢体能及时响应，从而让中枢活动和外周活动能紧密耦联。这种紧密耦联同时涉及从中枢到外周的运动传出通路和从外周到中枢的感觉传入通路，对于整个感觉运动控制系统的重构无疑是举足轻重的。另外很重要的一点是，脑机接口训练能够规范运动训练内容，让被试者避免形成不良的运动习惯，尤其是代偿性运动。可以预期，脑机接口辅助康复训练能够加快运动康复进程，缩短康复时间，提高最终的康复效果。2018年美国神经病学会会刊《神经病学》上发表的一篇荟萃分析,回顾了过去10多年的临床试验发现，相比于其他康复治疗手段（如镜像疗法、虚拟现实、机器人辅助、经颅直流电刺激等），接受脑机接口训练的患者的运动功能评分改善最为明显，表明脑机接口技术具有很大的优越性[8]。同年，瑞士一个团队报道了在卒中发病至少10个月以上的患者使用脑机接口进行康复训练的结果[9]。实验中，患者佩戴脑电帽，努力尝试伸展患侧手指。每当检测到运动意图时就驱动设备对指总伸肌（位于前臂和手掌背面的控制拇指以外4个手指伸展的肌群）进行功能性电刺激。经过连续5周训练，发现接受脑机接口训练的患者与那些接受随机功能性电刺激的患者相比，感觉运动功能评分获得临床显著意义的提升，且这种改善至少可保持30周。这项结果表明，脑机接口可以在一定程度上突破传统认为的卒中康复天花板（即卒中后6个月达到平台期），且治疗效果有持久性。</p><h3 id="8-未来的挑战"><a href="#8-未来的挑战" class="headerlink" title="8.未来的挑战"></a>8.未来的挑战</h3><p>从细胞学说到发现神经系统，再到阐明神经的可塑性，在探索神经系统的科研道路上，科学家们前赴后继，终于在近200年后催生出脑机接口技术，让卒中患者重获塑造新生的信心。经过20多年的探索，脑机接口已取得巨大进步，并在卒中康复治疗中展现出令人喜悦的效果。</p><p>由于人体神经—肌肉—骨骼系统的复杂性，目前限制脑机接口在运动康复中发挥最大效用的因素主要有两个方面。一是因为依然缺乏对感觉运动控制、高级认知、跨越细胞和皮层功能区的可塑性等神经机制的了解，包括左右大脑半球的相互关系、运动控制指令的产生和传输、局部神经网络的重构过程、电磁刺激对神经系统的作用机制等。其中极为重要的是运动意图是如何产生并逐步生成运动控制指令。当前主流的脑机接口都是采用单纯的运动想象范式来引导患者形成运动意图。但近年有研究表明，运动想象的皮层激活虽然与真实的运动执行有相似之处，但二者是有根本区别的，前者主要引起初级运动皮层浅层皮质的激活，后者则引起浅层和深层的激活，且激活水平明显更高。另外，这些运动想象范式往往都是让患者看到图像提示后凭空想象运动，而不是与某个确定的物体直接进行交互，这与我们日常生活中常见的目标导向运动相去甚远，也难以调动更多脑区参与到运动训练中。</p><p>另一方面是现有技术的不足，包括非侵入式信号的信息量有限、不同训练日的信号漂移与校正、神经界面的抗干扰能力差、神经控制环节的肌肉协同问题等。这些问题都需要各学科通力合作。例如，肌肉协同问题需要功能性电刺激和康复机器人能事先完成动力学建模、运动轨迹规划和力控计算，从而提高训练辅助过程中的柔顺性、精准性和安全性。而且，为设计精准的康复治疗方案，感觉运动功能评估的规范性和精准性也需进一步提高。</p><p>当前，世界各国对脑科学研究越来越重视，随着脑科学在神经康复上不断加大的投入和转化，将改变当前的临床现状，不仅把治疗师从繁重的体力劳动中解放出来，而且治疗方案也会进一步细化，并增强患者的参与度，提高康复速度和效果。脑机接口康复方法目前在国内刚刚萌芽，它将具有巨大的市场规模和广阔的市场前景。</p><h3 id="9-应用前景预测"><a href="#9-应用前景预测" class="headerlink" title="9. 应用前景预测"></a>9. 应用前景预测</h3><p>随着技术的不断进步和多学科的协同合作，BCI在神经康复中的应用前景广阔。未来，BCI技术有望成为神经系统疾病康复的重要手段，进一步推动康复医学的发展，显著改善患者的生活质量。</p>]]></content>
      
      
      <categories>
          
          <category> 前沿 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 专业前沿 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP之文件上传</title>
      <link href="/2023/10/08/php%E4%B9%8B%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/"/>
      <url>/2023/10/08/php%E4%B9%8B%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="PHP-文件上传-，通过-PHP，可以把文件上传到服务器。-允许用户从表单上传文件是非常有用的。"><a href="#PHP-文件上传-，通过-PHP，可以把文件上传到服务器。-允许用户从表单上传文件是非常有用的。" class="headerlink" title="PHP 文件上传 ，通过 PHP，可以把文件上传到服务器。 允许用户从表单上传文件是非常有用的。"></a>PHP 文件上传 ，通过 PHP，可以把文件上传到服务器。 允许用户从表单上传文件是非常有用的。</h2><h2 id="创建一个文件上传表单"><a href="#创建一个文件上传表单" class="headerlink" title="创建一个文件上传表单"></a>创建一个文件上传表单</h2><p>允许用户从表单上传文件是非常有用的。</p><p>请看下面这个供上传文件的 HTML 表单：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;utf-8&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>php文件上传<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span></span></span><br><span class="line"><span class="tag">      <span class="attr">action</span>=<span class="string">&quot;../php/upload_file.php&quot;</span></span></span><br><span class="line"><span class="tag">      <span class="attr">method</span>=<span class="string">&quot;post&quot;</span></span></span><br><span class="line"><span class="tag">      <span class="attr">enctype</span>=<span class="string">&quot;multipart/form-data&quot;</span></span></span><br><span class="line"><span class="tag">    &gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;file&quot;</span>&gt;</span>文件名：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;file&quot;</span> <span class="attr">name</span>=<span class="string">&quot;file&quot;</span> <span class="attr">id</span>=<span class="string">&quot;file&quot;</span> /&gt;</span><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">name</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;提交&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>有关上面的 HTML 表单的一些注意项列举如下：<br>form 标签的 enctype 属性规定了在提交表单时要使用哪种内容类型。在表单需要二进制数据时，比如文件内容，请使用 “multipart&#x2F;form-data”。<br>input 标签的 type&#x3D;”file” 属性规定了应该把输入作为文件来处理。举例来说，当在浏览器中预览时，会看到输入框旁边有一个浏览按钮。</p><p>注释：允许用户上传文件是一个巨大的安全风险。请仅仅允许可信的用户执行文件上传操作。</p><p>创建上传脚本：<br>“upload_file.php” 文件含有供上传文件的代码：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;error&quot;</span>] &gt; <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;错误：&quot;</span> . <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;error&quot;</span>] . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;上传文件名: &quot;</span> . <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;name&quot;</span>] . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;文件类型: &quot;</span> . <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;type&quot;</span>] . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;文件大小: &quot;</span> . (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;size&quot;</span>] / <span class="number">1024</span>) . <span class="string">&quot; kB&lt;br&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;文件临时存储的位置: &quot;</span> . <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;tmp_name&quot;</span>];</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一个参数是表单的 input name，第二个下标可以是 “name”、”type”、”size”、”tmp_name” 或 “error”。如下所示：</p><ul><li>$_FILES[“file”][“name”] - 上传文件的名称</li><li>$_FILES[“file”][“type”] - 上传文件的类型</li><li>$_FILES[“file”][“size”] - 上传文件的大小，以字节计</li><li>$_FILES[“file”][“tmp_name”] - 存储在服务器的文件的临时副本的名称</li><li>$_FILES[“file”][“error”] - 由文件上传导致的错误代码</li></ul><p>这是一种非常简单文件上传方式。基于安全方面的考虑，您应当增加有关允许哪些用户上传文件的限制。<br>下图是上传之后的显示。<br><img src="/img/108-1.png" alt="Lena"><br>在这个脚本中，我们增加了对文件上传的限制。用户只能上传 .gif、.jpeg、.jpg、.png 文件，文件大小必须小于 200 kB：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 允许上传的图片后缀</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$allowedExts</span> = <span class="keyword">array</span>(<span class="string">&quot;gif&quot;</span>, <span class="string">&quot;jpeg&quot;</span>, <span class="string">&quot;jpg&quot;</span>, <span class="string">&quot;png&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="variable">$temp</span> = <span class="title function_ invoke__">explode</span>(<span class="string">&quot;.&quot;</span>, <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;name&quot;</span>]);</span><br><span class="line"></span><br><span class="line"><span class="variable">$extension</span> = <span class="title function_ invoke__">end</span>(<span class="variable">$temp</span>);        <span class="comment">// 获取文件后缀名</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (((<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;image/gif&quot;</span>)</span><br><span class="line"></span><br><span class="line">|| (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;image/jpeg&quot;</span>)</span><br><span class="line"></span><br><span class="line">|| (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;image/jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">|| (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;image/pjpeg&quot;</span>)</span><br><span class="line"></span><br><span class="line">|| (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;image/x-png&quot;</span>)</span><br><span class="line"></span><br><span class="line">|| (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;image/png&quot;</span>))</span><br><span class="line"></span><br><span class="line">&amp;&amp; (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;size&quot;</span>] &lt; <span class="number">204800</span>)    <span class="comment">// 小于 200 kb</span></span><br><span class="line"></span><br><span class="line">&amp;&amp; <span class="title function_ invoke__">in_array</span>(<span class="variable">$extension</span>, <span class="variable">$allowedExts</span>))</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;error&quot;</span>] &gt; <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;错误：: &quot;</span> . <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;error&quot;</span>] . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;上传文件名: &quot;</span> . <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;name&quot;</span>] . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;文件类型: &quot;</span> . <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;type&quot;</span>] . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;文件大小: &quot;</span> . (<span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;size&quot;</span>] / <span class="number">1024</span>) . <span class="string">&quot; kB&lt;br&gt;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;文件临时存储的位置: &quot;</span> . <span class="variable">$_FILES</span>[<span class="string">&quot;file&quot;</span>][<span class="string">&quot;tmp_name&quot;</span>];</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;非法的文件格式&quot;</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果我们提交一个 doc 文档则会显示<br><img src="/img/108-2.png" alt="Lena"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP之表单操作</title>
      <link href="/2023/06/16/php%E4%B9%8B%E8%A1%A8%E5%8D%95/"/>
      <url>/2023/06/16/php%E4%B9%8B%E8%A1%A8%E5%8D%95/</url>
      
        <content type="html"><![CDATA[<p><img src="/img/615-1.png" alt="Lena"><br>这是我们 html 的代码，我们用一个 form 标签将我们要提交给服务器后台的数据“username”和“password”通过 post 请求传给后台 php 页面。<br><img src="/img/615-2.png" alt="Lena"><br>在 php 页面我们首先声明两个 post 变量用于接收数据。然后将这两个变量用连接符连接起来，输出在屏幕上，最后的效果是这样的。<br><img src="/img/615-3.png" alt="Lena"><br><img src="/img/615-4.png" alt="Lena"><br>这样我们就初步理解了表单提交这一部分知识点。<br>一、请求分为三种：<br>（1）post 数据提交型：post+url 地址+请求正文<br>（2）get：资源获取型： get+url 地址<br>（3）ajax：利用异步提交方式，在不刷新页面的情况下，提交数据给后台。<br>其中 ajax 位异步请求方式，旨在不改变页面的情况下将数据传给后台。<br>前端用 get，后端就用 $<em>GET 函数取，用 post 后端就用 $_POST 取</em></p><p>二、AJAX 请求<br><img src="/img/615-5.png" alt="Lena"></p><p>（1） 要引入 jquery 的 js 库</p><script src="../js/jquery-3.2.1.min.js"></script><p>（2）不再需要 form，只需要任意一个元素发起 js 事件，让 js 代码进行处理。<br>我们通过在 html 的代码中添加 script 行<br> <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> &lt;script&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">dopost</span>(<span class="params"></span>) &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取表单元素的值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> username = $(<span class="string">&quot;#username&quot;</span>).<span class="title function_">val</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> password = $(<span class="string">&quot;#password&quot;</span>).<span class="title function_">val</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">//通过字符串拼接为一个正文</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> param = <span class="string">&quot;username=&quot;</span> + username + <span class="string">&quot;&amp;password=&quot;</span>+password; <span class="comment">//将 username 和 password 加进去，加上&amp;符号在尾随&#x27;&#x27;后面。然后将正文</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//window.alert(param); //弹出警告框，并将其显示在页面上。 （如果不可用，请注意允许用户</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//利用 ajax 发送 post 请求，并获取响应。</span></span><br><span class="line"></span><br><span class="line">$.<span class="title function_">post</span>(<span class="string">&#x27;../php/login.php&#x27;</span> , param , <span class="keyword">function</span>(<span class="params">data</span>)&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//data 是返回值的字符串。这是一个 HTML 页面上的表单。 这是一个正文。把返回值包含在 param 中。在页面上查看数据时，可以看到 param。</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">window</span>.<span class="title function_">alert</span>(data); <span class="comment">//打印数据到页面上。 如果不可用，请允许用户。</span></span><br><span class="line"></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&lt;/script&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>    再在后面的登录button中用上上面定义的dopost函数<br>    <button onclick="dopost()">登录</button><br>    这样我们就实现了一个简单的ajax的请求。</p><p><img src="/img/616-6.png" alt="Lena"></p><pre><code></code></pre>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP之数据库操作</title>
      <link href="/2023/06/16/php%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2023/06/16/php%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p><img src="/img/616-1.png" alt="Lena"><br>在连接数据库的时候，输入账号密码，发现并没有显示出我们想要的东西。说明我们并没还有连接成功。<br>而此时我们 php 中的代码是这样的</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$conn</span> = <span class="title function_ invoke__">mysqli_connect</span>(<span class="string">&#x27;localhost&#x27;</span>, <span class="string">&#x27;root&#x27;</span>, <span class="string">&#x27;********&#x27;</span>);</span><br></pre></td></tr></table></figure><p>ps：这里****是我的密码我就不展示了。<br>问题出在哪里呢？<br>我上网查证，经过一番操作后，翻阅到一篇 php 连接数据的博客<br>里面的 php 代码是这样的</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> <span class="variable">$db_host</span> = <span class="string">&quot;localhost&quot;</span>; <span class="comment">// Host name&quot;;</span></span><br><span class="line"></span><br><span class="line"> <span class="variable">$db_name</span> = <span class="string">&quot;root&quot;</span>;</span><br><span class="line"></span><br><span class="line"> <span class="variable">$db_pwd</span> = <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line"> <span class="variable">$conn</span> = <span class="title function_ invoke__">mysqli_connect</span>(<span class="variable">$db_host</span>, <span class="variable">$db_name</span>, <span class="variable">$db_pwd</span>);</span><br><span class="line"> <span class="keyword">if</span> (<span class="variable">$conn</span>) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;success&quot;</span>;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;fall&quot;</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_ invoke__">mysqli_query</span>(<span class="variable">$conn</span>, <span class="string">&quot;set names utf_8&quot;</span>);</span><br></pre></td></tr></table></figure><p>我将他的代码 copy 过来，发现我的页面显示还是不正确。</p><p>这个时候重点来了，因为我之前发现我的 xampp 中的 mysql 和本地服务器的 mysql 他们有冲突，我当时的解决方案是关闭本地服务的 mysql，这样端口 3306 就给了 xampp 的 mysql，不会造成端口冲突。但这样一开一关很麻烦。我在网上查资料，发现可以将 xampp 的端口改为非 3306（例如 3307），我在 xampp 中就进行了一番配置。这里配置主要是 mysql 端口 config 下的 my.ini 里面，将 3306 都改为 3307，然后我也顺便将 Apache 的端口改成了 8826 原本是 80。两个部分具体的配置建议参照网上的教程，我这里不详细。（ps：记得重启 xampp 面板里面的两个服务，因为修改了配置文件）<br><img src="/img/616-2.png" alt="Lena"><br>配置完成之后<br>我将上面有一行的代码进行了修改。如下图。然后就成功了！如下图的显示。</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> <span class="variable">$db_host</span> = <span class="string">&quot;localhost：3307&quot;</span>; <span class="comment">// Host name&quot;;</span></span><br></pre></td></tr></table></figure><p><img src="/img/616-3.png" alt="Lena"><br>不过问题又来了，连接数据库貌似成功了，但是我们现在这个数据库和本地数据库是不同的。意思就是现在 xampp 中的数据库是空的。我们要在里面创建数据库，创建表，才能使得 php 和数据库进行连接访问，进行一些 sql 语句的使用。<br>mysqli_real_connect(): (HY000&#x2F;1045): Access denied for user ‘root‘@’localhost’ (using password: YES)</p><p>上面这条语句是我最后一个卡壳的问题。意思就是密码错误。<br>我当时的密码设置是我本地 mysql3306 的密码，我想肯定有问题，第一是现在我用的 3307 端口，第二是目前我用的 xampp 数据库他和本地数据库肯定不能共用。知道这一点之后我又在网上查询，发现 xampp 数据库初始密码为空！！！！好，我又将配置文件密码改回来，这个时候回看我的代码，我那个时候设置的 pssword 确实为空。才连接成功的。<br><img src="/img/616-4.png" alt="Lena"></p><p>上面这个截图是\xampp 目录下的 phpMyAdmin 文件夹里面的 config.inc.php 这个配置文件。<br>改好之后。我再次访问(<a href="http://localhost:8626/phpmyadmin/">http://localhost:8626/phpmyadmin/</a>)<br>ps：注意上面 localhost 后面 8626 是我改了 apache 端口之后的端口默认是 80，所以读者不要直接复制这个网址，主要是后面的 phpmyadmin 这个页面。然后此时显示出来了页面如下图。ok 我可以进行增加数据库以及更改数据库密码那些操作了。问题解决！<br><img src="/img/616-5.png" alt="Lena"></p><p><img src="/img/616-6.png" alt="Lena"></p><p>如上图显示 ,下面是我的代码，learn 是我在 xampp 新加的一个库，然后是 user 表 里面有 username 和 password 两个属性。成功的打印出了我们想要的东西。</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_ invoke__">mysqli_select_db</span>(<span class="variable">$conn</span>,<span class="string">&quot;learn&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="variable">$sql</span> =  <span class="string">&quot;select * from user where username = &#x27;<span class="subst">$username</span>&#x27; and password = &#x27;<span class="subst">$password</span>&#x27; &quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span> <span class="variable">$sql</span>;</span><br></pre></td></tr></table></figure><p>后面修改 xampp 数据库密码请参见这篇文章 (<a href="https://blog.csdn.net/qq_41901122/article/details/109910774">https://blog.csdn.net/qq_41901122/article/details/109910774</a>)</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一回</title>
      <link href="/2023/05/04/%E7%AC%AC%E4%B8%80%E5%9B%9E/"/>
      <url>/2023/05/04/%E7%AC%AC%E4%B8%80%E5%9B%9E/</url>
      
        <content type="html"><![CDATA[<pre><code>                                                     第一幕：久别之后 “老板，来两杯度数低一点的酒”。    走进店里的是一男一女，男孩略带羞涩的点了两杯酒，我一眼就看出来他们不是经常来喝酒的人。女孩坐在吧台面前转着自己的椅子，摇晃这面前的骰子。    “分开之后这些时间，过得怎么样？”男生的一句话打破了原先略显尴尬的气氛。    “噢？就那样呗，照样上课，按时吃饭，看看小说。”女孩低着头看着骰盅里面的点数，嘴里含糊这回答男孩。“你呢？不是计划着开始‘一路向北’旅游了吗，钱攒的怎么    样了？”    女孩进入酒馆后第一次眼神落在男孩身上。    “那肯定啊，我这么厉害”男孩眼神躲闪着，嘴上却说着肯定的话。“啰，这是我给你准备的七周年礼物回去才看哦”说着他从脚边拿起一个礼品袋看样子是装着他准备好的    礼物。    女生见状也从身边拎出了一个口袋放在吧台上。他们交换了礼物。    “你们的酒好了，来，这杯是你的叫‘勇敢的心‘。”说着我轻轻的将这杯酒推到了男生面前。“这杯’美国往事‘是你的小姐。”我以同样的动作将酒送到女孩面前。我走到了    一旁一边收拾着台面一边打望着这两个人。    “这个老板还挺有意思的，给这些酒取的名字。”女孩打趣地看着手上的酒。“味道也挺奇怪的，第一口下去好像是苹果的清香夹杂着焦糖的甜味，入喉之后留下的却是一    丝酸苦。真有点像那啥是吧。”女孩转头看向男生。    “啊？嗯……也许是这样的呢，我这杯酒和你描述的也差不多，不过感觉要烈一点？我感觉喝下去之后有点热….”男孩说着，手在脖子上打转。    “我看你又是老毛病犯了，酒精过敏了吧小趴菜，你还是别喝了”女孩说着要抢过男孩的酒杯。    “没有，你乱说，我才喝一口歪，你还是老样子喜欢乱说。”男生红着脸却依旧不松手，嘴里振振有词地说道。    “又不是外人，你还记得当初在班上上化学课的时候吗，老唐说你是缺少什么酶来着？乙醛脱氢酶？让你以后少喝酒，小心猝死，那我以后就没有前任咯。”女生嬉皮笑脸    地看着男孩眼睛。    “那岂不是正合你意？以后再谈，你就可以说实话啦，没有前任是吧”男生侧着脸，摇晃着酒杯，眼睛却不敢望向女孩。    “你说得对，那你多喝点儿吧小伙子，到时候看看是你先吃我的席还是我先吃你的席。”女生憋着笑看着男生。    “咋？最近有新情况了？”    “算了吧，狗都不谈感情。”    “欸，说起分开，我们到底是因为什么分开啊？”男孩若有所思的望向女生好像，想从她的口里得到那个答案。    “过去这么久了，真的还重要吗？”女孩避开了男生的眼神，露出漫不经心的表情。    不知道是这句话的原因还是因为时间太早 ，店里人本身也很少的原因，整个酒馆在女孩最后一个字说完的那刻没有再多余的声音。我隔了好一会儿才注意到气氛的微    妙。正准备走过去缓和一下气氛问他们需要点什么服务啥的时候她说话了。    “时间不早啦，我得走了，我室友还等着我回去给她们带吃的呢。”女孩拿起外套准备起身。    “嗯..那我们一起呗我送送你？”男生明显想多留一下她，有点着急的样子看向她。    “不用啦，我们也不顺路，那再见啦！”没有多余的话，女孩径直走出门，披着一头飘逸的长发就这样消失在了十字路口。男孩还没缓过神来，挺直的背一下变得瘫软了。    “小兄弟，别喝啦，再喝等会儿醉我这儿了小心。”我拍着他的背，想劝劝他。    “其实我也没有想过我们会有今天，周围的朋友也都很诧异，我甚至在想毕业了我就向她求婚。”男孩低着头转着手上的戒指。“七年啊，断断续续的七年，从我们第一次    遇见那是 14 岁到现在 22 岁，噢快 8 年了。但我们停在了第七年…….”男孩从他们第一次见面开始讲起-----    那是开学的第一天，经过一个假期的同学们都在教室里面聊着天分享着刚结束的那个夏天。“大家安静安静，听我说，回到各自座位上。”班主任走到讲台边，手扶了扶眼    镜    &quot;收作业的先停一下，接下来我要讲一件重要的事。这学期我们班有一位新的同学来到我们的班级，大家欢迎一下&quot;班主任刚说完，目光转向前门，招了招手，一位扎着    马尾女孩背着书包走了进来，她自信的迈着脚步。    “大家好，我叫玙小双，你们可以叫我小双，很高兴能够来到我们班和大家一起冲刺最后一年的学习生涯。”她微微一笑结束了自我介绍。    “那你就坐中间那儿，那个男生旁边，李煦那儿。”班主任指了指我的方向。 我细细打量着我这位同桌，小小的个子走起路来却十分的拽，眼神十分坚定。    “你好，我叫李煦，以后我们就是同桌了。”我用桌上的便利贴写下简短的话悄悄传给她。“好的。”简短的两个字的回复，我们的同桌生涯就这么开始了。    “快来看啊，快来看啊，这次第一居然不是李煦”同学们围着月考成绩榜小声交谈着。“屿小双！那个新转来的同学啊，真是没看出来这么厉害。”他们四处张望着寻找屿小    双的身影。而属于我原本的平静也被他们的话惊扰到。    “老郭，走陪我上个厕所”我走到好哥们儿身旁想把他拉出教室。    “啊？你怎么回事，居然有一天你李煦上厕所还要人陪啊？真是太阳打西边来了。”老郭停下手上的笔，起身跟在我身后。    “话真多啊你。”我双手插着兜，想赶快离开这个是非之地。没走多远，屿小双迎面朝我走来，手上好像拿着卷子，她看到我抬起头，摆着头故意瘪这嘴朝我笑了下有匆匆    跑回教室。    “欸，怎么回事啊你俩同桌，一个第一，一个第二，真有点神雕侠侣的感觉啊哈哈。”老郭不怀好意的看着我笑。    “你不要瞎起哄啊，这次纯考砸了，我到不信她下次还能排在我前面。”我难掩自己的尴尬解释着。    “得嘞，快回去了，马上打铃了，下节课老唐肯定要将成绩。你就等着被洗刷吧。”他一边跑回教室一边回头朝我比了个‘二‘的手势。    “叮铃铃铃~“    “相信大家已经看到了这次考试的成绩吧，新来的小双同学，第一场考试就考了第一，某些同学还是要警惕起来啊。当然大家也要像李煦和屿小双学习，他们同桌一个第    一，    一个第二…….“老唐话还没说完，下面一些同学就开始起哄了。我撇了一眼旁边的屿小双，她递过来一张便利贴”这位同学考第二也没什么大不了的，继续加油争取下次超    过我噢~    哈哈“，我看着看似安慰我的话抬起头撇了她一眼，很好贱贱的。    “现在会想起，我大概是从那时候就开始喜欢她了吧。我这个人就喜欢有挑战性的事，而她也是那么的耀眼。呵呵~“说着男孩儿又一口酒下肚。    “后来我们无论是考的好还是考的差都排在一起，老师家长都以为我们在谈恋爱，但其实当时我们都不知道什么是谈恋爱哈哈你说好不好笑。“男孩一边看着我一边给我生    动    的描述他脑海里的画面。    第一幕：久别之后    “老板，来两杯度数低一点的酒”。    走进店里的是一男一女，男孩略带羞涩的点了两杯酒，我一眼就看出来他们不是经常来喝酒的人。女孩坐在吧台面前转着自己的椅子，摇晃这面前的骰子。    “分开之后这些时间，过得怎么样？”男生的一句话打破了原先略显尴尬的气氛。    “噢？就那样呗，照样上课，按时吃饭，看看小说。”女孩低着头看着骰盅里面的点数，嘴里含糊这回答男孩。“你呢？不是计划着开始‘一路向北’旅游了吗，钱攒的怎么    样了？”女孩进入酒馆后第一次眼神落在男孩身上。    “那肯定啊，我这么厉害”男孩眼神躲闪着，嘴上却说着肯定的话。“啰，这是我给你准备的七周年礼物回去才看哦”说着他从脚边拿起一个礼品袋看样子是装着他准备好的    礼物。    女生见状也从身边拎出了一个口袋放在吧台上。他们交换了礼物。    “你们的酒好了，来，这杯是你的叫‘勇敢的心‘。”说着我轻轻的将这杯酒推到了男生面前。“这杯’美国往事‘是你的小姐。”我以同样的动作将酒送到女孩面前。我走到了    一    旁一边收拾着台面一边打望着这两个人。    “这个老板还挺有意思的，给这些酒取的名字。”女孩打趣地看着手上的酒。“味道也挺奇怪的，第一口下去好像是苹果的清香夹杂着焦糖的甜味，入喉之后留下的却是一    丝酸苦。真有点像那啥是吧。”女孩转头看向男生。    “啊？嗯……也许是这样的呢，我这杯酒和你描述的也差不多，不过感觉要烈一点？我感觉喝下去之后有点热….”男孩说着，手在脖子上打转。    “我看你又是老毛病犯了，酒精过敏了吧小趴菜，你还是别喝了”女孩说着要抢过男孩的酒杯。    “没有，你乱说，我才喝一口歪，你还是老样子喜欢乱说。”男生红着脸却依旧不松手，嘴里振振有词地说道。    “又不是外人，你还记得当初在班上上化学课的时候吗，老唐说你是缺少什么酶来着？乙醛脱氢酶？让你以后少喝酒，小心猝死，那我以后就没有前任咯。”女生嬉皮笑脸    地看着男孩眼睛。    “那岂不是正合你意？以后再谈，你就可以说实话啦，没有前任是吧”男生侧着脸，摇晃着酒杯，眼睛却不敢望向女孩。    “你说得对，那你多喝点儿吧小伙子，到时候看看是你先吃我的席还是我先吃你的席。”女生憋着笑看着男生。    “咋？最近有新情况了？”    “算了吧，狗都不谈感情。”    “欸，说起分开，我们到底是因为什么分开啊？”男孩若有所思的望向女生好像，想从她的口里得到那个答案。    “过去这么久了，真的还重要吗？”女孩避开了男生的眼神，露出漫不经心的表情。    不知道是这句话的原因还是因为时间太早 ，店里人本身也很少的原因，整个酒馆在女孩最后一个字说完的那刻没有再多余的声音。我隔了好一会儿才注意到气氛的微    妙。正准备走过去缓和一下气氛问他们需要点什么服务啥的时候她说话了。    “时间不早啦，我得走了，我室友还等着我回去给她们带吃的呢。”女孩拿起外套准备起身。    “嗯..那我们一起呗我送送你？”男生明显想多留一下她，有点着急的样子看向她。    “不用啦，我们也不顺路，那再见啦！”没有多余的话，女孩径直走出门，披着一头飘逸的长发就这样消失在了十字路口。    男孩还没缓过神来，挺直的背一下变得瘫软了。    “小兄弟，别喝啦，再喝等会儿醉我这儿了小心。”我拍着他的背，想劝劝他。    “其实我也没有想过我们会有今天，周围的朋友也都很诧异，我甚至在想毕业了我就向她求婚。”男孩低着头转着手上的戒指。“七年啊，断断续续的七年，从我们第一次    遇见那是 14 岁到现在 22 岁，噢快 8 年了。但我们停在了第七年…….”男孩从他们第一次见面开始讲起-----    那是开学的第一天，经过一个假期的同学们都在教室里面聊着天分享着刚结束的那个夏天。“大家安静安静，听我说，回到各自座位上。”班主任走到讲台边，手扶了    扶眼镜    &quot;收作业的先停一下，接下来我要讲一件重要的事。这学期我们班有一位新的同学来到我们的班级，大家欢迎一下&quot;班主任刚说完，目光转向前门，招了招手，一位扎着马    尾 女孩背着书包走了进来，她自信的迈着脚步。    “大家好，我叫玙小双，你们可以叫我小双，很高兴能够来到我们班和大家一起冲刺最后一年的学习生涯。”她微微一笑结束了自我介绍。    “那你就坐中间那儿，那个男生旁边，李煦那儿。”班主任指了指我的方向。 我细细打量着我这位同桌，小小的个子走起路来却十分的拽，眼神十分坚定。    “你好，我叫李煦，以后我们就是同桌了。”我用桌上的便利贴写下简短的话悄悄传给她。“好的。”简短的两个字的回复，我们的同桌生涯就这么开始了。    “快来看啊，快来看啊，这次第一居然不是李煦”同学们围着月考成绩榜小声交谈着。“屿小双！那个新转来的同学啊，真是没看出来这么厉害。”他们四处张望着寻找屿小    双的身影。而属于我原本的平静也被他们的话惊扰到。    “老郭，走陪我上个厕所”我走到好哥们儿身旁想把他拉出教室。    “啊？你怎么回事，居然有一天你李煦上厕所还要人陪啊？真是太阳打西边来了。”老郭停下手上的笔，起身跟在我身后。    “话真多啊你。”我双手插着兜，想赶快离开这个是非之地。没走多远，屿小双迎面朝我走来，手上好像拿着卷子，她看到我抬起头，摆着头故意瘪这嘴朝我笑了下有匆匆    跑回教室。    “欸，怎么回事啊你俩同桌，一个第一，一个第二，真有点神雕侠侣的感觉啊哈哈。”老郭不怀好意的看着我笑。    “你不要瞎起哄啊，这次纯考砸了，我到不信她下次还能排在我前面。”我难掩自己的尴尬解释着。    “得嘞，快回去了，马上打铃了，下节课老唐肯定要将成绩。你就等着被洗刷吧。”他一边跑回教室一边回头朝我比了个‘二‘的手势。    “叮铃铃铃~“    “相信大家已经看到了这次考试的成绩吧，新来的小双同学，第一场考试就考了第一，某些同学还是要警惕起来啊。当然大家也要像李煦和屿小双学习，他们同桌一个第    一，一个第二…….“老唐话还没说完，下面一些同学就开始起哄了。我撇了一眼旁边的屿小双，她递过来一张便利贴”这位同学考第二也没什么大不了的，继续加油争取下    次超过我噢~哈哈“，我看着看似安慰我的话抬起头撇了她一眼，很好贱贱的。    “现在会想起，我大概是从那时候就开始喜欢她了吧。我这个人就喜欢有挑战性的事，而她也是那么的耀眼。呵呵~“说着男孩儿又一口酒下肚。    “后来我们无论是考的好还是考的差都排在一起，老师家长都以为我们在谈恋爱，但其实当时我们都不知道什么是谈恋爱哈哈你说好不好笑。“男孩一边看着我一边给我生    动的描述他脑海里的画面。    “那后来呢，你们怎么在一起的？“我开始好奇他接下来的回忆。    “再后来，我们去了同一个高中，我学的理科，她选择了文科，我们之间的交际减少了许多，但是她经常来找我借我的数学笔记。哥们儿当时数学成绩可好了，每次考完    我的数学卷子都会在年级上展示，当然展示的都是复印件，原卷我总会留给她…..“他笑着描绘当初他的意气风发的模样。    “她文科看的懂你的卷子吗？“我问他。    “哼，你别看她是文科生，那个时候就很要强了，什么都想考第一，总会问我一些理科数学的方法拿去做她的文科题。太要强了，哈哈，在我们的感情里面也是……”说到最    后他的眼神又变的黯淡了些。    “你还没讲你们在一起的呢。”我推了下他的手，想让他继续往下讲。我从一旁倒了一杯牛奶给他。    “哈哈谢谢，我真没有醉。”他咕噜咕噜几口喝了下去。    “当时我和她都是走读，有一段时间我早上很早就自然醒了，去学校居然发现有比我还早到校的学生！我一看发现就是她，果然应证了那句话比你聪明的人还比你努力。    意外    发现她这个习惯之后，那段时间我就起的很早，想和她在校门多说会儿话。”他一边说一边沉浸在他的脑海里。    “冬天天亮得很晚，那个时候我骑着我的车，在车轮上按了那种彩色的灯一闪一闪的转起来超酷，我故意等到她过路口的时候从她面前路过，当然我的双手在我的包包里    面哈哈哈，至少在那个时候我觉得我很酷。”他笑着给我模仿他双手插兜骑车的样子，真别提有多二了。“更搞笑的是，后来我问她哥们儿酷不酷的时候，你知道她咋说    吗，她 说她压根儿没注意到我，她早上走路的时候在背书。”我和他都笑了。    “哈哈哈你小子还真玩孔雀开屏那套啊”我拍着他的肩膀笑着他。    “谁说不是呢，现在想起来都觉得尴尬。那时候太二了。那时候我们会教学楼天台一起看日出，我还记得就是那天，圣诞节前一天，噢对平安夜那天，她在天台给了我一    个苹果，那天她很特别，眼睛扭扭捏捏的看着我，我就问她‘看日出啊，老是瞟我干嘛？‘她好像被我说的不好意思了，别管了那时候太直男了，天透亮了，她从她校服口    袋里摸出了一封信给我，然后转身就跑走了。“他眯着眼睛开始回想。    “不知道从何说起，每次从你们班路过总会瞟一眼，看到你认真埋头写作业的背影让我觉得很心安。从前我总是一个人早早的在校门口等着，但后来有你陪着我，我……我    不知    道怎么了，最近总看到你和你后桌的女生说话，我心里很不舒服，上课会想，走路也会想，甚至睡觉的因为这件事情辗转反侧难以入眠。我想，我可能喜欢上你了李煦，    如果你不    喜欢我，你有喜欢的人，你就把这封信撕碎然后扔了，一定要撕碎！那如果你喜欢我……..”    “我给你讲哦，我当时别提有多开心了，这个傻瓜当时还觉得我喜欢我后桌那个女生哈哈哈”他笑着给我描述当时的场景，好像很得意的样子。    “那天下午放学，我像往常一样去骑车，结果她在外面等着我。我推车从她旁边走过，我当时也不知道怎么和他说嘛第一次这样挺紧张的其实。然后她就拉住了我的外    套。”    “所以，你对我什么感觉呢现在？”屿小双抿着嘴唇地看着我。    我看的出来了她有点不好意思，我心里想“哈哈哈哈哈，你也有今天啊屿小双，你也会有不好意思的时候。”    “做我女朋友吧。”我看着她的眼睛一动不动。    “啊？这样吗？好我答应你！”她脸上露出了笑容。    “莫名其妙明明是她给我表的白，变成了她答应我了，便宜都给他占完了。”我当时心想啊。    “那，李煦同学明天早上也会陪我看日出吗？”她跑到我车前回头看着我。    “啊？哈哈看心情咯”我故意逗她。    那天明明是骑着自行车上学的，回家却一直在走路。我们一边走一边聊天………..    “所以，你们这样就在一起了？”我一副吃瓜的样子看着他。    “是啊，那是第一次谈恋爱，身边的朋友们都很羡慕我们，就连家长知道之后也没有拦着我们，只是让我们把学习放在第一位。”他的声音放松了很多，神情也变得缓和起    来，看样子是比刚刚好点儿了吧。    “这场恋爱就像拔河，越到后面，我们都希望对方爱自己多一点，拼命想要赢得比赛，但是我忘了，在绳子的另一端对方先放手了，你只会摔得头破血流，我在这个梦里    沉睡了七年，醒过来的时候她已经到达彼岸，而我却不知身在何方。”他低沉的声音带我走进了那段些回忆…….    “我以前很喜欢你的。12 年高中毕业之后，我一个人来了成都，你选择呆在重庆，那段时间真是最灰暗的日子了。大一刚进校每天晚自习下课已经是 10 点钟了，一个人    回寝室，我一个人走在人行道最边上，唱歌给自己解闷，也常常默默地想你又在干什么。有一天我看到你发说说，我以为你背着我和其他女生出去玩了。那一瞬间真是干    净脑袋轰的一下要炸开了，懵了有好一会儿，你怎么可以背着我和其他女生出去玩呢，那天晚上给你打电话，却没有耐心听你的解释，我们爆发了第一次争吵，你说我像    煤气罐一样易燃易爆炸。那是我第一次体会到男人的嘴，骗人的鬼，你从前说过会包容的我的一切的。后来你的每条说说我都会看，但是再也不要给你点赞和评论了！    大二的时候，我没有住校了，我住在姑妈家里。他们睡得早，十点半之后就只剩我一个人坐在客厅里看书了，那么空旷只有一盏灯开着。有时候坐累了我就趴在桌子上闭    眼睛休息会儿，但常常还是想你，想我们下次见面是多久，我们可以去哪儿玩？你还记得吗有一天我们在打电话你说你在听西城男孩的歌，我告诉你我也在听，那时候我    真的觉得我们最有默契了!    你总说那段时间我喜怒无常经常删你，其实我都好几次想要放弃了，我不想再每天闲下来的时候都很想你但又见不到你了，不想在因为你的一条条信息反复读几次了。我    感觉你怎么不知道我在想什么呢，把你删了难道不知道来哄哄我吗，你是直男还是不喜欢我了呢？    但是每次你的好友申请发来我还是狠不下心来拒绝。有次十九分钟好友申请就过来了，搞得我怀疑删人还有好友通知呢。    你还记得你 14 年生日是在星期几吗？我记得是星期六，因为那天我掐着 3 点 24 分给你发生日快乐。那天早早给你说了晚安，你小子没想到吧，我一边听着蒲公英的    约定一边在沙发上盖着厚厚的一床被子玩手机。到了凌晨一点实在太晚了，我不想浪费电，我就把家里的灯都关了，就那么一小部手机配到我凌晨 2 点，但是实在太困    了，我把手机放在电视机下充电，循环播放着西城男孩的《Nothing gonna change my love for you》。稍稍清醒了又拔下来继续等，我设了个 3 点 21 分的闹钟便    稍稍休息了下.3 点 21 分闹钟响了，我码字等着，没想到因为实在太困了居然把消息发到了同学的群里，最后给你发的时间是 3 点 25 分。    ……….    七年啊，这七年我几乎天天都想着你，我不知道自己是怎么做到的。我省略了那么多的事，那么多我想你的心理路程，还是写了这么多字。中途好几次，想起那些过去，    喉咙都紧的厉害，眼睛也酸胀感觉眼泪已经蓄势待发。毕竟那些纠结，心酸，思念，放不下还有被一条条消息牵着这神经的感觉，一天天累积起来，又岂是文字可以说尽    的，你说我很少说起想你，因为没有你在身边的日子我已经习惯了。    你说我太不负责了，如此草草的就要结束我们七年的感情，可是你又曾懂过这七年我内心的想法，我不负责，偶尔想起还是觉得你是太过理智？还是就不曾喜欢过…….    在一起的时候我想要的太多了，我想你大小事任何事都让着我。我很容易悲观，总是喜欢往最坏的方向想，所以还是会没有安全感。只有你无条件的迁就，我才会觉得你    真的也很喜欢我吧。以至于我后来变得越来越无理取闹了，因为我真的想要你的多哄哄我。每次你一丁点的不耐烦，一句不太重的重话，还有吵架，还有家里的原因都让    我不停的内耗，到最后六年的感情竟也在一年的时间内消耗殆尽。    最开始分手的分手的那几天，有时候还在想要不要复合。但是翻翻分手晚上手机里的讯息，我又清醒过来，回想着那些感受和心情，我们真的不合适吧大概，分手会淡化    一些矛盾，但不代表那些矛盾消失。不知道过了这些日子你会怎么想我呢，只是我也想让你知道这些年我都是真心喜欢你的，我甚至想好了如果能一直走下去，我们就在    2017 年 9 月 9 日那天结婚吧，那天不仅是9.9 农历也是初九，多好的日子 999，代表长长久久。抱歉，浪费你七年的时光，希望我们向前走吧，祝你我都会遇到正确    的人   ----小双”    李煦强忍着泪水读完了一整封信，我问他你送的七周年礼物是什么？    “她最喜欢的拼图，上次我们旅游的时候她教我玩拼图，一开始总是找不对拼图，要不是大小不一样要么就是形状不一样。”他哽咽着。    “我想，人生就像拼图一样吧，我们从在一起到今天一直在拼着各自的拼图，结果发现我们没法组合成更大的拼图…….”他说完从礼品袋里掏出一条围巾上面是一张便利    贴。    “外面风大，围着它吧，我给你的周年礼物。”</code></pre>]]></content>
      
      
      <categories>
          
          <category> 小说 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shuoshuo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前言</title>
      <link href="/2023/05/04/%E5%89%8D%E8%A8%80/"/>
      <url>/2023/05/04/%E5%89%8D%E8%A8%80/</url>
      
        <content type="html"><![CDATA[<p>小邮 -李萧<br>前言</p><p>来到这座城市已经有了 10 个年头了，每天有数以万计的年轻人追逐梦想来到这里，</p><p>也有数以万计的人离开这座他们熟悉的城市。而我大概是会一直待在这种城市吧。08 年的时候我大学毕业，没有选择继续读研，进入社会工作是我当时唯一的出路了好像，记不清了害。只记得当时意气风发，和朋友谈笑间总是无意的表露出心中的心高气傲。<br>“老李，马上毕业了，你工作单位找好了吗？一天天也没见你着急”，嘴里一边吃着油条一边嘟囔着的人是我的室友小程。我们在学校外面早餐摊吃着早餐。我坐着小板凳上，望着还没亮的天发呆。</p><p>“喂，问你呢想啥呢”他用膝盖碰了碰我的膝盖。“啊？噢噢我啊，我自然是去最大的互联网公司挣最多的钱啦，再买一套三室一厅，娶个肤白貌美老婆，再生个女儿给你当妹妹，好大儿你觉得如何？”<br>我向他描绘着我脑袋里的蓝图，他果然十分欣喜的笑道“滚啊，就你四年挂的科比我谈的对象加起来还多。”，“你好意思是吧，大半夜把我叫出来喝酒说全是美女，结果是和你前任一起喝，你小子是<br>真不害臊啊”我给了他脑袋当头一“掌”。 “自己和前女友潇洒，喊我来帮你挡酒，真有你这么坑兄弟的”我不爽的看着他。“得了得了，这对早饭我请你好了吧，不气啦，下次我帮你，乖~臭宝儿”他摸着我的肩膀试图享用一顿饭就打发我，</p><p>“yue，别这样我才吃的早饭大哥。”我嫌弃的准备起身离开。“老板，钱给你放桌子上了啊~”他匆忙的结了帐从后面朝我跑了过来。一阵清风吹过，挑起了他的刘海，好吧清晨第一缕阳光撒在了他的脸<br>上，我承认小程是当时学校里面众多女生爱慕的对象，一字眉，长着一双杏眼，好似看什么都在放光一样。一米八几的个子好像在哪儿都是人群中的焦点。可能有些时候漂亮的脸蛋的确很有用吧，我<br>好像没那么生他的气了。“歪！你小子还真跑啊，也不知道等等你的宝贝”他故作娇羞的样子真的很好笑，他左手拿着衣服右手搭在我的肩膀上。“哎呀，你身上好大一股烟味，别给我蹭上了真是”我<br>皱褶眉头看着他，假意想摆脱他的手臂。“真男人说这些，大不了回去好哥哥帮你洗” ，“滚滚…” ……… 那个时候的我怎么也不会想到，有一天会在这种城市的某一个角落开一家酒馆吧。忘了自我介绍，我叫李森尧，我总向别人介绍到我自己“木子李，森林的森，尧舜禹的尧”。今年是我毕业后的第 6 年，</p><p>开店的第五年，这家叫做“不二酒馆”的酒馆是我自己攒钱开的，起初呢还没有这家小店，我只是在路边摆着一个小摊子给一些路过的人做一杯特调，赚的呢也大部分是那些去旁边酒馆里面消费不起的<br>学生的钱。我看见他们坐在路边和好朋友谈着人生，谈着他们的生活我十分感慨，时常也会想起当初被小程拉着去喝酒的那些日子，哥们儿几个也没啥生活费当时，常常都是他蹭着别人的卡蹭着别人<br>的酒还带上我。我在这儿给这些曾经的“我们”做着便宜的特调，听着他们的故事，尽兴之时也会抱起吉他弹上两曲，时间久了，来喝酒的都是些回头客。“老李，你这个摊子会一直在吗，等我们以后<br>毕业了，这就成了我们的老地方，成了我们喝酒的不二选择了啊！”这些可爱的学生们总是会问着我这么一个相同的问题，而我的回答也永远是“我也舍不得你们呀，只要你们还记得起我这个小酒<br>摊，你们随时回来喝！我给你们打八折哈哈哈”我笑着说。其实大概当时的我也不清楚自己会不会一直留在这儿吧，我这么高傲的人怎么可能摆一辈子的摊呢！？后来就有了现在这个不到 20 平的<br>小酒馆，名字就叫“不二”。</p><p>在这家小小的酒馆里，每天并没有很多的顾客，相比那些躁动的 livehouse，“不二”是一家清吧，每天坚持来的是一位音乐学院的驻场小姐姐，起初是没有驻场的，一次她来一个人坐在吧台点了一杯酒，她说让我按照她说的配，“威士忌，格雷伯爵红茶，橙子，苦酒，香草糖浆”。起初我是没有注意到有啥不一样的，她的声音十分低沉看上去是一个人你来喝闷酒的。“你们男人是不是没一个好东<br>西？”她摇着酒杯眼睛盯着我的方向，突然的提问打断了我在擦杯子的手“啊？你在问我吗？”我抬头看着他，似乎看到她眼里若隐若现的泪光。“嗯哼”她轻哼到，“我不这么认为，因为我就是男人，我更赞同把这个疑问换成‘好男人是谁？’，那我一定会毫不犹豫的告诉你，是你面前这个帅气的老板”我开玩笑想着缓和一下气氛。“算了吧，开个酒吧每天泡的妞不知道有多少呢，别装纯情噢大<br>叔。”她轻蔑地笑着说。“那可真不巧，我开这家店还真是自娱自乐，可不是打着调酒当老板的名声在这儿招摇撞骗。还有我不叫大叔。没比你大几岁”我眼神上下打量着这个也许才被某位小男生伤过的“心碎女士”。“啊？我不信，你看你这家酒馆，人也没几个，你挣什么钱啊，怪冷清的。”她眼神环顾着我的小店，嘴里说个不停像是在举出小店里的各个缺点。“欸对，你说的是有理，但总会有像你一样想找个安静的地方一个人喝苦酒倒苦水的小毛孩儿啊，巧了我还就挣你们的钱，你说气不气。”我的胜负欲告诉我我要反击了！她好像真被我说的话“攻击”到了，喝了一大口酒，然后朝我摆了摆手说“这个味道不对，你不行，怎么这么苦呢”。我笑了笑继续擦着手上的杯子“有些人啊，心里苦，欸他怪你的酒，你说好笑不好笑”。“切，大叔，别的店都有驻场，你怎么不请驻场啊，你这怎么和别人抢生意啊。”她一边说一边拿着酒杯在店里四处晃悠。“咯，那个角落看到了吗，一把吉他，一架 架子鼓东西我都是有的。有时候店里没人我自己就自娱自乐，有时候<br>有些顾客有才艺的我也欢迎他们展示。”</p><p>我话音还没落，她就拿起了靠在墙边的吉他。“哒哒哒哒，那片笑声让我想起我的那些花儿，在我生命每个角落静静为我开着~”，我心里咯噔一下，想不到啊这位“心碎女士”居然能弹能唱的。“真的很少</p><p>有见到女孩子听朴树的歌噢，不错嘛没看出来还挺会噢。”我手扶着下吧撑在吧台上。“那当然，我可是音乐学院的！你知道的吧我们学院有多厉害！那个李宇春知道吧就是我们学校的，我的直系师<br>姐！“ 我只当她在开玩笑，她一边说，我一边点头，附和着她的每一句吹出来的牛，她也越来越起劲了。“大叔，这样，要不你请我给你当驻场，我保证你这家酒馆生意好起来，怎么样？”她摇晃着身<br>子，手在空中比划着，好像在规划着这一切，看到他一本正经的说着她所谓的那些计划，我差点忘了我才是老板！“别，我可没那个钱付你的演出费，你们这些学生就会狮子大开口，我夸夸你，也没<br>让你来啊切”我赶忙拒绝到，想到我的小本生意本就不好做，要是再加上个演出费我的心就纯在滴血了。“嗨呀，瞧你那紧张那怂样儿，你看我像那些‘心‘很黑的人吗”她心里的眼神开着我。她一说<br>我才认真打量她，披着一头长长的黑发，小小的鹅蛋脸，弯弯的柳叶眉，眼睛里透露出一种清澈的“愚蠢”一看就让人觉得好骗，怪不得被渣男伤透了心。“咳咳，你大几啊，我可是先说啊在我这<br>间’小庙‘，只能是很少的出场费噢”我小声对她说，心里想着她应该能懂我的不容易吧。“这样，以后我要是来喝酒你不收我钱怎么样，就作为我的出场费，然后我可以先试着给你带几场，毕<br>竟！我可是大忙人，未来的天才歌手喂，懂吧。”她嘴里说着傲娇的话，脸上早已控制不住洋溢出了贱贱的笑。“好嘛，那我们一言为定，你带你的朋友们来我也不收钱。”当时的我真没有多犹<br>豫。“够爽快啊大叔，那祝我们合作愉快”，就这样“不二”的第一个驻场歌手就这么诞生了，直到后来很长一段时间我们都相处的很融洽，“不二”也成了他和她好朋友们的秘密基地，越来越多<br>的学生喜欢来我们这儿喝酒了，小小的店快要坐不下了，还好那个夏天到来了，我们在“不二”门口也添置了一些桌位，他们没有嫌弃“不二”太小了，反倒是享受炎炎夏日午夜的清风。</p><p>“重新认识一下，我叫郭墨。”</p><p><img src="/img/gm.jpg" alt="Lena"></p>]]></content>
      
      
      <categories>
          
          <category> 小说 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shuoshuo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于小说</title>
      <link href="/2023/05/04/%E5%85%B3%E4%BA%8E%E5%B0%8F%E8%AF%B4blog/"/>
      <url>/2023/05/04/%E5%85%B3%E4%BA%8E%E5%B0%8F%E8%AF%B4blog/</url>
      
        <content type="html"><![CDATA[<pre><code># 这篇小说的初衷谈起这篇小说的初衷，大概是年初的时候在小伙伴的启发下有了这个想法，想在今年年完善一篇十万字的小说，而小说的环境是我个人比较喜欢的一种环境--小酒馆。我的想法是，将身边发生的一些趣事，可能是我身上的也有朋友身上的，将这些故事进行一些小说化，最终展现在大家的眼前。这篇小说的受众群体初步定位是身边的朋友。毕竟个人的文笔有限，精力有限，写不出来什么大作，只当做是朋友间的消遣。## 小说的名字小说的名字在我最后的斟酌下，打算用“小邮筒”来命名，起初是小说的名字我是订作“不二酒馆”的，不二这个名字是源于我看过的一部电影里面的一个卡通兔子，不过我忘记是什么电影了，感兴趣的可以我搜索一下。但是在我很长一段时间的考虑下，还是放弃了之前的名字，觉得还是太普通甚至有点俗气了。而我也将小说的题材改变了。改名“小邮筒”，我是打算将这篇小说写成一篇类似于快穿？的一种小说吧。## 小说的背景前期故事背景还是以主人公以及小酒馆进行展开，在后期会随着发展需求，引入主线，“小邮筒”的出现。会有不同的人物出现，形成简短的小故事。</code></pre><hr><h2 id="小说的人物"><a href="#小说的人物" class="headerlink" title="小说的人物"></a>小说的人物</h2><p>因为这篇小说是一点点写出来的，每个故事只是有大概的雏形，所以对人物名称并没有全部一次性命名成功。所以我打算采用间断更新的方式，对小说的人物列表进行更新，写到哪一章就将人物更新到哪一章节。</p><blockquote><p><font color=Blue>主人公 -酒馆老板-李森尧</font> &gt; <font color=Blue>室友 - 小程</font> &gt; <font color=Blue>第一幕男主角 - 李煦</font> &gt; <font color=Blue>第一幕女主角 - 小双</font> &gt; <font color=Blue>驻场 - 郭墨</font></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 小说 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shuoshuo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快排模板</title>
      <link href="/2023/03/04/%E4%BB%A3%E7%A0%81%E5%9D%97%E6%BC%94%E7%A4%BA/%E6%BC%94%E7%A4%BA/"/>
      <url>/2023/03/04/%E4%BB%A3%E7%A0%81%E5%9D%97%E6%BC%94%E7%A4%BA/%E6%BC%94%E7%A4%BA/</url>
      
        <content type="html"><![CDATA[<!-- aplayer: true置顶 --><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1e6</span> + <span class="number">10</span>;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"><span class="type">int</span> q[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">quick_sort</span><span class="params">(<span class="type">int</span> q[],<span class="type">int</span> l,<span class="type">int</span> r)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(l&gt;=r) <span class="keyword">return</span>;</span><br><span class="line">    <span class="type">int</span> x = q[(l+r+<span class="number">1</span>)/<span class="number">2</span> ],i = l<span class="number">-1</span>,j = r+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;j)&#123;</span><br><span class="line">        <span class="keyword">do</span> i++ ;<span class="keyword">while</span>(q[i]&lt;x);</span><br><span class="line">        <span class="keyword">do</span> j-- ;<span class="keyword">while</span>(q[j]&gt;x);</span><br><span class="line">        <span class="keyword">if</span>(i&lt;j) <span class="built_in">swap</span>(q[i],q[j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">quick_sort</span>(q,l,j);</span><br><span class="line">    <span class="built_in">quick_sort</span>(q,j+<span class="number">1</span>,r);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;q[i]);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">quick_sort</span>(q, <span class="number">0</span> , n<span class="number">-1</span> );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++) <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,q[i]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>进入小李的世界吧！</title>
      <link href="/2022/11/17/%E8%BF%9B%E5%85%A5%E5%B0%8F%E6%9D%8E%E7%9A%84%E4%B8%96%E7%95%8C%E5%90%A7%EF%BC%81/"/>
      <url>/2022/11/17/%E8%BF%9B%E5%85%A5%E5%B0%8F%E6%9D%8E%E7%9A%84%E4%B8%96%E7%95%8C%E5%90%A7%EF%BC%81/</url>
      
        <content type="html"><![CDATA[<h1 id="The-World-of-Surely"><a href="#The-World-of-Surely" class="headerlink" title="The World of Surely"></a>The World of Surely</h1><p>介绍：在 11 月 16 日的晚上整个网站搭建完毕，从开始学习到有一个能看的网站用了大概 2-3 天零零散散的课余时间，做这个网站的初衷是为了记录我的学习日常，还有就是我未来的方向大概就是网络安全了，而我的第一站就是 Web 前端的学习，搭建网站也是必不可少的一关。So，·11111111 接下来我会在这个网站上继续更新，也会分享一些有趣的事。</p><p>此时此刻已经是 17 日的凌晨了，距离秋十的是生日已经过了两个月，我也是在看时间的时候不经意的注意到了这一点，最近是繁忙又充实的一段时间，快到期末了，有很多事情、比赛要去做，我也有点担心，不过不重要了其他的一切，一步一个脚印就 OK 了。</p><h2 id="关于-Surely"><a href="#关于-Surely" class="headerlink" title="关于 Surely"></a>关于 Surely</h2><p>我的网站域名是<a href="http://www.surely916.love.surely是我的一个昵称,小李的谐音,是不是很有意思呢,他本来的意思也是踏实的一步一个脚印的,也很符合我想成为的样子,呵呵./">www.Surely916.love。Surely是我的一个昵称，小李的谐音，是不是很有意思呢，他本来的意思也是踏实的一步一个脚印的，也很符合我想成为的样子，呵呵。</a></p><hr><p>下面我就自己记点儿未来半个月要做的事，试试 markdown 的语法</p><p>1 .复习 java（前段时间忙着 c++的学习忽略了 java）</p><p>2 .完成数据结构的项目</p><p>3 .似乎记不起来了</p><p>4 . 数电！！！知识太多了得复习</p><p>5 . 准备蓝桥杯和传智杯的比赛？！也是很重要的事情！！！</p><p>ok 大概就这些先这样</p><blockquote><p>试用一下区块这个语法</p><p>相比于普通的文本录入，旁边的竖线让整体显得更高级了一点，也是有了一点分门别类的感觉</p></blockquote><p>试一下代码的插入，咳咳(随便传的)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Person</span>(string name, <span class="type">int</span> age)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;m_Name = name;</span><br><span class="line">        <span class="keyword">this</span>-&gt;m_Age = age;</span><br><span class="line">    &#125;</span><br><span class="line">    string m_Name;</span><br><span class="line">    <span class="type">int</span> m_Age;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">test01</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    vector&lt;Person&gt; v;</span><br><span class="line">    <span class="function">Person <span class="title">p1</span><span class="params">(<span class="string">&quot;aaa&quot;</span>, <span class="number">10</span>)</span></span>;</span><br><span class="line">    <span class="function">Person <span class="title">p2</span><span class="params">(<span class="string">&quot;bbb&quot;</span>, <span class="number">20</span>)</span></span>;</span><br><span class="line">    <span class="function">Person <span class="title">p3</span><span class="params">(<span class="string">&quot;ccc&quot;</span>, <span class="number">30</span>)</span></span>;</span><br><span class="line">    <span class="function">Person <span class="title">p4</span><span class="params">(<span class="string">&quot;ddd&quot;</span>, <span class="number">40</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向容器中添加数据</span></span><br><span class="line">    v.<span class="built_in">push_back</span>(p1);</span><br><span class="line">    v.<span class="built_in">push_back</span>(p2);</span><br><span class="line">    v.<span class="built_in">push_back</span>(p3);</span><br><span class="line">    v.<span class="built_in">push_back</span>(p4);</span><br><span class="line">    <span class="keyword">for</span> (vector&lt;Person&gt;::iterator it = v.<span class="built_in">begin</span>(); it != v.<span class="built_in">end</span>(); it++)</span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;姓名：&quot;</span> &lt;&lt; (*it).m_Name &lt;&lt; <span class="string">&quot;年龄 ：&quot;</span> &lt;&lt; (*it).m_Age &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">test01</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">system</span>(<span class="string">&quot;pause&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>激动人心的时刻来了，接下来是尝试插入图片的语法，那么我会用什么图片呢？！</p><p>! <a href="https://tse4-mm.cn.bing.net/th/id/OIP-C.1kZBSgTYEJNKutwoLB4OsQHaHu?w=145&h=180&c=7&r=0&o=5&dpr=1.3&pid=1.7"> img</a></p><p>ps：这是创世之柱，最近网上很火的，据说是哈勃望远镜拍摄的 6500 光年外的鹰状星云内的一个照片，我感觉看上去很像一只巨大的手，神秘的！！</p><p>好啦，第一篇文章就到这里，一点三十七分！非常激动的结尾</p><p>By Surely</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
